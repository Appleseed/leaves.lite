{"page":1,"limit":30,"pages":2,"total":48,"_links":{"self":{"href":"http:\/\/qrisp.eastus.cloudapp.azure.com\/api\/entries?sort=created&order=desc&tags=cassandra&since=0&page=1&perPage=30"},"first":{"href":"http:\/\/qrisp.eastus.cloudapp.azure.com\/api\/entries?sort=created&order=desc&tags=cassandra&since=0&page=1&perPage=30"},"last":{"href":"http:\/\/qrisp.eastus.cloudapp.azure.com\/api\/entries?sort=created&order=desc&tags=cassandra&since=0&page=2&perPage=30"},"next":{"href":"http:\/\/qrisp.eastus.cloudapp.azure.com\/api\/entries?sort=created&order=desc&tags=cassandra&since=0&page=2&perPage=30"}},"_embedded":{"items":[{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4911,"title":"Relational Database to NoSQL","url":"https:\/\/www.datastax.com\/relational-database-to-nosql","content":"<!--HID72901 NSH--><!-- Google Tag Manager (noscript)  - PART 2 of 2  -->\n<noscript\/>\n<!-- End Google Tag Manager (noscript) -->\n<div id=\"DXDIV0\">\n    <!-- #Header -->\n\t<div id=\"Wrapper\"><!-- WrpprID1 -->\n\t\t<div class=\"wrapperContainer\">\n             \n    <div id=\"MainBody\">\n\t\t\t\t\t\t\t\t\n        <div id=\"MainChannel\" class=\"width-100 clearfix\">\n                                <div id=\"Content\" class=\" \">\n            \t\t\t\t\t\n\t\t\t\t\t\t<div id=\"ContentChannel\">\n\t\t\t<!-- https:\/\/www.datastax.com\/relational-database-to-nosql -->\n<!--  cloud  -->\n<div class=\"dx_stlfntmobmod_pge\" id=\"dx_thispage_div1\">\n<!-- DXGS_NoSqlBanner_v3 START -->\n<!-- DXGS_NoSqlBanner_v3 END -->\n<div class=\"thismb2content1width1\" readability=\"6.4545454545455\">\n       <div class=\"dx_hnltstd_lt_div dx_marginvertical_approx68pxless\" readability=\"18.454545454546\">\n            \n            <div class=\"dxfnts_ds_f20l30 \" readability=\"29\">\nTechnology that can scale, perform and deliver continuous availability is the difference between today\u2019s successful online applications and those that fail. Relational databases (RDBMS) have struggled to keep up with the wave of modernization, leading to the rise of NoSQL as the most viable database option for online Web and mobile applications.\n<p>The path to understanding whether a NoSQL technology like DataStax Enterprise is right for your business as either a complementary technology to an RDBMS or as a complete replacement is a three step approach.&#13;\n            <\/p><\/div>\n<\/div><\/div><!-- thismb2content1width1 -->\n<!-- dxcs_graybgdiv -->\n<\/div>\n\t\t\t\n<\/div> <!-- #ContentChannel -->\n<\/div> <!-- #MainChannel -->\n<div class=\"DXpgA2AclassV1\"><p>SHARE THIS PAGE<\/p><\/div>\n    \n    <\/div>\n\t <!-- #MainChannel -->\n\t\t\t<\/div> <!-- TBD IF - #MainBody -->\n\t\t<\/div> <!-- .wrapperContainer -->\n\t<\/div> <!-- #Wrapper -->\n              \n<!-- DXcom_footerKv2_div1 -->\n\t\n  <!-- Included JS Files (Compressed) -->\n    \n\t\n\t\n\t\n\t\n\t\n\t\n\t\n<\/div><!-- \/DXDIV0 -->","created_at":"2017-10-31T20:25:11+0000","updated_at":"2017-10-31T20:32:31+0000","annotations":[],"mimetype":"text\/html","language":"en-US","reading_time":0,"domain_name":"www.datastax.com","preview_picture":"http:\/\/www.datastax.com\/wp-content\/themes\/datastax-2013\/images\/common\/logo.png","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4911"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4910,"title":"MySQL to Cassandra Migrations","url":"https:\/\/academy.datastax.com\/planet-cassandra\/mysql-to-cassandra-migration","content":"<p>For 15+ years, Oracle\u2019s MySQL has been a de facto infrastructure piece in web applications, enjoying wide adoption. This is for good reason: MySQL provides a solid relational database that enables companies to build systems that perform well in many use cases. Yet, even its strongest supporters admit that it is not architected to tackle the new wave of big data applications. Modern businesses that need to manage big data use cases are turning to Apache Cassandra to replace MySQL.<\/p>\n\n<p>Migrating from MySQL to Cassandra:\u00a0General Info<\/p>\n<h3>Is Cassandra Right for Your Application?<\/h3>\n<p>A new class of databases (sometimes referred to as \u201cNoSQL\u201d) have been\u00a0developed and designed with 18+ years worth of lessons learned from\u00a0traditional relational databases such as MySQL. Cassandra (and other\u00a0distributed or \u201cNoSQL\u201d databases) aim to make the \u201cright\u201d tradeoffs to<br\/>ultimately deliver a database that provides the scalability,\u00a0redundancy, and performance needed in todays applications. Although\u00a0MySQL may have performed well for you in the past, new business\u00a0requirements and\/or the need to both scale and improve the reliability\u00a0of your application might mean that MySQL is no longer the correct fit.<\/p>\n<p>Before committing any further time towards a MySQL to Cassandra\u00a0migration, ask yourself:<br\/>\u201cIs MySQL\u00a0currently preventing development of new features or providing\u00a0acceptable uptime, reliability, and scalability for my users?\u201d<\/p>\n<p>\u201cNo\u201d: Not only should you not\u00a0migrate to Cassandra, but also you most\u00a0likely should not be considering a migration to any alternative\u00a0database. Migrating an application to a new database is a very\u00a0difficult, time consuming, and error-prone process.<\/p>\n<p>\u201cYes\u201d: Then hopefully you\u2019ve\u00a0found a helpful resource to help guide and\u00a0plan your migration from MySQL to Cassandra. There are many databases<br\/>available, all with their various advantages, disadvantages and\u00a0tradeoffs. This article is not an attempt to portray Cassandra as a\u00a0perfect solution; in fact, Cassandra\u2019s tradeoffs, advantages, and\u00a0disadvantages will be highlighted. Hopefully this will help you make a\u00a0decision that is both informed and educated; not one motivated by\u00a0marketing hype or change for the sake of change.<\/p>\n<p>Don\u2019t try to shove a square peg in a\u00a0round hole!<\/p>\n<ul><li>Cassandra is not a relational database.<\/li>\n<li>Cassandra is not a 100%\/\u201cdrop-in\u201d replacement for MySQL.<\/li>\n<li>Simply migrating existing code to Cassandra without\u00a0modifying and rethinking your existing data model will not result in\u00a0perfect uptime or fix performance bottlenecks for your application. In\u00a0fact, it might make things worse.<\/li>\n<\/ul>\n<h3>Key Terminology<\/h3>\n<p>The following overview of Cassandra terminology provides descriptions\u00a0and their MySQL equivalent. The goal is to introduce the most basic\u00a0terms and concepts required to get a basic understanding of Cassandra.\u00a0To read more on the key terms and architecture of Cassandra you can\u00a0find more detail in the\u00a0<a href=\"http:\/\/www.datastax.com\/documentation\/cassandra\/2.0\/cassandra\/architecture\/architectureIntro_c.html\">Cassandra\u00a0architecture documentation<\/a>\u00a0or for a higher level overview visit the\u00a0\u201c<a href=\"http:\/\/planetcassandra.org\/what-is-apache-cassandra\/\">What is\u00a0Cassandra<\/a>\u201d page on Planet Cassandra.<\/p>\n<p><img alt=\"\" src=\"https:\/\/academy.datastax.com\/sites\/default\/files\/keyterms-1.png\"\/><\/p>\n<p><img alt=\"\" src=\"https:\/\/academy.datastax.com\/sites\/default\/files\/keyterms-2.png\"\/><\/p>\n<p><img alt=\"\" src=\"https:\/\/academy.datastax.com\/sites\/default\/files\/keyterms-3.png\"\/><\/p>\n<h3>How is Data Handled?<\/h3>\n<p>At a very high level, Cassandra operates by dividing all data evenly\u00a0around a cluster of nodes, which can be visualized as aring. Nodes generally run on\u00a0commodity hardware. Each Cassandra node in the cluster is responsible\u00a0for and assigned a\u00a0token range\u00a0(which is essentially a range of hashes defined by a\u00a0partitioner, which defaults to\u00a0Murmur3Partitioner in Cassandra v1.2+). By default this hash range is\u00a0defined with a maximum number of possible hash values ranging from 0 to\u00a02^127-1.<\/p>\n<p>Each update or addition of data contains a unique\u00a0row key\u00a0(also known as a\u00a0primary key). The primary key is\u00a0hashed to determine a replica (or node) responsible for a token range\u00a0inclusive of a given row key. The data is then stored in the cluster<strong>n<\/strong>\u00a0times (where\u00a0<strong>n<\/strong>\u00a0is defined by the keyspace\u2019s\u00a0replication factor), or once on each\u00a0replica responsible a given query\u2019s row key. All nodes in Cassandra are\u00a0peers and a client\u2019s read or write request can be sent to any node in\u00a0the cluster, regardless of whether or not that node actually contains\u00a0and is responsible for the requested data. There is no concept of a\u00a0master or slave, and nodes dynamically learn about each other and the\u00a0state and health of other nodes thru the\u00a0gossip\u00a0protocol. A node that\u00a0receives a client query is referred to as the\u00a0coordinator\u00a0for the client\u00a0operation; it facilitates communication between all replica nodes\u00a0responsible for the query (contacting at least n replica nodes to\u00a0satisfy the query\u2019s\u00a0consistency level)\u00a0and prepares and returns a result to the client.<\/p>\n<h3>Reads and Writes<\/h3>\n<p>Clients may interface with Cassandra for reads and writes via either\u00a0the\u00a0native binary protocol\u00a0or\u00a0Thrift. CQL queries can be made over\u00a0both transports. As a general recommendation, if you are just getting\u00a0started with Cassandra you should stick to the native binary protocol\u00a0and CQL and ignore Thrift.<\/p>\n<p>When a client performs a read or write request, the coordinator node\u00a0contacts the number of required replicas to satisfy the consistency\u00a0level included with each request. For example, if a read request is\u00a0processed using QUORUM consistency, and the keyspace was created with a\u00a0\u201creplication factor\u201d of 3, 2 of the 3 replicas for the requested data\u00a0would be contacted, their results merged, and a single result returned\u00a0to the client. With write requests, the coordinator node will send a\u00a0write requests with all mutated columns to all replica nodes for a\u00a0given row key.<\/p>\n<h3>Processing a Local Update<\/h3>\n<p>When an update is processed \u2013 also known as a mutation \u2014 an entry is\u00a0first added to the\u00a0commit log,\u00a0which ensures durability of the transaction. Next, it is also added to\u00a0the\u00a0memtable. A memtable is a\u00a0bounded in memory write-back cache that contains recent writes which\u00a0have not yet been\u00a0flushed\u00a0to\u00a0an\u00a0SSTable\u00a0(a permanent,\u00a0immutable, and serialized on disk copy of the tables data).<\/p>\n<p>When updates cause a memtable to reach it\u2019s configured maximum\u00a0in-memory size, the memtable is flushed to an immutable SSTable,\u00a0persisting the data from the memtable permanently on disk while making\u00a0room for future updates. In the event of a crash or node failure,\u00a0events are replayed from the commit log, which prevents the loss of any\u00a0data from memtables that had not been flushed to disk prior to an\u00a0unexpected event such as a power outage or crash.<\/p>\n<h3>Distributed Computing<\/h3>\n<p>Distributed logic and designs will inevitably cause an increase in\u00a0complexity in application logic. When done right however, the rewards\u00a0are obvious and easy to appreciate. Operationally, while it might be\u00a0possible to get away with a single non-sharded MySQL instance installed\u00a0via apt-get\/emerge\/yum\/etc., operations with Cassandra need to be taken\u00a0seriously to achieve desired performance and uptime of the cluster. Or,\u00a0if you currently shard data across multiple MySQL instances, knowing\u00a0that Cassandra deals with sharding and replication for you might be a\u00a0huge benefit and upsell for Cassandra. But, unfortunately there is no\u00a0such thing as a free lunch. For example, although Cassandra will remove\u00a0all of your homegrown database abstraction and sharding code, you\u00a0ultimately ended simply moving that logic from your code to Cassandra.\u00a0Luckily, given the number of people and corporations of all sizes using\u00a0Cassandra in production combined with an engaged and involved\u00a0community, it\u2019s fair to assume and argue that Cassandra\u2019s equivalent of\u00a0your MySQL sharding code will be better than your old homegrown\u00a0solution.<\/p>\n\n<h2>Development Considerations<\/h2>\n<h3>Be\u00a0Thoughtful About Your Data Model<\/h3>\n<p>Creating a thoughtful and conscious data model in Cassandra from the\u00a0very beginning is very important. A bad data model can easily ruin and\u00a0erase any of the benefits you want by migrating to Cassandra in the\u00a0first place. With MySQL, the lack of a thoughtful or poor data model\u00a0can frequently be worked around and accommodated thanks to the various\u00a0relational database features (for example, the use of complex JOINS).<br\/>While these MySQL queries might be slow and expensive, given enough\u00a0time and resources it\u2019s possible to get the exact desired result from\u00a0the dataset. With Cassandra, it is much harder to retroactively \u201cfix\u201d a\u00a0poor data model. First, the lack of JOINS in Cassandra removes complex\u00a0reads as a hacked solution to a bad data model. Additionally, thanks to\u00a0the power and architecture of Cassandra, it becomes very easy to store\u00a0more rows and data than imaginable with MySQL. With increased amounts\u00a0of data stored, comes an increased complexity in successfully getting\u00a0the exact data needed within the given performance boundaries required\u00a0by your application. A SELECT query containing only 30 rows will return\u00a0quickly and predictably. Performing a query over 5 million rows\u00a0requires processing significantly more IO. Just as more data in MySQL\u00a0made complex JOINS more difficult, accommodating for a Cassandra data\u00a0model that requires the iteration over multiple nodes and rows will be\u00a0slow, inefficient, and most likely not work at all. Obviously, faster\u00a0database responses are always better in any application; so don\u2019t let\u00a0your data model be the cause of slow database latency in your\u00a0application!<\/p>\n<h3>Denormalization<\/h3>\n<p>Denormalization is the concept that a data model should be designed so\u00a0that a given query can be served from the results from one row and\u00a0query. Instead of doing multiple reads from multiple tables and rows to\u00a0gather all the required data for a response, instead modify your\u00a0application logic to insert the required data multiple times into every\u00a0row that might need it in the future. This way, all required data can\u00a0be available in just one read which prevents multiple lookups.<\/p>\n\n<h2>Operational Considerations<\/h2>\n<h3>Optimization\u00a0and Tuning Cassandra<\/h3>\n<p>There are lots of options to tweak in Cassandra. Much like turning the\u00a0treble, bass, and volume nobs of your car\u2019s sound system all to 11\u00a0won\u2019t sound very good to your ears, it\u2019s easy to do more harm than good\u00a0when \u201coptimizing\u201d Cassandra and it\u2019s many nobs and dials.<\/p>\n<p>Options such as\u00a0key cache\u00a0and\u00a0row cache\u00a0are two great examples. In\u00a0a MySQL world, much of the configuration tuning is spent on optimizing\u00a0the various amounts of cache allocated. In the Cassandra world, these\u00a0settings actually tend to decrease node and cluster stability.\u00a0Cassandra is written in Java, and thus it must operate within the\u00a0limitations of Java. One of the biggest considerations is\u00a0Garbage Collection\u00a0and the maximum\u00a0size of the heap possible without running into large garbage collection\u00a0related issues, which will crater the performance of Cassandra. As of\u00a0JDK7 with CMS (the default in Cassandra 1.2.x and 2.0.x) the maximum\u00a0recommended size of the heap is 8GB. This 8GB must be shared between\u00a0all of the various Cassandra components. 2GB allocated to the key cache\u00a0will (obviously) put another 2GB of pressure on the heap. Caches are an\u00a0optimization not a requirement, so allocating more memory to caches\u00a0should be considered as part of the big picture. If you can allocate\u00a0the full 8GB to Cassandra, a suggestion would be to start with\u00a0allocating no more than 768MB to the key cache (key_cache_size_in_mb)\u00a0and 0MB to the row cache (row_cache_size_in_mb).<\/p>\n<p>Another example is multithreaded_compaction. While this might seem like\u00a0an obvious option to enable, in most cases leaving this option disabled\u00a0can actually improve overall cluster stability and performance. In many\u00a0cases, less is more.<\/p>\n\n<h2>Migration Plan Considerations<\/h2>\n<h3>Maintaining Data Integrity<\/h3>\n<p>Sometimes the most difficult component of a migration is not in writing\u00a0a set of reliable scripts to read from MySQL and insert into Cassandra,\u00a0but trivial coding mistakes that can cause significant data\u00a0discrepancies between the MySQL and Cassandra versions of the data.<\/p>\n<p>Because migrating from MySQL to Cassandra will most likely require a\u00a0change in your data model, the logic required to \u201cconvert\u201d your\u00a0relational MySQL data to it\u2019s de-normalized form is the hardest part of\u00a0the migration and certainly has the biggest risk.<\/p>\n<p>Treat your migration scripts and logic not as one-off instances, but\u00a0production quality code that can be run in any order, at any time.\u00a0Mistakes in migration logic that result in an inconsistent version of\u00a0the migrated data in Cassandra most likely will have a much greater\u00a0impact than other dataset migration related bugs.<\/p>\n<h3>Get to Know Bulk Loading<\/h3>\n<p>Regardless of your migration strategy, in almost all cases you will\u00a0have to perform an initial bulk import of your existing MySQL data into\u00a0Cassandra. While it might be tempting to simply iterate over every\u00a0MySQL result and then insert that result one mutation at a time into\u00a0Cassandra, a more efficient way is to use the\u00a0Cassandra Bulk Loader. At a high\u00a0level, the Bulk Loader requires you to create a CSV file containing all\u00a0of the rows and columns that need to be loaded into Cassandra. Using\u00a0the Java class\u00a0SSTableSimpleUnsortedWriter,\u00a0you can create an SSTable from your CSV file, which can then be loaded\u00a0directly into Cassandra using\u00a0SSTableloader.<\/p>\n<p>For more details and code samples reference the article at\u00a0<a href=\"http:\/\/www.datastax.com\/dev\/blog\/bulk-loading\">http:\/\/www.datastax.com\/dev\/blog\/bulk-loading<\/a><\/p>\n\n<h3>Migration Methods<\/h3>\n<p>Sync Data Method:<br\/>When migrating to Cassandra and choosing a new data model might\u00a0significantly increase your database workload. Alternatively, you might\u00a0still need a live dataset in MySQL after the initial migration for\u00a0legacy scripts that have not yet been migrated to use Cassandra.<\/p>\n<p>Syncing from MySQL\u00a0to Cassandra<br\/>In some cases it might not be practicable to add Cassandra to a legacy\u00a0application. In this case it might be necessary to have an external\u00a0process sync data from MySQL to Cassandra while running both new and\u00a0old logic in parallel.<\/p>\n<p>Suggestion:<br\/>Add a\u00a0timestamp column to the MySQL table to be synced. With each update to\u00a0MySQL also update the timestamp with the last updated time. At a\u00a0scheduled interval then do a SELECT query from all MySQL shards where\u00a0the last updated timestamp is greater than or equal to the time your\u00a0last sync started.<\/p>\n<p>Syncing from\u00a0Cassandra back to MySQL<br\/>Some data models will be hard to sync from Cassandra back to MySQL (for\u00a0example time series data). However, rows containing more de-normalized<br\/>\u201cmetadata\u201d-like information can be synced.<\/p>\n<p>What won\u2019t work: Creating a sync script that executes via cron every n\u00a0minutes and attempts to do a SELECT * FROM TABLE from Cassandra (and<br\/>then update and insert all of those records into MySQL) is a recipe for\u00a0failure. Inherent to Cassandra\u2019s design is that data is sharded across\u00a0multiple nodes by a hash of it\u2019s key. Performing a SELECT * query is a\u00a0Cassandra anti-pattern and should be avoided. Iterating through every\u00a0key across all nodes and returning a single paged dataset is both\u00a0inefficient and impractical.<\/p>\n<p>1st Suggestion:<br\/>Implement a queue that your application additionally writes to when it\u00a0modifies a row in Cassandra. Have a script consume from this queue and\u00a0de-duplicate the modified keys on a time interval and then bulk insert\u00a0updates into MySQL.<\/p>\n<p>2nd Suggestion:<br\/>If the\u00a0data can be updated less frequently into MySQL, you could write a\u00a0Hadoop Map\/Reduce job that iterates over the column families that you\u00a0need to sync. This solution gives a practicable and reproducible way to\u00a0iterate through all keys in a column family. Using this approach as an\u00a0additional sanity option to resolve missed updates from other\u00a0incremental sync options.<\/p>\n<p>3rd Suggestion:<br\/>Another option if you can afford a greater delay in the delta between\u00a0updates from Cassandra back to MySQL is to use a tool such as\u00a0SSTable2JSON\u00a0to dump a column\u00a0families SSTables into a JSON format, which can then be parsed and then\u00a0used to update MySQL. This is a pretty heavy-handed method.\u00a0Additionally, you\u2019ll have to write logic to ensure you dump the\u00a0SSTables from all nodes to get the entire column family.<\/p>\n<p>Write Twice and Forget Method:<br\/>If you are able to modify your existing application to also interface\u00a0with Cassandra, you can initially start your migration by writing\u00a0database updates twice, once to MySQL and an additional time to\u00a0Cassandra. Once you have all new updates being written to both MySQL\u00a0and Cassandra, you can run a migration script that pages through all\u00a0your existing MySQL data and inserts those records into Cassandra.<\/p>\n<p>Initially, you might want to implement this second write to Cassandra\u00a0as a completely non-blocking, write and forget, operation. If you\u00a0experience initial issues during your Cassandra deployment, make sure\u00a0not to impact your existing application when Cassandra is down.<\/p>\n<p>Once you are satisfied with the fire-and-forget writes, you can slowly\u00a0modify your application logic to start performing reads from Cassandra\u00a0instead of MySQL. Thanks to the dual writes, if you run into issues,\u00a0simply revert back to doing reads from MySQL.<\/p>\n<h2>Use Cases and Migration Resources<\/h2>\n<h3>Use Cases<\/h3>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/youve-got-scale-aol-migrates-from-mysql-to-apache-cassandra-for-8x-improvement\/\">AOL<\/a><br\/>AOL migrated their\u00a0article index, in use for several AOL technologies form MySQL. The result was an 8X increase in writes, and considering the move to Cassandra as a \u201cbig win\u201d.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/interview\/coursera-migrates-to-the-top-of-the-class-moves-to-cassandra-for-an-always-on-on-demand-classroom\/\">Coursera<\/a><\/p>\n<p>Coursera was experiencing unexpected downtime, due to the RDBMS\u2019 single point of failure. \u00a0In addition, Cassandra has enabled Coursera to become more dynamic; introducing their over 9 million users to an always available, on-demand course system.<\/p>\n<p><a href=\"http:\/\/www.datastax.com\/wp-content\/uploads\/2011\/06\/DataStax-CaseStudy-Mahalo.pdf\">Mahalo<\/a><br\/>Mahalo\u2019s search technology was forced to move off of MySQL to Cassandra as their primary data store in order to realize lower costs and higher performance and scalability.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/scaling-in-the-cloud-with-cassandra-at-pantheon\">Pantheon Systems<\/a><br\/>Pantheon Systems, offering a platform for Drupal websites in the cloud, migrated to Cassandra primarily for greater scalability and ease of use.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/scoopit-turns-to-apache-cassandra-the-latest-and-best-technology-when-mysql-fails-to-keep-up\">Scoop.it<\/a><br\/>Scoop.it\u2019s content curation publishing platform experienced the limitations of MySQL for handling their data growth and moved to Apache Cassandra for scalability and requirement of no downtime.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/ampushs-migration-from-mysql-to-cassandra-for-data-volume-high-availability-and-performance\">Ampush<\/a><br\/>Ampush\u2019s migration from MySQL to Cassandra due to their increase in data volume, high availability and performance requirements which only Cassandra could satisfy.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/barracuda-networks-and-cassandra---battling-the-zombies\">Barracuda Networks<\/a><br\/>Barracudna Networks were not able to monitor customer threats in real-time with MySQL and went to Cassandra for the scalability and availability benefits.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/cassandra-summit-2013-cabs-cassandra-and-hailo-mysql-to-cassandra-by-dave-gardner\">Hailo<\/a><br\/>Hailo has leveraged Cassandra to build one of the most successful startups in European history. This presentation looks at how Hailo grew from a simple MySQL-backed infrastructure to a resilient Cassandra-backed system running in three data centers globally.<\/p>\n<p><a href=\"http:\/\/www.datastax.com\/wp-content\/uploads\/2011\/04\/DataStax-CS-Ooyala.pdf\">Ooyala<\/a><br\/>Ooyala chose Apache Cassandra for its elastic scalability and high performance \u2013 especially when their MySQL environment was not meeting customer service levels \u2013 to help their customers take a more strategic approach when delivering a digital video experience.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/appssavvy-fixes-mysql-scalability-by-switching-to-apache-cassandra\">AppsSavvy<\/a><br\/>AppsSavvy\u2019s targeted advertising delivery solution moved from MySQL to Cassandra for increased scalability and performance under load.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/dating-site-zoosk-breaks-up-with-mysql-migrates-to-apache-cassandra-for-persistent-notifications\">Zoosk<\/a><br\/>Zoosk\u2019s persistent notification system was moved off of MySQL and onto Apache Cassandra because it is a superior database for their high volume of writes of time series data.<\/p>\n<p><a href=\"http:\/\/planetcassandra.org\/blog\/post\/agentis-energy-stores-over-15-billion-records-of-time-series-usage-data-in-apache-cassandra\">Agentis<\/a><br\/>Agentis Energy had to move to Cassandra once the scale of their data became unmanageable on MySQL as they now store over 15 billion records of time series usage energy usage data.<\/p>\n<h3>Migration Resources<\/h3>\n<p>Whitepaper:\u00a0<a href=\"http:\/\/www.datastax.com\/wp-content\/uploads\/2012\/08\/WP-DataStax-MySQLtoCassandra.pdf\">Why Migrate From MySQL to Cassandra?<\/a>\u00a0By Robin Schumacher<br\/>This whitepaper discusses the \u2018why\u2019 and \u2018how\u2019 to migrate from MySQL to Cassandra as well as what a good migration candidate looks like.<\/p>\n<p>Hindsight is 20\/20:\u00a0<a href=\"http:\/\/www.youtube.com\/watch?v=gW4jEOKRB04\" target=\"_blank\">MySQL to Cassandra<\/a>. This webinar offers a\u00a0brief intro to how Barracuda Networks uses Cassandra and the ways in which they are replacing their MySQL infrastructure, with Cassandra including lessons learned. A slideshare from this presentation is available as well:\u00a0<a href=\"http:\/\/www.slideshare.net\/planetcassandra\/c-summit-2013-hindsight-is-2020-mysql-to-cassandra-by-michael-kjellman\">Hindsight is 20\/20: MySQL to Cassandra<\/a><\/p>\n<p>5 lessons learned by Zoosk for\u00a0<a href=\"https:\/\/about.zoosk.com\/en\/engineering-blog\/moving-persistent-notifications-from-mysql-to-cassandra\/\" target=\"_blank\">moving persistent notifications from MySQL to Apache Cassandra<\/a>\u00a0in order to support very high volumes of write while minimizing write latency.<\/p>\n\n<h3>About the Author<\/h3>\n<p>Michael Kjellman is a San Francisco based Software Engineer. Michael works across multiple products, technologies, and languages. He primarily works on Barracuda\u2019s spam infrastructure and web filter classification data. Follow him on Twitter at<a href=\"https:\/\/twitter.com\/mkjellman\">@mkjellman<\/a>.<\/p>","created_at":"2017-10-31T20:25:15+0000","updated_at":"2017-10-31T20:32:31+0000","annotations":[],"mimetype":"text\/html","language":"","reading_time":16,"domain_name":"academy.datastax.com","preview_picture":"https:\/\/academy.datastax.com\/sites\/default\/files\/keyterms-1.png","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4910"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4909,"title":"datastax\/java-driver","url":"https:\/\/github.com\/datastax\/java-driver","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p><a href=\"https:\/\/travis-ci.org\/datastax\/java-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/8c0a0df4c133ce530d31b6639c743655b23f2fd2\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f6a6176612d6472697665722e7376673f6272616e63683d332e78\" alt=\"Build Status\" data-canonical-src=\"https:\/\/travis-ci.org\/datastax\/java-driver.svg?branch=3.x\"\/><\/a><\/p>\n<p><em>If you're reading this on github.com, please note that this is the readme\nfor the development version and that some features described here might\nnot yet have been released. You can find the documentation for latest\nversion through <a href=\"http:\/\/datastax.github.io\/java-driver\/\">Java driver\ndocs<\/a> or via the release tags,\n<a href=\"https:\/\/github.com\/datastax\/java-driver\/tree\/3.3.0\">e.g.\n3.3.0<\/a>.<\/em><\/p>\n<p>A modern, <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\">feature-rich<\/a> and highly tunable Java client\nlibrary for Apache Cassandra (1.2+) and DataStax Enterprise (3.1+) using\nexclusively Cassandra's binary protocol and Cassandra Query Language v3.<\/p>\n<p><strong>Features:<\/strong><\/p>\n<ul><li><a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\">Sync<\/a> and <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/async\">Async<\/a> API<\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/statements\/simple\">Simple<\/a>, <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/statements\/prepared\">Prepared<\/a>, and <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/statements\/batch\">Batch<\/a>\nstatements<\/li>\n<li>Asynchronous IO, parallel execution, request pipelining<\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/pooling\">Connection pooling<\/a><\/li>\n<li>Auto node discovery<\/li>\n<li>Automatic reconnection<\/li>\n<li>Configurable <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/load_balancing\">load balancing<\/a> and <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/retries\">retry policies<\/a><\/li>\n<li>Works with any cluster size<\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/statements\/built\">Query builder<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/object_mapper\">Object mapper<\/a><\/li>\n<\/ul><p>The driver architecture is based on layers. At the bottom lies the driver core.\nThis core handles everything related to the connections to a Cassandra\ncluster (for example, connection pool, discovering new nodes, etc.) and exposes a simple,\nrelatively low-level API on top of which higher level layers can be built.<\/p>\n<p>The driver contains the following modules:<\/p>\n<ul><li>driver-core: the core layer.<\/li>\n<li>driver-mapping: the object mapper.<\/li>\n<li>driver-extras: optional features for the Java driver.<\/li>\n<li>driver-examples: example applications using the other modules which are\nonly meant for demonstration purposes.<\/li>\n<li>driver-tests: tests for the java-driver.<\/li>\n<\/ul><p><strong>Useful links:<\/strong><\/p>\n<ul><li>JIRA (bug tracking): <a href=\"https:\/\/datastax-oss.atlassian.net\/browse\/JAVA\">https:\/\/datastax-oss.atlassian.net\/browse\/JAVA<\/a><\/li>\n<li>MAILING LIST: <a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/java-driver-user\">https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/java-driver-user<\/a><\/li>\n<li>IRC: #datastax-drivers on <a href=\"http:\/\/freenode.net\">irc.freenode.net<\/a><\/li>\n<li>TWITTER: <a href=\"https:\/\/twitter.com\/dsJavaDriver\">@dsJavaDriver<\/a> tweets Java\ndriver releases and important announcements (low frequency).\n<a href=\"https:\/\/twitter.com\/datastaxeng\">@DataStaxEng<\/a> has more news including\nother drivers, Cassandra, and DSE.<\/li>\n<li>DOCS: the <a href=\"http:\/\/docs.datastax.com\/en\/developer\/java-driver\/3.2\/manual\/\">manual<\/a> has quick\nstart material and technical details about the driver and its features.<\/li>\n<li>API: <a href=\"http:\/\/www.datastax.com\/drivers\/java\/3.2\">http:\/\/www.datastax.com\/drivers\/java\/3.2<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/changelog\">changelog<\/a><\/li>\n<li><a href=\"http:\/\/downloads.datastax.com\/java-driver\/cassandra-java-driver-3.3.0.tar.gz\">binary tarball<\/a><\/li>\n<\/ul><p><strong>Feeback requested:<\/strong> help us focus our efforts, provide your input on the <a href=\"http:\/\/goo.gl\/forms\/qwUE6qnL7U\">Platform and Runtime Survey<\/a> (we kept it short).<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/java-driver#getting-the-driver\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-the-driver\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting the driver<\/h2>\n<p>The last release of the driver is available on Maven Central. You can install\nit in your application using the following Maven dependency:<\/p>\n<div class=\"highlight highlight-text-xml\"><pre>&lt;dependency&gt;\n  &lt;groupId&gt;com.datastax.cassandra&lt;\/groupId&gt;\n  &lt;artifactId&gt;cassandra-driver-core&lt;\/artifactId&gt;\n  &lt;version&gt;3.3.0&lt;\/version&gt;\n&lt;\/dependency&gt;<\/pre><\/div>\n<p>Note that the object mapper is published as a separate artifact:<\/p>\n<div class=\"highlight highlight-text-xml\"><pre>&lt;dependency&gt;\n  &lt;groupId&gt;com.datastax.cassandra&lt;\/groupId&gt;\n  &lt;artifactId&gt;cassandra-driver-mapping&lt;\/artifactId&gt;\n  &lt;version&gt;3.3.0&lt;\/version&gt;\n&lt;\/dependency&gt;<\/pre><\/div>\n<p>The 'extras' module is also published as a separate artifact:<\/p>\n<div class=\"highlight highlight-text-xml\"><pre>&lt;dependency&gt;\n  &lt;groupId&gt;com.datastax.cassandra&lt;\/groupId&gt;\n  &lt;artifactId&gt;cassandra-driver-extras&lt;\/artifactId&gt;\n  &lt;version&gt;3.3.0&lt;\/version&gt;\n&lt;\/dependency&gt;<\/pre><\/div>\n<p>We also provide a <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/manual\/shaded_jar\">shaded JAR<\/a>\nto avoid the explicit dependency to Netty.<\/p>\n<p>If you can't use a dependency management tool, a\n<a href=\"http:\/\/downloads.datastax.com\/java-driver\/cassandra-java-driver-3.3.0.tar.gz\">binary tarball<\/a>\nis available for download.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/java-driver#compatibility\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-compatibility\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Compatibility<\/h2>\n<p>The Java client driver 3.3.0 (<a href=\"https:\/\/github.com\/datastax\/java-driver\/tree\/3.x\">branch 3.x<\/a>) is compatible with Apache\nCassandra 1.2, 2.0, 2.1, 2.2 and 3.0 (see <a href=\"http:\/\/datastax.github.io\/java-driver\/manual\/native_protocol\">this page<\/a> for\nthe most up-to-date compatibility information).<\/p>\n<p>UDT and tuple support is available only when using Apache Cassandra 2.1 or higher (see <a href=\"http:\/\/www.datastax.com\/dev\/blog\/cql-in-2-1\">CQL improvements in Cassandra 2.1<\/a>).<\/p>\n<p>Other features are available only when using Apache Cassandra 2.0 or higher (e.g. result set paging,\n<a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/driver-core\/src\/main\/java\/com\/datastax\/driver\/core\/BatchStatement.java\">BatchStatement<\/a>,\n<a href=\"http:\/\/www.datastax.com\/documentation\/cql\/3.1\/cql\/cql_using\/use_ltweight_transaction_t.html\">lightweight transactions<\/a>\n-- see <a href=\"http:\/\/www.datastax.com\/documentation\/cassandra\/2.0\/cassandra\/features\/features_key_c.html\">What's new in Cassandra 2.0<\/a>).\nTrying to use these with a cluster running Cassandra 1.2 will result in\nan <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/driver-core\/src\/main\/java\/com\/datastax\/driver\/core\/exceptions\/UnsupportedFeatureException.java\">UnsupportedFeatureException<\/a> being thrown.<\/p>\n<p><strong>Note<\/strong>: DataStax products do not support big-endian systems.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/java-driver#upgrading-from-previous-versions\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-upgrading-from-previous-versions\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Upgrading from previous versions<\/h2>\n<p>If you are upgrading from a previous version of the driver, be sure to have a look at\nthe <a href=\"https:\/\/github.com\/datastax\/java-driver\/blob\/3.x\/upgrade_guide\">upgrade guide<\/a>.<\/p>\n<h3><a href=\"https:\/\/github.com\/datastax\/java-driver#troubleshooting\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-troubleshooting\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Troubleshooting<\/h3>\n<p>If you are having issues connecting to the cluster (seeing <code>NoHostAvailableConnection<\/code> exceptions) please check the\n<a href=\"https:\/\/github.com\/datastax\/java-driver\/wiki\/Connection-requirements\">connection requirements<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/java-driver#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright 2012-2015, DataStax<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:25:20+0000","updated_at":"2017-10-31T20:32:30+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":3,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/8c0a0df4c133ce530d31b6639c743655b23f2fd2\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f6a6176612d6472697665722e7376673f6272616e63683d332e78","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4909"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4908,"title":"datastax\/cpp-driver \u00b7 GitHub","url":"https:\/\/github.com\/datastax\/cpp-driver","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p><a href=\"https:\/\/travis-ci.org\/datastax\/cpp-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/57fca1f7ce88e7a0e7110393ac2ef16d0304a6e9\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f6370702d6472697665722e7376673f6272616e63683d6d6173746572\" alt=\"Build Status: Linux\" data-canonical-src=\"https:\/\/travis-ci.org\/datastax\/cpp-driver.svg?branch=master\"\/><\/a>\n<a href=\"https:\/\/ci.appveyor.com\/project\/DataStax\/cpp-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/1200623e2f8525a13948f2cdb42f09cce61e386c\/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f656330783076756b35396173323872362f6272616e63682f6d61737465723f7376673d74727565\" alt=\"Build Status: Windows\" data-canonical-src=\"https:\/\/ci.appveyor.com\/api\/projects\/status\/ec0x0vuk59as28r6\/branch\/master?svg=true\"\/><\/a><\/p>\n<p>A modern, <a href=\"https:\/\/github.com\/datastax\/cpp-driver#features\">feature-rich<\/a>, and highly tunable C\/C++ client library for\nApache Cassandra (1.2+) and DataStax Enterprise (3.1+) using exclusively\nCassandra's native protocol and Cassandra Query Language v3.<\/p>\n<ul><li>Code: <a href=\"https:\/\/github.com\/datastax\/cpp-driver\">https:\/\/github.com\/datastax\/cpp-driver<\/a><\/li>\n<li>Binaries: <a href=\"http:\/\/downloads.datastax.com\/cpp-driver\/\">http:\/\/downloads.datastax.com\/cpp-driver\/<\/a><\/li>\n<li>Docs: <a href=\"http:\/\/datastax.github.io\/cpp-driver\">http:\/\/datastax.github.io\/cpp-driver<\/a><\/li>\n<li>JIRA: <a href=\"https:\/\/datastax-oss.atlassian.net\/browse\/CPP\">https:\/\/datastax-oss.atlassian.net\/browse\/CPP<\/a><\/li>\n<li>Mailing List: <a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/cpp-driver-user\">https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/cpp-driver-user<\/a><\/li>\n<li>IRC: <a href=\"http:\/\/webchat.freenode.net\/?channels=datastax-drivers\">#datastax-drivers on <code>irc.freenode.net &lt;http:\/\/freenode.net&gt;<\/code><\/a><\/li>\n<\/ul><p><strong>Note<\/strong>: DataStax products do not support big-endian systems.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#whats-new-in-2526\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-whats-new-in-2526\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>What's New in 2.5\/2.6<\/h2>\n<ul><li>Support for <a href=\"https:\/\/github.com\/datastax\/cpp-driver\/tree\/2.6.0\/examples\/duration\/duration.c\"><code>duration<\/code><\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#speculative-execution\">Speculative execution<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#query-idempotence\">Idempotent statements<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/security\/ssl\/\">SSL<\/a> can be enabled without re-initializing the underlying library (e.g. OpenSSL)<\/li>\n<\/ul><p>More information about features included in 2.3 can be found in this <a href=\"http:\/\/www.datastax.com\/dev\/blog\/datastax-c-driver-2-3-ga-released\">blog\npost<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#upgrading-from-20-or-21-to-22\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-upgrading-from-20-or-21-to-22\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Upgrading from 2.0 or 2.1 to 2.2+<\/h2>\n<p>The new schema metadata API in 2.2 required some breaking API changes.\nApplications that used the previous schema metadata API from 2.0 and 2.1 will\nrequire some small modifications to use the new API. More information about the\nnew schema metadata API can be found in this\n<a href=\"http:\/\/www.datastax.com\/dev\/blog\/datastax-c-driver-2-2-ga-released\">blog post<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#upgrading-from-10-to-20\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-upgrading-from-10-to-20\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Upgrading from 1.0 to 2.0+<\/h2>\n<p>There were a couple breaking API changes between 1.0 and 2.0 that are documented\n<a href=\"http:\/\/www.datastax.com\/dev\/blog\/datastax-c-driver-2-0-released\">here<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#features\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-features\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Features<\/h2>\n<ul><li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/#futures\">Asynchronous API<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/#executing-queries\">Simple<\/a>, <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/basics\/prepared_statements\/\">Prepared<\/a>, and <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/basics\/batches\/\">Batch<\/a> statements<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/#asynchronous-i-o\">Asynchronous I\/O<\/a>, <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/#thread-safety\">parallel execution<\/a>, and request pipelining<\/li>\n<li>Connection pooling<\/li>\n<li>Automatic node discovery<\/li>\n<li>Automatic reconnection<\/li>\n<li>Configurable <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#load-balancing\">load balancing<\/a><\/li>\n<li>Works with any cluster size<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/security\/#authentication\">Authentication<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/security\/ssl\/\">SSL<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#latency-aware-routing\">Latency-aware routing<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/metrics\/\">Performance metrics<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/basics\/tuples\/\">Tuples<\/a> and <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/basics\/user_defined_types\/\">UDTs<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/basics\/binding_parameters\/#nested-collections\">Nested collections<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/retry_policies\/\">Retry policies<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/basics\/client_side_timestamps\/\">Client-side timestamps<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/basics\/data_types\/\">Data types<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#connection-heartbeats\">Idle connection heartbeats<\/a><\/li>\n<li>Support for materialized view and secondary index metadata<\/li>\n<li>Support for clustering key order, <code>frozen&lt;&gt;<\/code> and Cassandra version metadata<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#blacklist\">Blacklist<\/a>, <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#datacenter\">whitelist DC<\/a>, and <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/configuration\/#datacenter\">blacklist DC<\/a> load balancing policies<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/security\/#custom\">Custom<\/a> authenticators<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/security\/ssl\/#enabling-cassandra-identity-verification\">Reverse DNS<\/a> with SSL peer identity verification support<\/li>\n<li>Randomized contact points<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#compatibility\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-compatibility\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Compatibility<\/h2>\n<p>This release is compatible with Apache Cassandra 1.2, 2.0, 2.1, 2.2 and 3.0.<\/p>\n<p>A complete compatibility matrix for both Apache Cassandra and DataStax\nEnterprise can be found\n<a href=\"https:\/\/docs.datastax.com\/en\/developer\/driver-matrix\/doc\/common\/driverMatrix.html?scroll=driverMatrix__cpp-driver-matrix\">here<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#installation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-installation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Installation<\/h2>\n<p>Binary packages are <a href=\"http:\/\/downloads.datastax.com\/cpp-driver\/\">available<\/a> for\nCentOS, Ubuntu and Windows. Packages for the driver's dependencies, libuv (1.x)\nand OpenSSL, are also provided under the <code>dependencies<\/code> directory for each\nplatform e.g. <a href=\"http:\/\/downloads.datastax.com\/cpp-driver\/centos\/7\/dependencies\/\">CentOS 7<\/a>,\n<a href=\"http:\/\/downloads.datastax.com\/cpp-driver\/ubuntu\/14.04\/dependencies\/\">Ubuntu 14.04<\/a>,\n<a href=\"http:\/\/downloads.datastax.com\/cpp-driver\/windows\/dependencies\/\">Windows<\/a>.<\/p>\n<p><em>Note<\/em>: CentOS and Ubuntu use the version of OpenSSL provided with the\ndistribution.<\/p>\n<p>The driver can also be <a href=\"http:\/\/datastax.github.io\/cpp-driver\/topics\/building\/\">built from\nsource<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#feedback-requested\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-feedback-requested\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Feedback Requested<\/h2>\n<p><strong>Help us focus our efforts!<\/strong> <a href=\"http:\/\/goo.gl\/forms\/ihKC5uEQr6\">Provide your input<\/a> on the C\/C++ Driver Platform and Runtime Survey (we kept it short).<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#examples\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-examples\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Examples<\/h2>\n<p>There are several examples provided here: <a href=\"https:\/\/github.com\/datastax\/cpp-driver\/tree\/1.0\/examples\">examples<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#a-simple-example\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-a-simple-example\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>A Simple Example<\/h2>\n<div class=\"highlight highlight-source-c\"><pre>#include &lt;cassandra.h&gt;\n#include &lt;stdio.h&gt;\nint main(int argc, char* argv[]) {\n  \/* Setup and connect to cluster *\/\n  CassFuture* connect_future = NULL;\n  CassCluster* cluster = cass_cluster_new();\n  CassSession* session = cass_session_new();\n  char* hosts = \"127.0.0.1\";\n  if (argc &gt; 1) {\n    hosts = argv[1];\n  }\n  \/* Add contact points *\/\n  cass_cluster_set_contact_points(cluster, hosts);\n  \/* Provide the cluster object as configuration to connect the session *\/\n  connect_future = cass_session_connect(session, cluster);\n  if (cass_future_error_code(connect_future) == CASS_OK) {\n    CassFuture* close_future = NULL;\n    \/* Build statement and execute query *\/\n    const char* query = \"SELECT release_version FROM system.local\";\n    CassStatement* statement = cass_statement_new(query, 0);\n    CassFuture* result_future = cass_session_execute(session, statement);\n    if (cass_future_error_code(result_future) == CASS_OK) {\n      \/* Retrieve result set and get the first row *\/\n      const CassResult* result = cass_future_get_result(result_future);\n      const CassRow* row = cass_result_first_row(result);\n      if (row) {\n        const CassValue* value = cass_row_get_column_by_name(row, \"release_version\");\n        const char* release_version;\n        size_t release_version_length;\n        cass_value_get_string(value, &amp;release_version, &amp;release_version_length);\n        printf(\"release_version: '%.*s'\\n\", (int)release_version_length, release_version);\n      }\n      cass_result_free(result);\n    } else {\n      \/* Handle error *\/\n      const char* message;\n      size_t message_length;\n      cass_future_error_message(result_future, &amp;message, &amp;message_length);\n      fprintf(stderr, \"Unable to run query: '%.*s'\\n\", (int)message_length, message);\n    }\n    cass_statement_free(statement);\n    cass_future_free(result_future);\n    \/* Close the session *\/\n    close_future = cass_session_close(session);\n    cass_future_wait(close_future);\n    cass_future_free(close_future);\n  } else {\n    \/* Handle error *\/\n    const char* message;\n    size_t message_length;\n    cass_future_error_message(connect_future, &amp;message, &amp;message_length);\n    fprintf(stderr, \"Unable to connect: '%.*s'\\n\", (int)message_length, message);\n  }\n  cass_future_free(connect_future);\n  cass_cluster_free(cluster);\n  cass_session_free(session);\n  return 0;\n}<\/pre><\/div>\n<h2><a href=\"https:\/\/github.com\/datastax\/cpp-driver#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright (c) 2014-2016 DataStax<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:25:24+0000","updated_at":"2017-10-31T20:32:30+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":4,"domain_name":"github.com","preview_picture":"https:\/\/avatars0.githubusercontent.com\/u\/573369?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4908"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4907,"title":"datastax\/python-driver","url":"https:\/\/github.com\/datastax\/python-driver","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.rst\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<a href=\"https:\/\/travis-ci.org\/datastax\/python-driver\"><img alt=\"https:\/\/travis-ci.org\/datastax\/python-driver.png?branch=master\" src=\"https:\/\/camo.githubusercontent.com\/f127f299b7b441d923b99ecfef34bdfc72d7fb63\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f707974686f6e2d6472697665722e706e673f6272616e63683d6d6173746572\" data-canonical-src=\"https:\/\/travis-ci.org\/datastax\/python-driver.png?branch=master\"\/><\/a>\n<p>A modern, <a href=\"https:\/\/github.com\/datastax\/python-driver#features\">feature-rich<\/a> and highly-tunable Python client library for Apache Cassandra (2.1+) using exclusively Cassandra's binary protocol and Cassandra Query Language v3.<\/p>\n<p>The driver supports Python 2.7, 3.3, 3.4, 3.5, and 3.6.<\/p>\n<p>If you require compatibility with DataStax Enterprise, use the <a href=\"http:\/\/docs.datastax.com\/en\/developer\/python-dse-driver\/\">DataStax Enterprise Python Driver<\/a>.<\/p>\n<p><strong>Note:<\/strong> DataStax products do not support big-endian systems.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#feedback-requested\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-feedback-requested\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Feedback Requested<\/h2>\n<p><strong>Help us focus our efforts!<\/strong> Provide your input on the <a href=\"https:\/\/docs.google.com\/a\/datastax.com\/forms\/d\/10wkbKLqmqs91gvhFW5u43y60pg_geZDolVNrxfO5_48\/viewform\">Platform and Runtime Survey<\/a> (we kept it short).<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#features\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-features\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Features<\/h2>\n<ul><li><a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/cluster.html#cassandra.cluster.Session.execute\">Synchronous<\/a> and <a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/cluster.html#cassandra.cluster.Session.execute_async\">Asynchronous<\/a> APIs<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/query.html#cassandra.query.Statement\">Simple, Prepared, and Batch statements<\/a><\/li>\n<li>Asynchronous IO, parallel execution, request pipelining<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/cluster.html#cassandra.cluster.Cluster.get_core_connections_per_host\">Connection pooling<\/a><\/li>\n<li>Automatic node discovery<\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/policies.html#reconnecting-to-dead-hosts\">Automatic reconnection<\/a><\/li>\n<li>Configurable <a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/policies.html#load-balancing\">load balancing<\/a> and <a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/policies.html#retrying-failed-operations\">retry policies<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/api\/cassandra\/concurrent.html\">Concurrent execution utilities<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/object_mapper.html\">Object mapper<\/a><\/li>\n<\/ul>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#installation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-installation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Installation<\/h2>\n<p>Installation through pip is recommended:<\/p>\n<pre>$ pip install cassandra-driver\n<\/pre>\n<p>For more complete installation instructions, see the\n<a href=\"http:\/\/datastax.github.io\/python-driver\/installation.html\">installation guide<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<p>The documentation can be found online <a href=\"http:\/\/datastax.github.io\/python-driver\/index.html\">here<\/a>.<\/p>\n<p>A couple of links for getting up to speed:<\/p>\n<ul><li><a href=\"http:\/\/datastax.github.io\/python-driver\/installation.html\">Installation<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/getting_started.html\">Getting started guide<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/api\/index.html\">API docs<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/python-driver\/performance.html\">Performance tips<\/a><\/li>\n<\/ul>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#object-mapper\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-object-mapper\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Object Mapper<\/h2>\n<p>cqlengine (originally developed by Blake Eggleston and Jon Haddad, with contributions from the\ncommunity) is now maintained as an integral part of this package. Refer to\n<a href=\"http:\/\/datastax.github.io\/python-driver\/object_mapper.html\">documentation here<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#contributing\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-contributing\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Contributing<\/h2>\n<p>See <a href=\"https:\/\/github.com\/datastax\/python-driver\/blob\/master\/CONTRIBUTING.rst\">CONTRIBUTING.md<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#reporting-problems\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-reporting-problems\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Reporting Problems<\/h2>\n<p>Please report any bugs and make any feature requests on the\n<a href=\"https:\/\/datastax-oss.atlassian.net\/browse\/PYTHON\">JIRA<\/a> issue tracker.<\/p>\n<p>If you would like to contribute, please feel free to open a pull request.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#getting-help\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-help\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting Help<\/h2>\n<p>Your best options for getting help with the driver are the\n<a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/python-driver-user\">mailing list<\/a>\nand the <code>#datastax-drivers<\/code> channel in the <a href=\"https:\/\/academy.datastax.com\/slack\">DataStax Academy Slack<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/python-driver#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright 2013-2017 DataStax<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:25:30+0000","updated_at":"2017-10-31T20:32:29+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":1,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/f127f299b7b441d923b99ecfef34bdfc72d7fb63\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f707974686f6e2d6472697665722e706e673f6272616e63683d6d6173746572","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4907"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4906,"title":"Datastax Ruby Driver for Apache Cassandra","url":"https:\/\/github.com\/datastax\/ruby-driver","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p><em>If you're reading this on GitHub, please note that this is the readme for the development version and that some\nfeatures described here might not yet have been released. You can view the documentation for the latest released\nversion <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/latest\">here<\/a>.<\/em><\/p>\n<p><a href=\"https:\/\/travis-ci.org\/datastax\/ruby-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/5f27a8ea4298c2484f420bd170bd7a41f65bc570\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f727562792d6472697665722e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https:\/\/travis-ci.org\/datastax\/ruby-driver.svg?branch=master\"\/><\/a><\/p>\n<p>A Ruby client driver for Apache Cassandra. This driver works exclusively with\nthe Cassandra Query Language version 3 (CQL3) and Cassandra's native protocol.<\/p>\n<p>Use the <a href=\"https:\/\/github.com\/datastax\/ruby-dse-driver.git\">Ruby DSE driver<\/a> for\nbetter compatibility and support for DataStax Enterprise.<\/p>\n<ul><li>Code: <a href=\"https:\/\/github.com\/datastax\/ruby-driver\">https:\/\/github.com\/datastax\/ruby-driver<\/a><\/li>\n<li>Docs: <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\">http:\/\/docs.datastax.com\/en\/developer\/ruby-driver<\/a><\/li>\n<li>Jira: <a href=\"https:\/\/datastax-oss.atlassian.net\/browse\/RUBY\">https:\/\/datastax-oss.atlassian.net\/browse\/RUBY<\/a><\/li>\n<li>Mailing List: <a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/ruby-driver-user\">https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/ruby-driver-user<\/a><\/li>\n<li>Slack: <code>#datastax-drivers<\/code> channel at <a href=\"https:\/\/academy.datastax.com\/slack\">https:\/\/academy.datastax.com\/slack<\/a><\/li>\n<li>Twitter: Follow the latest news about DataStax Drivers - <a href=\"http:\/\/twitter.com\/stamhankar999\">@stamhankar999<\/a>, <a href=\"http:\/\/twitter.com\/avalanche123\">@avalanche123<\/a>, <a href=\"https:\/\/twitter.com\/al3xandru\">@al3xandru<\/a><\/li>\n<\/ul><p>This driver is based on <a href=\"https:\/\/github.com\/iconara\/cql-rb\">the cql-rb gem<\/a> by <a href=\"https:\/\/github.com\/iconara\">Theo Hultberg<\/a> and we added support for:<\/p>\n<ul><li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/asynchronous_io\/\">Asynchronous execution<\/a><\/li>\n<li>One-off, <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/basics\/prepared_statements\/\">prepared<\/a> and <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/basics\/batch_statements\/\">batch statements<\/a><\/li>\n<li>Automatic peer discovery and cluster metadata with <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/state_listeners\/\">support for change notifications<\/a><\/li>\n<li>Various <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/load_balancing\/\">load-balancing<\/a>, <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/retry_policies\/\">retry<\/a> and <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/reconnection\/\">reconnection<\/a> policies with <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/load_balancing\/implementing_a_policy\/\">ability to write your own<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/security\/ssl_encryption\/\">SSL encryption<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/error_handling\/\">Flexible and robust error handling<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/debugging\/\">Per-request execution information and tracing<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/address_resolution\/\">Configurable address resolution<\/a><\/li>\n<\/ul><p><a href=\"https:\/\/speakerdeck.com\/avalanche123\/ruby-driver-explained\">Check out the slides from Ruby Driver Explained<\/a> for a detailed overview of the Ruby Driver architecture.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#compatibility\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-compatibility\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Compatibility<\/h2>\n<p>This driver works exclusively with the Cassandra Query Language v3 (CQL3) and Cassandra's native protocol. The current version works with:<\/p>\n<ul><li>Apache Cassandra versions 2.1, 2.2, and 3.x<\/li>\n<li>DataStax Enterprise 4.8 and above. However, the <a href=\"https:\/\/github.com\/datastax\/ruby-dse-driver.git\">Ruby DSE driver<\/a> provides more features and is recommended for use with DataStax Enterprise.<\/li>\n<li>Ruby (MRI) 2.2, 2.3, 2.4<\/li>\n<li>JRuby 1.7, 9k<\/li>\n<\/ul><p><strong>Note<\/strong>: Rubinius is not supported. MRI 2.0, and 2.1 are not officially supported, but they should work. MRI 1.9.3 is deprecated\nand may break in any release after 3.0.<\/p>\n<p><strong>Note<\/strong>: Big-endian systems are not supported.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#feedback-requested\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-feedback-requested\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Feedback Requested<\/h2>\n<p><em>Help us focus our efforts!<\/em> <a href=\"http:\/\/goo.gl\/forms\/pCs8PTpHLf\">Provide your input<\/a> on the Ruby Driver Platform and Runtime Survey (we kept it short).<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#quick-start\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-quick-start\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Quick start<\/h2>\n<div class=\"highlight highlight-source-ruby\"><pre>require 'cassandra'\ncluster = Cassandra.cluster # connects to localhost by default\ncluster.each_host do |host| # automatically discovers all peers\n  puts \"Host #{host.ip}: id=#{host.id} datacenter=#{host.datacenter} rack=#{host.rack}\"\nend\nkeyspace = 'system_schema'\nsession  = cluster.connect(keyspace) # create session, optionally scoped to a keyspace, to execute queries\nfuture = session.execute_async('SELECT keyspace_name, table_name FROM tables') # fully asynchronous api\nfuture.on_success do |rows|\n  rows.each do |row|\n    puts \"The keyspace #{row['keyspace_name']} has a table called #{row['table_name']}\"\n  end\nend\nfuture.join<\/pre><\/div>\n<p><strong>Note<\/strong>: The host you specify is just a seed node, the driver will automatically discover all peers in the cluster.<\/p>\n<p>Read more:<\/p>\n<ul><li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/api\/cassandra\/#cluster-class_method\"><code>Cassandra.cluster<\/code> options<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/api\/cassandra\/session\/#execute_async-instance_method\"><code>Session#execute_async<\/code> options<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\">Usage documentation<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#installation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-installation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Installation<\/h2>\n<p>Install via rubygems<\/p>\n<div class=\"highlight highlight-source-shell\"><pre>gem install cassandra-driver<\/pre><\/div>\n<p>Install via Gemfile<\/p>\n<div class=\"highlight highlight-source-ruby\"><pre>gem 'cassandra-driver'<\/pre><\/div>\n<p><strong>Note<\/strong>: if you want to use compression you should also install <a href=\"http:\/\/rubygems.org\/gems\/snappy\">snappy<\/a> or <a href=\"http:\/\/rubygems.org\/gems\/lz4-ruby\">lz4-ruby<\/a>. <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/#compression\">Read more about compression.<\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#upgrading-from-cql-rb\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-upgrading-from-cql-rb\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Upgrading from cql-rb<\/h2>\n<p>Some of the new features added to the driver have unfortunately led to changes in the original cql-rb API.\nIn the examples directory, you can find <a href=\"https:\/\/github.com\/datastax\/ruby-driver\/blob\/master\/examples\/cql-rb-wrapper.rb\">an example of how to wrap the ruby driver to achieve almost complete\ninterface parity with cql-rb<\/a>\nto assist you with gradual upgrade.<\/p>\n<p>If you are upgrading to DataStax Enterprise, use the <a href=\"https:\/\/github.com\/datastax\/ruby-dse-driver.git\">Ruby DSE driver<\/a>\nfor more features and better compatibility.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#whats-new-in-v32\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-whats-new-in-v32\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>What's new in v3.2<\/h2>\n<p>This minor release adds support for MRI 2.4.x and also contains a few miscellaneous defect fixes.<\/p>\n<p>See the <a href=\"https:\/\/github.com\/datastax\/ruby-driver\/blob\/master\/CHANGELOG.md\">changelog<\/a> for more information on all\nchanges in this version and past versions.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#whats-new-in-v31\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-whats-new-in-v31\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>What's new in v3.1<\/h2>\n<p>This minor release introduces features and fixes around resiliency, schema metadata, usability, and performance. One\nof the most user-impacting of these is the introduction of\n<a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.1\/features\/basics\/execution_profiles\">execution profiles<\/a>.\nExecution profiles allow you to group various execution options into a 'profile' and you reference the desired\nprofile at execution time. Get the scoop\n<a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.1\/features\/basics\/execution_profiles\">here<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#whats-new-in-v30\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-whats-new-in-v30\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>What's new in v3.0<\/h2>\n<h3><a href=\"https:\/\/github.com\/datastax\/ruby-driver#features\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-features\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Features:<\/h3>\n<ul><li>Add support for Apache Cassandra native protocol v4<\/li>\n<li>Add support for smallint, tinyint, date (<code>Cassandra::Date<\/code>) and time (<code>Cassandra::Time<\/code>) data types.<\/li>\n<li>Include schema metadata for User Defined Functions and User Defined Aggregates.<\/li>\n<li>Augment the <code>Cassandra::Table<\/code> object to expose many more attributes: <code>id<\/code>, <code>options<\/code>, <code>keyspace<\/code>, <code>partition_key<\/code>, <code>clustering_columns<\/code>, and <code>clustering_order<\/code>. This makes it significantly easier to write administration scripts that report various attributes of your schema, which may help to highlight areas for improvement.<\/li>\n<li>Include client ip addresses in request traces, only on Cassandra 3.x.<\/li>\n<li>Add new retry policy decision <code>Cassandra::Retry::Policy#try_next_host<\/code>.<\/li>\n<li>Support specifying statement idempotence with the new <code>idempotent<\/code> option when executing.<\/li>\n<li>Support sending custom payloads when preparing or executing statements using the new <code>payload<\/code> option.<\/li>\n<li>Expose custom payloads received with responses on server exceptions and <code>Cassandra::Execution::Info<\/code> instances.<\/li>\n<li>Expose server warnings on server exceptions and <code>Cassandra::Execution::Info<\/code> instances.<\/li>\n<li>Add <code>connections_per_local_node<\/code>, <code>connections_per_remote_node<\/code>, <code>requests_per_connection<\/code> cluster configuration options to tune parallel query execution and resource usage.<\/li>\n<li>Add <code>Cassandra::Logger<\/code> class to make it easy for users to enable debug logging in the client.<\/li>\n<li>Add <code>protocol_version<\/code> configuration option to allow the user to force the protocol version to use for communication with nodes.<\/li>\n<li>Add support for materialized views and indexes in the schema metadata.<\/li>\n<li>Support the <code>ReadError<\/code>, <code>WriteError<\/code>, and <code>FunctionCallError<\/code> Cassandra error responses introduced in Cassandra 2.2.<\/li>\n<li>Add support for unset variables in bound statements.<\/li>\n<li>Support DSE security (<code>DseAuthenticator<\/code>, configured for LDAP).<\/li>\n<li>Add a timeout option to <code>Cassandra::Future#get<\/code>.<\/li>\n<\/ul><h3><a href=\"https:\/\/github.com\/datastax\/ruby-driver#breaking-changes-from-2x\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-breaking-changes-from-2x\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Breaking Changes from 2.x:<\/h3>\n<ul><li><code>Cassandra::Future#join<\/code> is now an alias to Cassandra::Future#get and will raise an error if the future is resolved with one.<\/li>\n<li>Default consistency level is now LOCAL_ONE.<\/li>\n<li>Enable tcp no-delay by default.<\/li>\n<li>Unavailable errors are retried on the next host in the load balancing plan by default.<\/li>\n<li>Statement execution no longer retried on timeouts, unless the statement is marked as idempotent in the call to <code>Cassandra::Session#execute*<\/code> or when creating a <code>Cassandra::Statement<\/code> object.<\/li>\n<li><code>Cassandra::Statements::Batch#add<\/code> and <code>Cassandra::Session#execute*<\/code> signatures have changed in how one specifies query parameters. Specify the query parameters array as the value of the arguments key:<\/li>\n<\/ul><div class=\"highlight highlight-source-ruby\"><pre>batch.add(query, ['val1', 'val2'])\n# becomes\nbatch.add(query, arguments: ['val1', 'val2'])\nbatch.add(query, {p1: 'val1'})\n# becomes\nbatch.add(query, arguments: {p1: 'val1'})<\/pre><\/div>\n<ul><li>The Datacenter-aware load balancing policy (<code>Cassandra::LoadBalancing::Policies::DCAwareRoundRobin<\/code>) defaults to using\nnodes in the local DC only. In prior releases, the policy would fall back to remote nodes after exhausting local nodes.\nSpecify a positive value (or nil for unlimited) for <code>max_remote_hosts_to_use<\/code> when initializing the policy to allow remote node use.<\/li>\n<li>Unspecified variables in statements previously resulted in an exception. Now they are essentially ignored or treated as null.<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#code-examples\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-code-examples\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Code examples<\/h2>\n<p>The DataStax Ruby Driver uses the awesome <a href=\"http:\/\/cukes.info\/\">Cucumber Framework<\/a> for\nboth end-to-end, or acceptance, testing and constructing documentation. All of the\nfeatures supported by the driver have appropriate acceptance tests with easy-to-copy code\nexamples in the <code>features\/<\/code> directory.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#running-tests\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-running-tests\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Running tests<\/h2>\n<p>If you don't feel like reading through the following instructions on how to run\nruby-driver tests, feel free to <a href=\"https:\/\/github.com\/datastax\/ruby-driver\/blob\/master\/.travis.yml\">check out .travis.yml for the entire build code<\/a>.<\/p>\n<ul><li>Check out the driver codebase and install test dependencies:<\/li>\n<\/ul><div class=\"highlight highlight-source-shell\"><pre>git clone https:\/\/github.com\/datastax\/ruby-driver.git\ncd ruby-driver\nbundle install --without docs<\/pre><\/div>\n<ul><li>\n<p><a href=\"http:\/\/www.datastax.com\/dev\/blog\/ccm-a-development-tool-for-creating-local-cassandra-clusters\">Install ccm<\/a><\/p>\n<\/li>\n<li>\n<p>Run tests against different versions of Cassandra:<\/p>\n<\/li>\n<\/ul><div class=\"highlight highlight-source-shell\"><pre>CASSANDRA_VERSION=3.1.1 bundle exec cucumber # runs end-to-end tests (or bundle exec rake cucumber)\nCASSANDRA_VERSION=3.0.0 bundle exec rspec # runs unit tests (or bundle exec rake rspec)\nCASSANDRA_VERSION=2.1.12 bundle exec rake integration # run integration tests\nCASSANDRA_VERSION=2.1.12 bundle exec rake test # run both as well as integration tests<\/pre><\/div>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#changelog--versioning\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-changelog--versioning\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Changelog &amp; versioning<\/h2>\n<p>Check out the <a href=\"https:\/\/github.com\/datastax\/ruby-driver\/releases\">releases on GitHub<\/a> and\n<a href=\"https:\/\/github.com\/datastax\/ruby-driver\/blob\/master\/CHANGELOG.md\">changelog<\/a>. Version\nnumbering follows the <a href=\"http:\/\/semver.org\/\">semantic versioning<\/a> scheme.<\/p>\n<p>Private and experimental APIs, defined as whatever is not in the\n<a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/api\">public API documentation<\/a>, i.e. classes and methods marked as <code>@private<\/code>, will change\nwithout warning. If you've been recommended to try an experimental API by the maintainers,\nplease let them know if you depend on that API. Experimental APIs will eventually become\npublic, and knowing how they are used helps in determining their maturity.<\/p>\n<p>Prereleases will be stable, in the sense that they will have finished and properly tested\nfeatures only, but may introduce APIs that will change before the final release. Please\nuse the prereleases and report bugs, but don't deploy them to production without\nconsulting the maintainers, or doing extensive testing yourself. If you do deploy to\nproduction please let the maintainers know as this helps in determining the maturity of\nthe release.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#known-bugs--limitations\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-known-bugs--limitations\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Known bugs &amp; limitations<\/h2>\n<ul><li>Specifying a <code>protocol_version<\/code> option of 1 or 2 in cluster options will fail with a\n<code>NoHostsAvailable<\/code> error rather than a <code>ProtocolError<\/code> against Cassandra node versions 3.0-3.4.<\/li>\n<li>Because the driver reactor is using <code>IO.select<\/code>, the maximum number of tcp connections allowed is 1024.<\/li>\n<li>Because the driver uses <code>IO#write_nonblock<\/code>, Windows is not supported.<\/li>\n<\/ul><p>Please <a href=\"http:\/\/docs.datastax.com\/en\/developer\/ruby-driver\/3.0\/features\/\">refer to the usage documentation for more information on common pitfalls<\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#contributing\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-contributing\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Contributing<\/h2>\n<p>For contributing read <a href=\"https:\/\/github.com\/datastax\/ruby-driver\/blob\/master\/CONTRIBUTING.md\">CONTRIBUTING.md<\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#credits\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-credits\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Credits<\/h2>\n<p>This driver is based on the original work of <a href=\"https:\/\/github.com\/iconara\">Theo Hultberg<\/a>\non <a href=\"https:\/\/github.com\/iconara\/cql-rb\/\">cql-rb<\/a> and adds a series of advanced features\nthat are common across all other DataStax drivers for Apache Cassandra.<\/p>\n<p>The development effort to provide an up to date, high performance, fully featured Ruby\nDriver for Apache Cassandra will continue on this project, while\n<a href=\"https:\/\/github.com\/iconara\/cql-rb\/\">cql-rb<\/a> has been discontinued.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/ruby-driver#copyright\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-copyright\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Copyright<\/h2>\n<p>Copyright 2013-2017 DataStax, Inc.<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\nexcept in compliance with the License. You may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software distributed under the\nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\neither express or implied. See the License for the specific language governing permissions\nand limitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:25:34+0000","updated_at":"2017-10-31T20:32:29+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":8,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/5f27a8ea4298c2484f420bd170bd7a41f65bc570\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f727562792d6472697665722e7376673f6272616e63683d6d6173746572","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4906"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4905,"title":"datastax\/nodejs-driver","url":"https:\/\/github.com\/datastax\/nodejs-driver","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p>A modern, <a href=\"https:\/\/github.com\/datastax\/nodejs-driver#features\">feature-rich<\/a> and highly tunable Node.js client library for Apache Cassandra (1.2+) using exclusively Cassandra's binary protocol and Cassandra Query Language v3. <em>Use the <a href=\"https:\/\/github.com\/datastax\/nodejs-dse-driver\">DSE Node.js driver<\/a> for better compatibility and support for DataStax Enterprise<\/em>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#installation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-installation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Installation<\/h2>\n<div class=\"highlight highlight-source-shell\"><pre>$ npm install cassandra-driver<\/pre><\/div>\n<p><a href=\"https:\/\/travis-ci.org\/datastax\/nodejs-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/eb00101df16c48e8c49bad714207b207be5feac1\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f6e6f64656a732d6472697665722e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https:\/\/travis-ci.org\/datastax\/nodejs-driver.svg?branch=master\"\/><\/a> <a href=\"https:\/\/ci.appveyor.com\/project\/datastax\/nodejs-driver\/branch\/master\"><img src=\"https:\/\/camo.githubusercontent.com\/964cf2b4f7f404c95ca883916f62576cd8915f30\/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6d32317432746664706d6b6a6578316c2f6272616e63682f6d61737465723f7376673d74727565\" alt=\"Build status\" data-canonical-src=\"https:\/\/ci.appveyor.com\/api\/projects\/status\/m21t2tfdpmkjex1l\/branch\/master?svg=true\"\/><\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#features\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-features\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Features<\/h2>\n<ul><li>Simple, Prepared, and <a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/batch\/\">Batch<\/a> statements<\/li>\n<li>Asynchronous IO, parallel execution, request pipelining<\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/connection-pooling\/\">Connection pooling<\/a><\/li>\n<li>Auto node discovery<\/li>\n<li>Automatic reconnection<\/li>\n<li>Configurable <a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/tuning-policies\/#load-balancing-policy\">load balancing<\/a> and <a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/tuning-policies\/#retry-policy\">retry policies<\/a><\/li>\n<li>Works with any cluster size<\/li>\n<li>Both <a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/promise-callback\/\">promise and callback-based API<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#row-streaming-and-pipes\">Row streaming and pipes<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<ul><li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/\">Documentation index<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/datatypes\/\">CQL types to JavaScript types<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/api\/\">API docs<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/faq\/\">FAQ<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#getting-help\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-help\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting Help<\/h2>\n<p>You can use the <a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/nodejs-driver-user\">project mailing list<\/a> or create a ticket on the <a href=\"https:\/\/datastax-oss.atlassian.net\/projects\/NODEJS\/issues\">Jira issue tracker<\/a>. Additionally, you can use the <code>#datastax-drivers<\/code> channel in the <a href=\"https:\/\/academy.datastax.com\/slack\">DataStax Academy Slack<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#basic-usage\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-basic-usage\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Basic usage<\/h2>\n<div class=\"highlight highlight-source-js\"><pre>const cassandra = require('cassandra-driver');\nconst client = new cassandra.Client({ contactPoints: ['h1', 'h2'], keyspace: 'ks1' });\nconst query = 'SELECT name, email FROM users WHERE key = ?';\nclient.execute(query, [ 'someone' ])\n  .then(result =&gt; console.log('User with email %s', result.rows[0].email));<\/pre><\/div>\n<p>Alternatively, you can use the callback-based execution for all asynchronous methods of the API.<\/p>\n<div class=\"highlight highlight-source-js\"><pre>client.execute(query, [ 'someone' ], function(err, result) {\n  assert.ifError(err);\n  console.log('User with email %s', result.rows[0].email);\n});<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#prepare-your-queries\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-prepare-your-queries\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Prepare your queries<\/h3>\n<p>Using prepared statements provides multiple benefits.\nPrepared statements are parsed and prepared on the Cassandra nodes and are ready for future execution.\nAlso, when preparing, the driver retrieves information about the parameter types which\n<strong>allows an accurate mapping between a JavaScript type and a Cassandra type<\/strong>.<\/p>\n<p>The driver will prepare the query once on each host and execute the statement with the bound parameters.<\/p>\n<div class=\"highlight highlight-source-js\"><pre>\/\/ Use query markers (?) and parameters\nconst query = 'UPDATE users SET birth = ? WHERE key=?'; \nconst params = [ new Date(1942, 10, 1), 'jimi-hendrix' ];\n\/\/ Set the prepare flag in the query options\nclient.execute(query, params, { prepare: true })\n  .then(result =&gt; console.log('Row updated on the cluster'));<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#row-streaming-and-pipes\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-row-streaming-and-pipes\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Row streaming and pipes<\/h3>\n<p>When using <code>#eachRow()<\/code> and <code>#stream()<\/code> methods, the driver parses each row as soon as it is received,\nyielding rows without buffering them.<\/p>\n<div class=\"highlight highlight-source-js\"><pre>\/\/ Reducing a large result\nclient.eachRow('SELECT time, val FROM temperature WHERE station_id=', ['abc'],\n  function(n, row) {\n    \/\/ The callback will be invoked per each row as soon as they are received\n    minTemperature = Math.min(row.val, minTemperature);\n  },\n  function (err) {\n    assert.ifError(err);\n  }\n);<\/pre><\/div>\n<p>The <code>#stream()<\/code> method works in the same way but instead of callback it returns a <a href=\"http:\/\/nodejs.org\/api\/stream.html#stream_class_stream_readable\">Readable Streams2<\/a> object\nin <code>objectMode<\/code> that emits instances of <code>Row<\/code>.\nIt can be <strong>piped<\/strong> downstream and provides automatic pause\/resume logic (it buffers when not read).<\/p>\n<div class=\"highlight highlight-source-js\"><pre>client.stream('SELECT time, val FROM temperature WHERE station_id=', [ 'abc' ])\n  .on('readable', function () {\n    \/\/ 'readable' is emitted as soon a row is received and parsed\n    var row;\n    while (row = this.read()) {\n      console.log('time %s and value %s', row.time, row.val);\n    }\n  })\n  .on('end', function () {\n    \/\/ Stream ended, there aren't any more rows\n  })\n  .on('error', function (err) {\n    \/\/ Something went wrong: err is a response error from Cassandra\n  });<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#user-defined-types\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-user-defined-types\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>User defined types<\/h3>\n<p><a href=\"http:\/\/cassandra.apache.org\/doc\/latest\/cql\/types.html#udts\">User defined types (UDT)<\/a> are represented as JavaScript objects.<\/p>\n<p>For example:\nConsider the following UDT and table<\/p>\n<div class=\"highlight highlight-source-sql\"><pre>CREATE TYPE address (\n  street text,\n  city text,\n  state text,\n  zip int,\n  phones set&lt;text&gt;\n);\nCREATE TABLE users (\n  name text PRIMARY KEY,\n  email text,\n  address frozen&lt;address&gt;\n);<\/pre><\/div>\n<p>You can retrieve the user address details as a regular JavaScript object.<\/p>\n<div class=\"highlight highlight-source-js\"><pre>const query = 'SELECT name, address FROM users WHERE key = ?';\nclient.execute(query, [ key ], { prepare: true })\n  .then(result =&gt; {\n    const row = result.first();\n    const address = row.address;\n    console.log('User lives in %s, %s - %s', address.street, address.city, address.state); \n  });<\/pre><\/div>\n<p>Read more information  about using <a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/datatypes\/udts\/\">UDTs with the Node.js Driver<\/a>.<\/p>\n<h3><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#paging\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-paging\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Paging<\/h3>\n<p>All driver methods use a default <code>fetchSize<\/code> of 5000 rows, retrieving only first page of results up to a\nmaximum of 5000 rows to shield an application against accidentally large result sets. To retrieve the following\nrecords you can use the <code>autoPage<\/code> flag in the query options of <code>#eachRow()<\/code> and <code>#stream()<\/code> methods.<\/p>\n<div class=\"highlight highlight-source-js\"><pre>\/\/Imagine a column family with millions of rows\nconst query = 'SELECT * FROM largetable';\nclient.eachRow(query, [], { autoPage: true }, function (n, row) {\n  \/\/ This function will be invoked per each of the rows in all the table\n}, endCallback);<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#batch-multiple-statements\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-batch-multiple-statements\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Batch multiple statements<\/h3>\n<p>You can execute multiple statements in a batch to update\/insert several rows atomically even in different column families.<\/p>\n<div class=\"highlight highlight-source-js\"><pre>const queries = [\n  {\n    query: 'UPDATE user_profiles SET email=? WHERE key=?',\n    params: [ emailAddress, 'hendrix' ]\n  },\n  {\n    query: 'INSERT INTO user_track (key, text, date) VALUES (?, ?, ?)',\n    params: [ 'hendrix', 'Changed email', new Date() ]\n  }\n];\nclient.batch(queries, { prepare: true })\n  .then(result =&gt; console.log('Data updated on cluster'));<\/pre><\/div>\n<hr\/><h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#data-types\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-data-types\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Data types<\/h2>\n<p>There are few data types defined in the ECMAScript specification, this usually represents a problem when you are trying\nto deal with data types that come from other systems in JavaScript.<\/p>\n<p>The driver supports all the CQL data types in Apache Cassandra (3.0 and below) even for types with no built-in\nJavaScript representation, like decimal, varint and bigint. Check the documentation on working with\n<a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/datatypes\/numerical\/\">numerical values<\/a>, <a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/datatypes\/uuids\/\">uuids<\/a> and <a href=\"http:\/\/docs.datastax.com\/en\/developer\/nodejs-driver\/latest\/features\/datatypes\/collections\/\">collections<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#logging\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-logging\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Logging<\/h2>\n<p>Instances of <code>Client()<\/code> are <code>EventEmitter<\/code> and emit <code>log<\/code> events:<\/p>\n<div class=\"highlight highlight-source-js\"><pre>client.on('log', function(level, className, message, furtherInfo) {\n  console.log('log event: %s -- %s', level, message);\n});<\/pre><\/div>\n<p>The <code>level<\/code> being passed to the listener can be <code>verbose<\/code>, <code>info<\/code>, <code>warning<\/code> or <code>error<\/code>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#compatibility\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-compatibility\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Compatibility<\/h2>\n<ul><li>Apache Cassandra versions 2.0 and above.<\/li>\n<li>DataStax Enterprise versions 4.5 and above.<\/li>\n<li>Node.js versions 0.10 and above.<\/li>\n<\/ul><p>Note: DataStax products do not support big-endian systems.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#feedback-requested\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-feedback-requested\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Feedback Requested<\/h2>\n<p><strong>Help us focus our efforts!<\/strong> Provide your input on the <a href=\"http:\/\/goo.gl\/forms\/f216tY3Ebr\">Platform and Runtime Survey<\/a> (we kept it short).<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#credits\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-credits\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Credits<\/h2>\n<p>This driver is based on the original work of <a href=\"https:\/\/github.com\/jorgebay\">Jorge Bay<\/a> on <a href=\"https:\/\/github.com\/jorgebay\/node-cassandra-cql\">node-cassandra-cql<\/a> and adds a series of advanced features that are common across all other <a href=\"https:\/\/github.com\/datastax\">DataStax drivers<\/a> for Apache Cassandra.<\/p>\n<p>The development effort to provide an up to date, high performance, fully featured Node.js Driver for Apache Cassandra will continue on this project, while <a href=\"https:\/\/github.com\/jorgebay\/node-cassandra-cql\">node-cassandra-cql<\/a> will be discontinued.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/nodejs-driver#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright 2014-2017 DataStax<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:25:39+0000","updated_at":"2017-10-31T20:32:28+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":5,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/eb00101df16c48e8c49bad714207b207be5feac1\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f6e6f64656a732d6472697665722e7376673f6272616e63683d6d6173746572","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4905"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4904,"title":"DataStax .NET Driver for Apache Cassandra","url":"https:\/\/github.com\/datastax\/csharp-driver","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p>A modern, <a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/features\/\">feature-rich<\/a> and highly tunable C# client library for Apache Cassandra (1.2+) using exclusively Cassandra's binary protocol and Cassandra Query Language v3. <em>Use the <a href=\"https:\/\/github.com\/datastax\/csharp-dse-driver\">DSE C# driver<\/a> for better compatibility and support for DataStax Enterprise<\/em>.<\/p>\n<p>The driver supports .NET Framework 4.5+ and .NET Core 1+.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#installation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-installation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Installation<\/h2>\n<p><a href=\"https:\/\/nuget.org\/packages\/CassandraCSharpDriver\/\">Get it on Nuget<\/a><\/p>\n<div class=\"highlight highlight-source-shell\"><pre>PM&gt; Install-Package CassandraCSharpDriver<\/pre><\/div>\n<p><a href=\"https:\/\/travis-ci.org\/datastax\/csharp-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/65a02e83e7515dc3b1ef568bd7317d0dac6a1874\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f6373686172702d6472697665722e7376673f6272616e63683d6d6173746572\" alt=\"Build status\" data-canonical-src=\"https:\/\/travis-ci.org\/datastax\/csharp-driver.svg?branch=master\"\/><\/a>\n<a href=\"https:\/\/ci.appveyor.com\/project\/DataStax\/csharp-driver\/branch\/master\"><img src=\"https:\/\/camo.githubusercontent.com\/5735947c513653cfe29b994bb8826e9cd99d797f\/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f7269316f6c7638626c376237796b37792f6272616e63682f6d61737465723f7376673d74727565\" alt=\"Windows Build status\" data-canonical-src=\"https:\/\/ci.appveyor.com\/api\/projects\/status\/ri1olv8bl7b7yk7y\/branch\/master?svg=true\"\/><\/a>\n<a href=\"https:\/\/www.nuget.org\/packages\/CassandraCSharpDriver\"><img src=\"https:\/\/camo.githubusercontent.com\/5d098659e24e8ec35c2a495433a10248901d2036\/68747470733a2f2f696d672e736869656c64732e696f2f6e756765742f762f43617373616e6472614353686172704472697665722e737667\" alt=\"Latest stable\" data-canonical-src=\"https:\/\/img.shields.io\/nuget\/v\/CassandraCSharpDriver.svg\"\/><\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#features\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-features\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Features<\/h2>\n<ul><li>Sync and <a href=\"https:\/\/github.com\/datastax\/csharp-driver#asynchronous-api\">Async<\/a> API<\/li>\n<li>Simple, <a href=\"https:\/\/github.com\/datastax\/csharp-driver#prepared-statements\">Prepared<\/a>, and <a href=\"https:\/\/github.com\/datastax\/csharp-driver#batching-statements\">Batch<\/a> statements<\/li>\n<li>Asynchronous IO, parallel execution, request pipelining<\/li>\n<li>Connection pooling<\/li>\n<li>Auto node discovery<\/li>\n<li>Automatic reconnection<\/li>\n<li>Configurable <a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/features\/tuning-policies\/\">load balancing<\/a> and <a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/features\/tuning-policies\/\">retry policies<\/a><\/li>\n<li>Works with any cluster size<\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/features\/components\/linq\/\">Linq2Cql<\/a> and Ado.Net support<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<ul><li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/\">Documentation index<\/a><\/li>\n<li><a href=\"https:\/\/academy.datastax.com\/resources\/getting-started-apache-cassandra-and-c-net\">Getting started guide<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/drivers\/csharp\/3.3\/\">API docs<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#getting-help\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-help\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting Help<\/h2>\n<p>You can use the project <a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/csharp-driver-user\">Mailing list<\/a> or create a ticket on the <a href=\"https:\/\/datastax-oss.atlassian.net\/projects\/CSHARP\/issues\">Jira issue tracker<\/a>. Additionally, you can use the <code>#datastax-drivers<\/code> channel in the <a href=\"https:\/\/academy.datastax.com\/slack\">DataStax Academy Slack<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#upgrading-from-previous-versions\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-upgrading-from-previous-versions\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Upgrading from previous versions<\/h2>\n<p>If you are upgrading to <a href=\"https:\/\/www.datastax.com\/products\/datastax-enterprise\">DataStax Enterprise<\/a>, use the <a href=\"https:\/\/github.com\/datastax\/csharp-dse-driver\">DSE C# driver<\/a> for more features and better compatibility.<\/p>\n<p>If you are upgrading from the 2.1 branch of the driver, be sure to have a look at the <a href=\"https:\/\/github.com\/datastax\/csharp-driver\/blob\/master\/doc\/upgrade-guide-2.5.md\">upgrade guide<\/a>.<\/p>\n<p>If you are upgrading from the 1.x branch of the driver, follow the <a href=\"https:\/\/github.com\/datastax\/csharp-driver\/blob\/master\/doc\/upgrade-guide-2.0.md\">upgrade guide to 2.0<\/a>, and then the above document.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#basic-usage\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-basic-usage\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Basic Usage<\/h2>\n<div class=\"highlight highlight-source-cs\"><pre>var cluster = Cluster.Builder()\n                     .AddContactPoints(\"host1\")\n                     .Build();\n\/\/ Connect to the nodes using a keyspace\nvar session = cluster.Connect(\"sample_keyspace\");\n\/\/ Execute a query on a connection synchronously\nvar rs = session.Execute(\"SELECT * FROM sample_table\");\n\/\/ Iterate through the RowSet\nforeach (var row in rs)\n{\n  var value = row.GetValue&lt;int&gt;(\"sample_int_column\");\n  \/\/ Do something with the value\n}<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/csharp-driver#prepared-statements\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-prepared-statements\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Prepared statements<\/h3>\n<p>Prepare your query <strong>once<\/strong> and bind different parameters to obtain best performance.<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>\/\/ Prepare a statement once\nvar ps = session.Prepare(\"UPDATE user_profiles SET birth=? WHERE key=?\");\n\/\/ ...bind different parameters every time you need to execute\nvar statement = ps.Bind(new DateTime(1942, 11, 27), \"hendrix\");\n\/\/ Execute the bound statement with the provided parameters\nsession.Execute(statement);<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/csharp-driver#batching-statements\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-batching-statements\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Batching statements<\/h3>\n<p>You can execute multiple statements (prepared or unprepared) in a batch to update\/insert several rows atomically even in different column families.<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>\/\/ Prepare the statements involved in a profile update once\nvar profileStmt = session.Prepare(\"UPDATE user_profiles SET email=? WHERE key=?\");\nvar userTrackStmt = session.Prepare(\"INSERT INTO user_track (key, text, date) VALUES (?, ?, ?)\");\n\/\/ ...you should reuse the prepared statement\n\/\/ Bind the parameters and add the statement to the batch batch\nvar batch = new BatchStatement()\n  .Add(profileStmt.Bind(emailAddress, \"hendrix\"))\n  .Add(userTrackStmt.Bind(\"hendrix\", \"You changed your email\", DateTime.Now));\n\/\/ Execute the batch\nsession.Execute(batch);<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/csharp-driver#asynchronous-api\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-asynchronous-api\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Asynchronous API<\/h3>\n<p>Session allows asynchronous execution of statements (for any type of statement: simple, bound or batch) by exposing the <code>ExecuteAsync<\/code> method.<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>\/\/ Execute a statement asynchronously using await\nvar rs = await session.ExecuteAsync(statement);<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/csharp-driver#avoid-boilerplate-mapping-code\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-avoid-boilerplate-mapping-code\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Avoid boilerplate mapping code<\/h3>\n<p>The driver features a built-in <a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/features\/components\/mapper\/\">Mapper<\/a> and <a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/features\/components\/linq\/\">Linq<\/a> components that can use to avoid boilerplate mapping code between cql rows and your application entities.<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>User user = mapper.Single&lt;User&gt;(\"SELECT name, email FROM users WHERE id = ?\", userId);<\/pre><\/div>\n<p>See the <a href=\"http:\/\/docs.datastax.com\/en\/developer\/csharp-driver\/latest\/features\/components\/\">driver components documentation<\/a> for more information.<\/p>\n<h3><a href=\"https:\/\/github.com\/datastax\/csharp-driver#automatic-pagination-of-results\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-automatic-pagination-of-results\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Automatic pagination of results<\/h3>\n<p>You can iterate indefinitely over the <code>RowSet<\/code>, having the rows fetched block by block until the rows available on the client side are exhausted.<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>var statement = new SimpleStatement(\"SELECT * from large_table\");\n\/\/ Set the page size, in this case the RowSet will not contain more than 1000 at any time\nstatement.SetPageSize(1000);\nvar rs = session.Execute(statement);\nforeach (var row in rs)\n{\n  \/\/ The enumerator will yield all the rows from Cassandra\n  \/\/ Retrieving them in the back in blocks of 1000.\n}<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/csharp-driver#user-defined-types-mapping\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-user-defined-types-mapping\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>User defined types mapping<\/h3>\n<p>You can map your <a href=\"http:\/\/docs.datastax.com\/en\/cql\/3.1\/cql\/cql_reference\/cqlRefUDType.html\">Cassandra User Defined Types<\/a> to your application entities.<\/p>\n<p>For a given udt<\/p>\n<div class=\"highlight highlight-source-sql\"><pre>CREATE TYPE address (\n  street text,\n  city text,\n  zip_code int,\n  phones set&lt;text&gt;\n);<\/pre><\/div>\n<p>For a given class<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>public class Address\n{\n  public string Street { get; set; }\n  public string City { get; set; }\n  public int ZipCode { get; set; }\n  public IEnumerable&lt;string&gt; Phones { get; set;}\n}<\/pre><\/div>\n<p>You can either map the properties by name<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>\/\/Map the properties by name automatically\nsession.UserDefinedTypes.Define(\n  UdtMap.For&lt;Address&gt;()\n);<\/pre><\/div>\n<p>Or you can define the properties manually<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>session.UserDefinedTypes.Define(\n  UdtMap.For&lt;Address&gt;()\n    .Map(a =&gt; a.Street, \"street\")\n    .Map(a =&gt; a.City, \"city\")\n    .Map(a =&gt; a.ZipCode, \"zip_code\")\n    .Map(a =&gt; a.Phones, \"phones\")\n);<\/pre><\/div>\n<p>You should <strong>map your <a href=\"http:\/\/docs.datastax.com\/en\/cql\/3.1\/cql\/cql_reference\/cqlRefUDType.html\">UDT<\/a> to your entity once<\/strong> and you will be able to use that mapping during all your application lifetime.<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>var rs = session.Execute(\"SELECT id, name, address FROM users where id = x\");\nvar row = rs.First();\n\/\/ You can retrieve the field as a value of type Address\nvar userAddress = row.GetValue&lt;Address&gt;(\"address\");\nConsole.WriteLine(\"user lives on {0} Street\", userAddress.Street);<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/datastax\/csharp-driver#setting-cluster-and-statement-execution-options\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-setting-cluster-and-statement-execution-options\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Setting cluster and statement execution options<\/h3>\n<p>You can set the options on how the driver connects to the nodes and the execution options.<\/p>\n<div class=\"highlight highlight-source-cs\"><pre>\/\/ Example at cluster level\nvar cluster = Cluster\n  .Builder()\n  .AddContactPoints(hosts)\n  .WithCompression(CompressionType.LZ4)\n  .WithLoadBalancingPolicy(new DCAwareRoundRobinPolicy(\"west\"));\n\/\/ Example at statement (simple, bound, batch) level\nvar statement = new SimpleStatement(query)\n  .SetConsistencyLevel(ConsistencyLevel.Quorum)\n  .SetRetryPolicy(DowngradingConsistencyRetryPolicy.Instance)\n  .SetPageSize(1000);<\/pre><\/div>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#compatibility\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-compatibility\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Compatibility<\/h2>\n<ul><li>Apache Cassandra versions 2.0 and above.<\/li>\n<li>DataStax Enterprise versions 4.5 and above.<\/li>\n<li>.NET Framework versions 4.5 and above and .NET Core versions 1.0 and above.<\/li>\n<\/ul><p>Note: DataStax products do not support big-endian systems.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#feedback-requested\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-feedback-requested\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Feedback Requested<\/h2>\n<p><strong>Help us focus our efforts!<\/strong> Provide your input on the <a href=\"http:\/\/goo.gl\/forms\/3BxcP8nKs6\">Platform and Runtime Survey<\/a> (we kept it short).<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#building-and-running-the-tests\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-building-and-running-the-tests\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Building and running the tests<\/h2>\n<p>You can use Visual Studio or msbuild to build the solution.<\/p>\n<p><a href=\"https:\/\/github.com\/datastax\/csharp-driver\/wiki\/Building-and-running-tests\">Check the documentation for building the driver from source and running the tests<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/csharp-driver#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright 2012-2017, DataStax.<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:25:43+0000","updated_at":"2017-10-31T20:32:28+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":5,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/65a02e83e7515dc3b1ef568bd7317d0dac6a1874\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f6373686172702d6472697665722e7376673f6272616e63683d6d6173746572","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4904"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4903,"title":"datastax\/php-driver","url":"https:\/\/github.com\/datastax\/php-driver","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p><a href=\"https:\/\/travis-ci.org\/datastax\/php-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/09a7363d0b5b437e7d129fb1adfd52fce91adef8\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f7068702d6472697665722e737667\" alt=\"Build Status: Linux\" data-canonical-src=\"https:\/\/travis-ci.org\/datastax\/php-driver.svg\"\/><\/a>\n<a href=\"https:\/\/ci.appveyor.com\/project\/DataStax\/php-driver\"><img src=\"https:\/\/camo.githubusercontent.com\/fa5204103666528431e43d40985aad115d22d4e4\/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38767278706b666c34786d3266336e6d3f7376673d74727565\" alt=\"Build Status: Windows\" data-canonical-src=\"https:\/\/ci.appveyor.com\/api\/projects\/status\/8vrxpkfl4xm2f3nm?svg=true\"\/><\/a><\/p>\n<p>A modern, <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\">feature-rich<\/a> and highly tunable PHP client library for\n<a href=\"http:\/\/cassandra.apache.org\">Apache Cassandra<\/a> 2.1+ using exclusively Cassandra's binary protocol and\nCassandra Query Language v3. <strong>Use the <a href=\"http:\/\/docs.datastax.com\/en\/developer\/php-driver-dse\/latest\">DSE PHP driver<\/a> for better compatibility\nand support for <a href=\"http:\/\/www.datastax.com\/products\/datastax-enterprise\">DataStax Enterprise<\/a><\/strong>.<\/p>\n<p>This is a wrapper around the <a href=\"http:\/\/docs.datastax.com\/en\/developer\/cpp-driver\/latest\">DataStax C\/C++ Driver for Apache Cassandra<\/a>.<\/p>\n<p><strong>Note<\/strong>: DataStax products do not support big-endian systems.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#getting-the-driver\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-the-driver\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting the Driver<\/h2>\n<p>Binary versions of the driver, available for multiple operating systems and\nmultiple versions of PHP, can be obtained from our [download server]. The\nsource code is made available via <a href=\"https:\/\/github.com\/datastax\/php-driver\">GitHub<\/a>. <strong>If using <a href=\"http:\/\/www.datastax.com\/products\/datastax-enterprise\">DataStax Enterprise<\/a>\nuse the <a href=\"http:\/\/docs.datastax.com\/en\/developer\/php-driver-dse\/latest\">DSE PHP driver<\/a> instead<\/strong>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#whats-new-in-v120v130\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-whats-new-in-v120v130\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>What's new in v1.2.0\/v1.3.0<\/h2>\n<ul><li>Support for <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/duration.feature\"><code>duration<\/code><\/a><\/li>\n<li><code>Session::execute()<\/code> and <code>Session::executeAsync()<\/code> now support a\n<a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/simple_string_queries.feature\">simple string<\/a> for the query CQL and a simple array for the query execution\noption<\/li>\n<li>Full support for Apache Cassandra 2.2 and 3.0+<\/li>\n<li>Support for <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/datatypes.feature#L92\"><code>tinyint<\/code> and <code>smallint<\/code><\/a><\/li>\n<li>Support for <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/datatypes.feature#L135\"><code>date<\/code><\/a> and <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/datatypes.feature#L170\"><code>time<\/code><\/a><\/li>\n<li>Support for <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/function_and_aggregate_metadata.feature\">user-defined function and aggregate<\/a> metadata<\/li>\n<li>Support for <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/secondary_index_metadata.feature\">secondary index<\/a> and <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\/materialized_view_metadata.feature\">materialized view<\/a> metadata<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/php-driver#compatibility\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-compatibility\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Compatibility<\/h2>\n<p>This driver works exclusively with the Cassandra Query Language v3 (CQL3) and\nCassandra's native protocol. The current version works with:<\/p>\n<ul><li>Apache Cassandra versions 2.1, 2.2 and 3.0+<\/li>\n<li>PHP 5.6, PHP 7.0, and PHP 7.1\n<ul><li>32-bit (x86) and 64-bit (x64)<\/li>\n<li>Thread safe (TS) and non-thread safe (NTS)<\/li>\n<\/ul><\/li>\n<li>Compilers: GCC 4.1.2+, Clang 3.4+, and MSVC 2010\/2012\/2013\/2015<\/li>\n<\/ul><p>If using <a href=\"http:\/\/www.datastax.com\/products\/datastax-enterprise\">DataStax Enterprise<\/a> the <a href=\"http:\/\/docs.datastax.com\/en\/developer\/php-driver-dse\/latest\">DSE PHP driver<\/a> provides more features and\nbetter compatibility.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<ul><li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/php-driver\/latest\">Home<\/a><\/li>\n<li><a href=\"http:\/\/docs.datastax.com\/en\/developer\/php-driver\/latest\/api\">API<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\">Features<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/php-driver#getting-help\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-help\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting Help<\/h2>\n<ul><li>JIRA: <a href=\"https:\/\/datastax-oss.atlassian.net\/browse\/PHP\">https:\/\/datastax-oss.atlassian.net\/browse\/PHP<\/a><\/li>\n<li>Mailing List: <a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/php-driver-user\">https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/php-driver-user<\/a><\/li>\n<li>DataStax Academy via Slack: <a href=\"https:\/\/academy.datastax.com\/slack\">https:\/\/academy.datastax.com\/slack<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/php-driver#feedback-requested\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-feedback-requested\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Feedback Requested<\/h2>\n<p><strong>Help us focus our efforts!<\/strong> <a href=\"http:\/\/goo.gl\/forms\/HbSiIJ2tLP\">Provide your input<\/a> on the PHP Driver Platform\nand Runtime Survey (we kept it short).<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#quick-start\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-quick-start\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Quick Start<\/h2>\n<div class=\"highlight highlight-text-html-php\"><pre>&lt;?php\n$cluster   = Cassandra::cluster()                 \/\/ connects to localhost by default\n                 -&gt;build();\n$keyspace  = 'system';\n$session   = $cluster-&gt;connect($keyspace);        \/\/ create session, optionally scoped to a keyspace\n$statement = new Cassandra\\SimpleStatement(       \/\/ also supports prepared and batch statements\n    'SELECT keyspace_name, columnfamily_name FROM schema_columnfamilies'\n);\n$future    = $session-&gt;executeAsync($statement);  \/\/ fully asynchronous and easy parallel execution\n$result    = $future-&gt;get();                      \/\/ wait for the result, with an optional timeout\nforeach ($result as $row) {                       \/\/ results and rows implement Iterator, Countable and ArrayAccess\n    printf(\"The keyspace %s has a table called %s\\n\", $row['keyspace_name'], $row['columnfamily_name']);\n}<\/pre><\/div>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#installation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-installation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Installation<\/h2>\n<div class=\"highlight highlight-source-shell\"><pre>pecl install cassandra<\/pre><\/div>\n<p><a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/ext\/README.md\">Read detailed instructions on building and installing the\nextension<\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#contributing\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-contributing\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Contributing<\/h2>\n<p><a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/CONTRIBUTING.md\">Read our contribution policy<\/a> for a detailed description\nof the process.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#code-examples\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-code-examples\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Code examples<\/h2>\n<p>The DataStax PHP Driver uses the amazing <a href=\"http:\/\/docs.behat.org\">Behat Framework<\/a> for both end-to-end,\nor acceptance testing and documentation. All of the features supported by the\ndriver have appropriate acceptance tests with <a href=\"https:\/\/github.com\/datastax\/php-driver\/blob\/master\/features\">easy-to-copy code examples in\nthe <code>features\/<\/code> directory<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#running-tests\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-running-tests\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Running tests<\/h2>\n<p>For your convenience a <code>Vagrantfile<\/code> with configuration ready for testing is\navailable. To execute tests, run the following:<\/p>\n<div class=\"highlight highlight-source-shell\"><pre>git clone https:\/\/github.com\/datastax\/php-driver.git\ncd php-driver\ngit submodule update --init\nvagrant up\nvagrant ssh<\/pre><\/div>\n<p>Once you've logged in to the vagrant VM, run:<\/p>\n<div class=\"highlight highlight-source-shell\"><pre>cd \/usr\/local\/src\/php-driver\n.\/bin\/behat\n.\/bin\/phpunit<\/pre><\/div>\n<h2><a href=\"https:\/\/github.com\/datastax\/php-driver#copyright\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-copyright\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Copyright<\/h2>\n<p>Copyright 2015-2017 DataStax, Inc.<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use\nthis file except in compliance with the License. You may obtain a copy of the\nLicense at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software distributed\nunder the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\nCONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:26:08+0000","updated_at":"2017-10-31T20:32:27+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":3,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/09a7363d0b5b437e7d129fb1adfd52fce91adef8\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f7068702d6472697665722e737667","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4903"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4902,"title":"datastax\/cstar_perf","url":"https:\/\/github.com\/datastax\/cstar_perf","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p>cstar_perf is a performance testing platform for Apache Cassandra\nwhich focuses on a high level of automation and test consistency.<\/p>\n<p>It handles the following:<\/p>\n<ul><li>Download and build Cassandra source code.<\/li>\n<li>Configure and bootstrap nodes on a real cluster.<\/li>\n<li>Run stress workloads.<\/li>\n<li>Capture performance metrics.<\/li>\n<li>Create reports and charts comparing different configs\/workloads.<\/li>\n<li>Webserver frontend for scheduling tests, viewing prior runs, and monitoring test clusters.<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/cstar_perf#5-minute-introduction\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-5-minute-introduction\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>5 Minute Introduction<\/h2>\n<p><a href=\"http:\/\/www.youtube.com\/watch?v=jSS96ooZwVw\"><img src=\"https:\/\/camo.githubusercontent.com\/3df7dd40432822f3f49d3259e4bfbc5cc20802cb\/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6a535339366f6f5a7756772f302e6a7067\" alt=\"IMAGE ALT TEXT HERE\" data-canonical-src=\"http:\/\/img.youtube.com\/vi\/jSS96ooZwVw\/0.jpg\"\/><\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cstar_perf#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<p>The evolving documentation is <a href=\"https:\/\/datastax.github.io\/cstar_perf\">available online here<\/a>.<\/p>\n<ul><li><a href=\"http:\/\/datastax.github.io\/cstar_perf\/setup_dev_environment.html\">Setup a cstar_perf development\/demo environment<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cstar_perf\/setup_cstar_perf_tool.html\">Setup cstar_perf.tool<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cstar_perf\/setup_cstar_perf_frontend.html\">Setup cstar_perf.frontend<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cstar_perf\/running_tests.html\">Running Tests<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/cstar_perf\/architecture.html\">Architecture<\/a><\/li>\n<\/ul><p>The source for these docs are contained in the\n<a href=\"https:\/\/github.com\/datastax\/cstar_perf\/tree\/gh-pages\">gh-pages<\/a>\nbranch, please feel free to make pull requests for improvements.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/cstar_perf#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright 2014 DataStax<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:26:12+0000","updated_at":"2017-10-31T20:32:27+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":1,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/3df7dd40432822f3f49d3259e4bfbc5cc20802cb\/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6a535339366f6f5a7756772f302e6a7067","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4902"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4901,"title":"datastax\/spark-cassandra-stress","url":"https:\/\/github.com\/datastax\/spark-cassandra-stress","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p>A tool for testing the <a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\">DataStax Spark Cassandra Connector<\/a> against both <a href=\"https:\/\/cassandra.apache.org\/\">Apache\nCassandra<\/a> (TM) and <a href=\"http:\/\/www.datastax.com\/products\/datastax-enterprise\">DataStax Enterprise<\/a> (DSE) with either bundled libraries from\nDSE, Maven, or the connector built from source!<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-stress#building\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-building\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Building<\/h2>\n<p>This project is built using Gradle and can be built in three exciting ways:<\/p>\n<ol><li>Using the Connector and Spark libraries installed by DataStax Enterprise<\/li>\n<li>Using libraries downloaded from maven<\/li>\n<li>Using libraries assembled fresh from your local Spark Cassandra Connector Repository<\/li>\n<\/ol><p>The jar can be built using<\/p>\n<pre>.\/gradlew jar -Pagainst=[type]\n<\/pre>\n<p>Where type is one of <code>dse<\/code>,<code>maven<\/code> or <code>source<\/code><\/p>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-stress#dse-options\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-dse-options\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>DSE Options<\/h3>\n<p>DSE libraries are located by looking for the installation of DSE on your machine.\nChange environment variables <code>DSE_HOME<\/code> and <code>DSE_RESOURCES<\/code> if your installation\ndiffers from the default.<\/p>\n<p>Defaults<\/p>\n<pre>DSE_HOME=$HOME\/dse\nDSE_RESOURCES=$HOME\/dse\/resources\n<\/pre>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-stress#maven-options\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-maven-options\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Maven Options<\/h3>\n<p>When getting libraries from Maven we need to specify the Connector version and\nSpark Version libraries to compile against. Change environment variables\n<code>CONNECTOR_VERSION<\/code> and <code>SPARK_VERSION<\/code> to the artifacts you would like to\nuse.<\/p>\n<p>Defaults<\/p>\n<pre>CONNECTOR_VERSION=1.2.0-rc2\nSPARK_VERSION=1.2.1\n<\/pre>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-stress#source-options\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-source-options\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Source Options<\/h3>\n<p>Gradle will attempt to clean and build the assembly jar for the Spark Connector\nlooking for the repository in environment variable <code>SPARKCC_HOME<\/code>. This will\nbuild whatever commit the connector is currently at.<\/p>\n<p>Default<\/p>\n<pre>SPARKCC_HOME=$HOME\/repos\/spark-cassandra-connector\/\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-stress#running\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-running\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Running<\/h2>\n<p>There are many options which can be used to configure your run of\nSpark Cassandra Stress but the two main invocations are either using\n<code>dse spark-submit<\/code> or <code>spark-submit<\/code>.<\/p>\n<p>See the <code>run.sh<\/code> script for examples or use it to launch the program.<\/p>\n<pre>.\/run.sh [dse|apache] --help\n<\/pre>\n<p>Will bring up the built in help.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-stress#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright 2014-17, DataStax, Inc.<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:26:17+0000","updated_at":"2017-10-31T20:32:27+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":1,"domain_name":"github.com","preview_picture":"https:\/\/avatars0.githubusercontent.com\/u\/573369?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4901"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4900,"title":"o19s\/trireme","url":"https:\/\/github.com\/o19s\/trireme","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p>Trireme is a tool providing migration support for Apache Cassandra, DataStax Enterprise Cassandra &amp; Solr. Commands are run using the Python <a href=\"https:\/\/github.com\/pyinvoke\/invoke\">Invoke<\/a> CLI tool.<\/p>\n<h2><a href=\"https:\/\/github.com\/o19s\/trireme#system-dependencies\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-system-dependencies\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>System Dependencies<\/h2>\n<ul><li><code>cqlsh<\/code> must be on the <code>PATH<\/code>. Some tasks utilize the <code>cqlsh<\/code> tool for running scripts and dumping schemas to disk.<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/o19s\/trireme#integration\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-integration\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Integration<\/h2>\n<p>To use this tool within the scope of your project follow these steps.<\/p>\n<ol><li>\n<p>Install <code>trireme<\/code> with <code>pip install trireme<\/code><\/p>\n<\/li>\n<li>\n<p>Create a <code>tasks.py<\/code> file with the following content:<\/p>\n<div class=\"highlight highlight-source-python\"><pre>from invoke import Collection\nfrom trireme import trireme\nnamespace = Collection(trireme)<\/pre><\/div>\n<\/li>\n<li>\n<p>Create a <code>trireme_config.py<\/code> file with your Cassandra and Solr information.<\/p>\n<div class=\"highlight highlight-source-python\"><pre># Cassandra Configuration\n# Contact points for your cluster, currently only the first is used\ncontact_points = ['127.0.0.1']\n# Keyspace to work with, this doesn't have to exist yet.\nkeyspace = 'foo'\n# Replication options. Defined as a map just as you would in CQL.\nreplication = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n# replication = {'class' : 'NetworkTopologyStrategy', 'dc1' : 3, 'dc2' : 2}\n# Authentication Information\nusername = None\npassword = None\n# Flag indicating whether this host is the migration master. Migrations are only run on the migration master\nmigration_master = True\n# Solr Configuration\nsolr_url = 'http:\/\/127.0.0.1:8983\/solr'<\/pre><\/div>\n<\/li>\n<li>\n<p>Run the trireme setup task to create the basic directories<\/p>\n<div class=\"highlight highlight-source-shell\"><pre>inv trireme.setup<\/pre><\/div>\n<\/li>\n<\/ol><h2><a href=\"https:\/\/github.com\/o19s\/trireme#usage\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-usage\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Usage<\/h2>\n<p>Migrators contain logic to run migrations. This project contains a migrator for simple CQL scripts and Solr core configuration files. Not every migrator supports all actions. For example Solr included in DSE 4.6 does not include the ability to delete cores. In this case we do not have a task named drop.<\/p>\n<p>List all commands:<\/p>\n<p><code>inv -l<\/code><\/p>\n<p>To list optional parameters for a command:<\/p>\n<p><code>inv --help command.name<\/code>.<\/p>\n<p>Example: <code>inv --help cassandra.add_migration<\/code><\/p>\n<h3><a href=\"https:\/\/github.com\/o19s\/trireme#cassandra\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-cassandra\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Cassandra<\/h3>\n<p><em>Note: This feature works with both Apache Cassandra and DataStax Enterprise<\/em><\/p>\n<p>Actions supported:<\/p>\n<ul><li><code>cassandra.create<\/code> - Creates the keyspace along with a table to track migrations. Note: The default replication strategy is SimpleStrategy with a Replication Factor of 3.<\/li>\n<li><code>cassandra.drop<\/code> - Drops the keyspace.<\/li>\n<li><code>cassandra.migrate<\/code> - Runs all missing migrations against the keyspace.<\/li>\n<li><code>cassandra.add_migration --name migration_name<\/code> - Generates a migration\nfile under <code>db\/migrations<\/code> with the current timestamp prepended to the\nprovided <code>--name<\/code> value.<\/li>\n<li><code>cassandra.dump_schema<\/code> - Dumps the current schmea to ```db\/schema.cql``. Be careful when using this feature when Solr is enabled.<\/li>\n<li><code>cassandra.load_schema<\/code> - Loads the schema from <code>db\/schema.cql<\/code>. This may be faster than running all migrations in a project.<\/li>\n<\/ul><h4><a href=\"https:\/\/github.com\/o19s\/trireme#examples\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-examples\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Examples:<\/h4>\n<ul><li><code>inv cassandra.create cassandra.migrate<\/code> - Creates the keyspaces and runs all migrations<\/li>\n<li><code>inv cassandra.load_schema<\/code> - Creates the keyspace and loads the schema from <code>db\/schema.cql<\/code><\/li>\n<\/ul><h3><a href=\"https:\/\/github.com\/o19s\/trireme#solr\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-solr\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Solr<\/h3>\n<p><em>Note: This feature only works with DataStax Enterprise<\/em><\/p>\n<p>Actions supported:<\/p>\n<ul><li><code>solr.create [--core foo.bar]<\/code> - Uploads the core configuration files and calls the CREATE API endpoint<\/li>\n<li><code>solr.migrate [--core foo.bar]<\/code> - Uploads the core configuration files and calls the RELOAD API endpoint<\/li>\n<li><code>solr.add_core --name foo.bar<\/code> - Creates a core configuration directory and files. Use the format\n<code>keyspace.table_name<\/code> when naming your cores.<\/li>\n<\/ul><p>Example: <code>inv solr.create<\/code> - Uploads all core configuration files and calls the create core API endpoint.<\/p>\n<p><code>solr.create<\/code> and <code>solr.migrate<\/code> support the <code>--core core.name<\/code> flag. This will run the task against only one core instead of all cores. Remember the core name in DSE Solr is <code>keyspace.table_name<\/code>.<\/p>\n<h2><a href=\"https:\/\/github.com\/o19s\/trireme#directory-layout\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-directory-layout\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Directory Layout<\/h2>\n<h3><a href=\"https:\/\/github.com\/o19s\/trireme#dbmigrations\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-dbmigrations\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>db\/migrations<\/h3>\n<p>CQL migration files generated by the <code>cassandra.add_migration<\/code> command will be placed in this directory with a timestamp prepended.<\/p>\n<p>Example directory layout:<\/p>\n<pre>db\/\n  migrations\/\n    201501301409_create_users_table.cql\n    201501301623_create_tweets_table.cql\n    ...\n<\/pre>\n<h3><a href=\"https:\/\/github.com\/o19s\/trireme#dbsolr\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-dbsolr\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>db\/solr<\/h3>\n<p>Folder containing all the Solr core configuration files. With DataStax Enterprise the core name is comprised of the keyspace and table name in the format <em>keyspace.table_name<\/em>. Within this directory we house sub-directories for each core. These directories in turn have the <code>schema.xml<\/code> and <code>solrconfig.xml<\/code> files needed for configuring the core.<\/p>\n<p>Example directory layout:<\/p>\n<pre>db\/\n  solr\/\n    example_keyspace.a_table\/\n      schema.xml\n      solrconfig.xml\n    example_keyspace.b_table\/\n      schema.xml\n      solrconfig.xml\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/o19s\/trireme#trireme-project-layout\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-trireme-project-layout\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Trireme Project Layout<\/h2>\n<pre>trireme\/\n  migrators\/\n    cassandra.py\n    solr.py\n  trireme.py\n<\/pre>\n<h3><a href=\"https:\/\/github.com\/o19s\/trireme#migrators\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-migrators\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>migrators<\/h3>\n<p>The code that powers the migration engine. Each migrator receives its own file and provides invoke tasks.<\/p>\n<h3><a href=\"https:\/\/github.com\/o19s\/trireme#triremepy\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-triremepy\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>trireme.py<\/h3>\n<p>Collects all of the Invoke tasks into a common namespace along with a simple setup task<\/p>\n<h2><a href=\"https:\/\/github.com\/o19s\/trireme#python-dependencies\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-python-dependencies\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Python Dependencies<\/h2>\n<p><em>All required items have been specified in <code>requirements.txt<\/code> and\n<code>setup.py<\/code>. Select items are outlined below.<\/em><\/p>\n<ul><li>cassandra-driver - DataStax driver for connecting with Cassandra, used when creating and dropping keyspaces<\/li>\n<li>requests - HTTP Client, used when communicating with the Solr APIs<\/li>\n<li>invoke - Task execution tool &amp; library. This is used to run the exposed migration tasks<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/o19s\/trireme#extending-trireme\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-extending-trireme\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Extending Trireme<\/h2>\n<p>Adding a new migrator involves placing the code to invoke annotations in a file within the migrators directory. Next add your migrator to the <code>Collection<\/code> entry in <code>trireme.py<\/code>. If you create a new migrator and would like to share it with the community, please fork the repo, add your migrator, and then open a pull request.<\/p>\n<\/article>","created_at":"2017-10-31T20:26:22+0000","updated_at":"2017-10-31T20:32:27+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":4,"domain_name":"github.com","preview_picture":"https:\/\/avatars3.githubusercontent.com\/u\/339001?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4900"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4899,"title":"Netflix\/astyanax","url":"https:\/\/github.com\/Netflix\/astyanax","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      Readme.markdown\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p>Astyanax is a high level Java client for <a href=\"http:\/\/cassandra.apache.org\">Apache Cassandra<\/a>.\nApache Cassandra is a highly available column oriented database.<\/p>\n<p>Astyanax is currently in use at <a href=\"http:\/\/movies.netflix.com\">Netflix<\/a>, but is being <a href=\"https:\/\/medium.com\/netflix-techblog\/astyanax-retiring-an-old-friend-6cca1de9ac4\">retired<\/a>. Fixes will be made for serious issues, but it is not under active development.<\/p>\n<h2><a href=\"https:\/\/github.com\/Netflix\/astyanax#artifacts\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-artifacts\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Artifacts<\/h2>\n<p>Astyanax jars are published to Maven Central.  As of astyanax 1.56.27 the project has been split into multiple sub project, each of which needs to be pulled in separately.<\/p>\n<p>Required artifacts<\/p>\n<table><thead><tr><th>GroupID\/Org<\/th>\n<th>ArtifactID\/Name<\/th>\n<\/tr><\/thead><tbody><tr><td>com.netflix.astyanax<\/td>\n<td>astyanax-core<\/td>\n<\/tr><tr><td>com.netflix.astyanax<\/td>\n<td>astyanax-thrift<\/td>\n<\/tr><tr><td>com.netflix.astyanax<\/td>\n<td>astyanax-cassandra<\/td>\n<\/tr><\/tbody><\/table><p>Optional artifacts<\/p>\n<table><thead><tr><th>GroupID\/Org<\/th>\n<th>ArtifactID\/Name<\/th>\n<\/tr><\/thead><tbody><tr><td>com.netflix.astyanax<\/td>\n<td>astyanax-queue<\/td>\n<\/tr><tr><td>com.netflix.astyanax<\/td>\n<td>astyanax-entity-mapper<\/td>\n<\/tr><tr><td>com.netflix.astyanax<\/td>\n<td>astyanax-recipes<\/td>\n<\/tr><\/tbody><\/table><h2><a href=\"https:\/\/github.com\/Netflix\/astyanax#features\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-features\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Features<\/h2>\n<p>A quick overview can be found at the <a href=\"http:\/\/techblog.netflix.com\/2012\/01\/announcing-astyanax.html\">Netflix Tech Blog<\/a>. Some features provided by this client:<\/p>\n<ul><li>High level, simple object oriented interface to Cassandra.<\/li>\n<li>Fail-over behavior on the client side.<\/li>\n<li>Connection pool abstraction.  Implementation of a round robin connection pool.<\/li>\n<li>Monitoring abstraction to get event notification from the connection pool.<\/li>\n<li>Complete encapsulation of the underlying Thrift API and structs.<\/li>\n<li>Automatic retry of downed hosts.<\/li>\n<li>Automatic discovery of additional hosts in the cluster.<\/li>\n<li>Suspension of hosts for a short period of time after several timeouts.<\/li>\n<li>Annotations to simplify use of composite columns.<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/Netflix\/astyanax#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<p>Detailed documentation of Astyanax's features and usage can be found on the <a href=\"https:\/\/github.com\/Netflix\/astyanax\/wiki\">wiki<\/a> and the <a href=\"https:\/\/github.com\/Netflix\/astyanax\/wiki\/Getting-Started\">getting started guide<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/Netflix\/astyanax#ancient-history\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-ancient-history\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Ancient History<\/h2>\n<p><a href=\"http:\/\/en.wikipedia.org\/wiki\/Astyanax\">Astyanax<\/a> was the son of <a href=\"http:\/\/en.wikipedia.org\/wiki\/Hector\">Hector<\/a> who was <a href=\"http:\/\/en.wikipedia.org\/wiki\/Cassandra\">Cassandra's<\/a> brother in greek mythology.<\/p>\n<h2><a href=\"https:\/\/github.com\/Netflix\/astyanax#modern-history\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-modern-history\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Modern History<\/h2>\n<p>This work was initially inspired by <a href=\"https:\/\/github.com\/hector-client\/hector\">Hector<\/a>.<\/p>\n<\/article>","created_at":"2017-10-31T20:26:26+0000","updated_at":"2017-10-31T20:32:26+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":1,"domain_name":"github.com","preview_picture":"https:\/\/avatars1.githubusercontent.com\/u\/913567?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4899"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4898,"title":"Untitled","url":"http:\/\/caffinitas.org\/mapper\/","content":"wallabag can't retrieve contents for this article. Please <a href=\"http:\/\/doc.wallabag.org\/en\/master\/user\/errors_during_fetching.html#how-can-i-help-to-fix-that\">troubleshoot this issue<\/a>.\n","created_at":"2017-10-31T20:26:31+0000","updated_at":"2017-10-31T20:32:26+0000","annotations":[],"mimetype":"text\/html","language":"","reading_time":0,"domain_name":"caffinitas.org","http_status":"404","_links":{"self":{"href":"\/api\/entries\/4898"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4897,"title":"Achilles","url":"http:\/\/doanduyhai.github.io\/Achilles\/","content":"<header readability=\"0\"><ul><li class=\"download\"><a class=\"buttons\" href=\"https:\/\/github.com\/doanduyhai\/Achilles\/zipball\/gh-pages\">Download ZIP<\/a><\/li>\n            <li class=\"download\"><a class=\"buttons\" href=\"https:\/\/github.com\/doanduyhai\/Achilles\/tarball\/gh-pages\">Download TAR<\/a><\/li>\n          \n          <li><a class=\"buttons github\" href=\"https:\/\/github.com\/doanduyhai\/Achilles\">View On GitHub<\/a><\/li>\n        <\/ul><\/header><section readability=\"46\"><p><img src=\"https:\/\/raw.github.com\/wiki\/doanduyhai\/Achilles\/assets\/Achilles_New_Logo.png\" alt=\"Achilles\"\/><\/p>\n<p><br\/>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<a href=\"https:\/\/travis-ci.org\/doanduyhai\/Achilles\"><img src=\"https:\/\/travis-ci.org\/doanduyhai\/Achilles.png?branch=master\" alt=\"Build Status\"\/><\/a><\/p>\n<h2 id=\"presentation\">Presentation<\/h2>\n<p>Achilles is an <strong>open source<\/strong>  advanced object mapper for <strong>Apache Cassandra<\/strong>. Among all the features:<\/p>\n<ul><li>Advanced bean mapping (compound primary key, composite partition key, timeUUID, counter, static column \u2026)<\/li>\n  <li>Pluggable <strong>codec system<\/strong> to define your own types<\/li>\n  <li>Life cycle <strong>interceptors<\/strong> to define custom behavior before INSERT\/UPDATE\/DELETE\/SELECT operations<\/li>\n  <li>Fluent <strong>options system<\/strong> to parameter runtime statements (consistency level, retry policy, \u2026)<\/li>\n  <li>Powerful and <strong>type-safe DSL<\/strong> to create your own queries<\/li>\n  <li>Display of DML scripts &amp; DDL statements<\/li>\n  <li>Wrapper to deploy an embedded <strong>Cassandra<\/strong> server easily<\/li>\n  <li>Tight integration with JUnit for productive TDD programming<\/li>\n  <li>Support for Bean Validation (JSR-303)<\/li>\n  <li>Support for <strong>Lightweight Transaction<\/strong> with dedicated listener interface<\/li>\n  <li>Support for <strong>Materialized View<\/strong><\/li>\n  <li>Support for typed-safe <strong>Function calls<\/strong><\/li>\n  <li>Support for the new <strong>JSON<\/strong> API<\/li>\n  <li>Support for multi-project compilation unit<\/li>\n  <li>Support for native index, <strong>SASI<\/strong> and <strong>DSE Search<\/strong><\/li>\n  <li>Flexible naming strategy &amp; insert strategy<\/li>\n  <li>Runtime <strong>Schema Name Provider<\/strong> for multi-tenant environments<\/li>\n  <li>Full compatibility with Java 8 <strong>CompletableFuture<\/strong><\/li>\n<\/ul><blockquote readability=\"8\">\n  <p><strong>Warning: Achilles versions 4.x are no longer maintained, only bug-fixes are supported, please migrate to\nversion 5.x and follow the [Migration From 4.x Guide]<\/strong><\/p>\n<\/blockquote>\n<h2 id=\"installation\">Installation<\/h2>\n<p>Below is the compatibility matrix between <strong>Achilles<\/strong>, <strong>Java Driver<\/strong> and <strong>Cassandra<\/strong> versions<\/p>\n<table border=\"1\"><thead><tr><th>Achilles version<\/th>\n\t\t\t<th>Java Driver version<\/th>\n\t\t\t<th>Cassandra version<\/th>\n\t\t<\/tr><\/thead><tbody readability=\"3\"><tr readability=\"1\"><td>5.2.0 (all Cassandra versions up to 3.7)<\/td>\n       \t    <td>3.1.3<\/td>\n            <td>3.7<\/td>\n        <\/tr><tr readability=\"1\"><td>5.0.0 (all Cassandra versions up to 3.7)<\/td>\n            <td>3.1.0<\/td>\n            <td>3.7<\/td>\n        <\/tr><tr readability=\"1\"><td>4.2.3 (all Cassandra versions up to 3.7)<\/td>\n\t    <td>3.1.0<\/td>\n\t    <td>3.7<\/td>\n\t<\/tr><tr readability=\"1\"><td>4.0.1 (limited to Cassandra 2.2.3 features)<\/td>\n\t    <td>3.0.0-alpha5<\/td>\n\t    <td>2.2.3<\/td>\n\t<\/tr><tr readability=\"1\"><td>3.2.3 (limited to Cassandra 2.1.x features)<\/td>\n\t    <td>2.1.6<\/td>\n\t    <td>2.1.5<\/td>\n\t<\/tr><tr readability=\"1\"><td>3.0.22 (limited to Cassandra 2.0.x features)<\/td>\n\t    <td>2.1.6<\/td>\n\t    <td>2.0.15<\/td>\n\t<\/tr><\/tbody><\/table><blockquote readability=\"7\">\n  <p>Warning: there will be no new features for branches older than <strong>5.0.x<\/strong>. Those branches are\nonly supported for bug fixes. New features will <strong>not<\/strong> be back-ported. Please upgrade to the\nlatest version of <strong>Achilles<\/strong> to benefit from new features<\/p>\n<\/blockquote>\n<p>To use <strong>Achilles<\/strong>, just add the following dependency in your <strong>pom.xml<\/strong>:<\/p>\n<div class=\"language-xml highlighter-rouge\" readability=\"7\"><pre>\t&lt;dependency&gt;\n\t\t&lt;groupId&gt;info.archinnov&lt;\/groupId&gt;\n\t\t&lt;artifactId&gt;achilles-core&lt;\/artifactId&gt;\n\t\t&lt;version&gt;${achilles.version}&lt;\/version&gt;\n\t&lt;\/dependency&gt;\n<\/pre>\n<\/div>\n<p>Do not forget to deactivate <em>incremental compilation<\/em> and use <em>Java 8<\/em> in your <strong>pom.xml<\/strong> file<\/p>\n<div class=\"language-xml highlighter-rouge\" readability=\"8\"><pre>    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;\/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;\/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;1.8&lt;\/source&gt;\n                    &lt;target&gt;1.8&lt;\/target&gt;\n                    &lt;useIncrementalCompilation&gt;false&lt;\/useIncrementalCompilation&gt;\n                &lt;\/configuration&gt;\n            &lt;\/plugin&gt;\n        &lt;\/plugins&gt;\n    &lt;\/build&gt;        \n<\/pre>\n<\/div>\n<blockquote readability=\"4\">\n  <p>Achilles 4.x requires a JDK 8 to work. It is recommended to use JDK 8 update 45 or later<\/p>\n<\/blockquote>\n<p>For unit-testing with embedded Cassandra, add this dependency with <strong>test<\/strong> scope:<\/p>\n<div class=\"language-xml highlighter-rouge\" readability=\"7\"><pre> \t&lt;dependency&gt;\n \t\t&lt;groupId&gt;info.archinnov&lt;\/groupId&gt;\n \t\t&lt;artifactId&gt;achilles-junit&lt;\/artifactId&gt;\n \t\t&lt;version&gt;${achilles.version}&lt;\/version&gt;\n \t\t&lt;scope&gt;test&lt;\/scope&gt;\n \t&lt;\/dependency&gt;\n<\/pre>\n<\/div>\n<p>For now, <strong>Achilles<\/strong> depends on the following libraries:<\/p>\n<ol><li>cassandra (see matrix version above)<\/li>\n  <li>cassandra-driver-core (see matrix version above)<\/li>\n  <li>Jackson core, annotations, databind &amp; module jaxb annotations 2.3.3<\/li>\n  <li>Google Auto Common 0.4<\/li>\n  <li>Google Auto Service 1.0-rc2<\/li>\n  <li>Java Poet 1.5.1<\/li>\n  <li>Guava 18.0<\/li>\n  <li>slf4j-api 1.7.2<\/li>\n  <li>commons-io 2.4<\/li>\n  <li>commons-lang3 3.3.2<\/li>\n  <li>commons-collections 3.2.1<\/li>\n  <li>validation-api 1.1.0.Final<\/li>\n  <li>org.eclipse.jdt.core.compiler-ecj 4.4.2<\/li>\n<\/ol><h2 id=\"configure-your-ide\">Configure Your IDE<\/h2>\n<p><strong>Achilles<\/strong> is using code generation at compile time through annotation processors, you\u2019ll need to configure your IDE carefully. \n Please follow the <strong><a href=\"https:\/\/github.com\/doanduyhai\/Achilles\/wiki\/IDE-configuration\">IDE Configuration<\/a><\/strong> guide<\/p>\n<h2 id=\"5-minutes-tutorial\">5 minutes tutorial<\/h2>\n<p>To boostrap quickly with <strong>Achilles<\/strong>, you can check the <strong><a href=\"https:\/\/github.com\/doanduyhai\/Achilles\/wiki\/5-minutes-Tutorial\">5 minutes tutorial<\/a><\/strong><\/p>\n<h2 id=\"quick-reference\">Quick Reference<\/h2>\n<p>To be productive quickly with <strong>Achilles<\/strong>. Most of useful examples are given in the <strong><a href=\"https:\/\/github.com\/doanduyhai\/Achilles\/wiki\/Quick-Reference\">Quick Reference<\/a><\/strong><\/p>\n<h2 id=\"advanced-tutorial\">Advanced tutorial<\/h2>\n<p>To get a deeper look on how you can use <strong>Achilles<\/strong>, check out the <strong><a href=\"https:\/\/github.com\/doanduyhai\/Achilles\/wiki\/Advanced-Tutorial:-KillrChat\">KillrChat<\/a><\/strong> application<\/p>\n<h2 id=\"documentation\">Documentation<\/h2>\n<p>All the documentation and tutorial is available in the <strong><a href=\"https:\/\/github.com\/doanduyhai\/Achilles\/wiki\">Wiki<\/a><\/strong><\/p>\n<p>Versioned documentation is available at <strong><a href=\"https:\/\/github.com\/doanduyhai\/Achilles\/tree\/master\/documentation\/versions\">Documentation<\/a><\/strong><\/p>\n<h2 id=\"mailing-list\">Mailing list<\/h2>\n<p>For any question, bug encountered, you can use the <strong><a href=\"https:\/\/groups.google.com\/forum\/?hl=fr#!forum\/cassandra-achilles\">mailing list<\/a><\/strong><\/p>\n<h2 id=\"license\">License<\/h2>\n<p>Copyright 2012-2016 DuyHai DOAN<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d); you may not use this application except in compliance with the License. You may obtain a copy of the License at<\/p>\n<p>http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/p>\n<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.<\/p>\n      <\/section>","created_at":"2017-10-31T20:26:35+0000","updated_at":"2017-10-31T20:32:25+0000","annotations":[],"mimetype":"text\/html","language":"","reading_time":4,"domain_name":"doanduyhai.github.io","preview_picture":"https:\/\/raw.github.com\/wiki\/doanduyhai\/Achilles\/assets\/Achilles_New_Logo.png","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4897"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4896,"title":"thobbs\/phpcassa \u00b7 GitHub","url":"https:\/\/github.com\/thobbs\/phpcassa","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.mkd\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p><a href=\"http:\/\/travis-ci.org\/thobbs\/phpcassa\"><img src=\"https:\/\/camo.githubusercontent.com\/818a30af972b5a12ce7226dcc42cea98c2e58be5\/68747470733a2f2f7365637572652e7472617669732d63692e6f72672f74686f6262732f70687063617373612e706e673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https:\/\/secure.travis-ci.org\/thobbs\/phpcassa.png?branch=master\"\/><\/a><\/p>\n<p>phpcassa is a PHP client library for <a href=\"http:\/\/cassandra.apache.org\">Apache Cassandra<\/a>.<\/p>\n<ul><li>Compatible with Cassandra 0.7 through 1.2<\/li>\n<li>Optional C extension for improved performance<\/li>\n<\/ul><p>phpcassa is compatible with PHP 5.3+<\/p>\n<p>phpcassa is open source under the <a href=\"http:\/\/www.opensource.org\/licenses\/mit-license.php\">MIT license<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/thobbs\/phpcassa#deprecated\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-deprecated\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Deprecated<\/h2>\n<p>At this point, <strong>phpcassa has been deprecated and will no longer be supported<\/strong>.<\/p>\n<p>I suggest using the DataStax PHP driver located here: <a href=\"https:\/\/github.com\/datastax\/php-driver\">https:\/\/github.com\/datastax\/php-driver<\/a>.  It supports CQL, has many excellent features, and is well maintained.<\/p>\n<h2><a href=\"https:\/\/github.com\/thobbs\/phpcassa#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<p>While this README includes some useful information, the official and more\nthorough documentation can be found here:<\/p>\n<p><a href=\"http:\/\/thobbs.github.com\/phpcassa\">http:\/\/thobbs.github.com\/phpcassa<\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/thobbs\/phpcassa#examples\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-examples\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Examples<\/h2>\n<p>You can find a few fully working example scripts in the <code>examples\/<\/code> directory.<\/p>\n<h3><a href=\"https:\/\/github.com\/thobbs\/phpcassa#opening-connections\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-opening-connections\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Opening Connections<\/h3>\n<div class=\"highlight highlight-text-html-php\"><pre>$pool = new ConnectionPool('Keyspace1');<\/pre><\/div>\n<p>or<\/p>\n<div class=\"highlight highlight-text-html-php\"><pre>$pool = new ConnectionPool('Keyspace1', array('localhost'));<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/thobbs\/phpcassa#create-a-column-family-object\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-create-a-column-family-object\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Create a column family object<\/h3>\n<div class=\"highlight highlight-text-html-php\"><pre>$users = new ColumnFamily($pool, 'Standard1');\n$super = new SuperColumnFamily($pool, 'Super1');<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/thobbs\/phpcassa#inserting\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-inserting\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Inserting<\/h3>\n<div class=\"highlight highlight-text-html-php\"><pre>$users-&gt;insert('key', array('column1' =&gt; 'value1', 'column2' =&gt; 'value2'));<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/thobbs\/phpcassa#querying\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-querying\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Querying<\/h3>\n<div class=\"highlight highlight-text-html-php\"><pre>$users-&gt;get('key');\n$users-&gt;multiget(array('key1', 'key2'));<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/thobbs\/phpcassa#removing\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-removing\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Removing<\/h3>\n<div class=\"highlight highlight-text-html-php\"><pre>$users-&gt;remove('key1'); \/\/ removes whole row\n$users-&gt;remove('key1', 'column1'); \/\/ removes 'column1'<\/pre><\/div>\n<h3><a href=\"https:\/\/github.com\/thobbs\/phpcassa#other\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-other\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Other<\/h3>\n<div class=\"highlight highlight-text-html-php\"><pre>$users-&gt;get_count('key1'); \/\/ counts the number of columns in row 'key1'\n$users-&gt;get_range('key1', 'key9'); \/\/ gets all rows with keys between '1' and '9'<\/pre><\/div>\n<h2><a href=\"https:\/\/github.com\/thobbs\/phpcassa#using-the-c-extension\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-using-the-c-extension\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Using the C Extension<\/h2>\n<p>The C extension is crucial for phpcassa's performance.<\/p>\n<p>You need to configure and make to be able to use the C extension.<\/p>\n<p><em>Note<\/em>: if <code>checkinstall<\/code> is available, run <code>sudo checkinstall<\/code> in place of\n<code>sudo make install<\/code>.<\/p>\n<div class=\"highlight highlight-source-shell\"><pre>cd ext\/thrift_protocol\nphpize\n.\/configure\nmake\nsudo make install<\/pre><\/div>\n<p>Add the following line to your php.ini file:<\/p>\n<pre>extension=thrift_protocol.so\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/thobbs\/phpcassa#getting-help\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-help\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting Help<\/h2>\n<ul><li>Mailing list: <a href=\"http:\/\/groups.google.com\/group\/phpcassa\">phpcassa on google groups<\/a><\/li>\n<li>IRC: Channel #cassandra on irc.freenode.net<\/li>\n<\/ul><\/article>","created_at":"2017-10-31T20:26:39+0000","updated_at":"2017-10-31T20:32:25+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":1,"domain_name":"github.com","preview_picture":"https:\/\/avatars1.githubusercontent.com\/u\/355580?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4896"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4895,"title":"Cassandra Parameters for Dummies","url":"https:\/\/www.ecyrd.com\/cassandracalculator\/","content":"<p>This simple form allows you to try out different values for your <a href=\"http:\/\/cassandra.apache.org\">Apache Cassandra<\/a> cluster\nand see what the impact is for your application.<\/p><div alt=\"form\">\n<p>\n  <label for=\"N\">Cluster size<\/label>\n  <\/p>\n<p>\n  <label for=\"RF\">Replication Factor<\/label>\n  <\/p>\n<p>\n  <label for=\"W\">Write Level<\/label>\n  <\/p>\n<p>\n  <label for=\"R\">Read Level<\/label>\n  <\/p>\n<hr\/><div class=\"calculated\" readability=\"19\">\n   Your reads are \n   <p>\"Consistent\" means that for this particular Read\/Write level combo, all nodes will \"see\" the same data.  \"Eventually consistent\" means\n        that you might get old data from some nodes and new data for others until the data has been replicated across all devices.  The idea is that this way you can\n        increase read\/write speeds and improve tolerance against dead nodes.<\/p>\n<\/div>\n<div class=\"calculated\" readability=\"18\">\n   You can survive the loss of  without impacting the application.\n   <p>How many nodes can go down without application noticing? This is a lower bound - in large clusters, you could lose more nodes and if they happen to be handling different parts of the keyspace, then you wouldn't notice either.<\/p>\n<\/div>\n<div class=\"calculated\" readability=\"20\">\n    You can survive the loss of  without data loss.\n    <p>How many nodes can go down without physically losing data? This is a lower bound - in large clusters, you could lose more nodes and if they happen to be handling different parts of the keyspace, then you wouldn't notice either.<\/p>\n<\/div>\n<div class=\"calculated\" readability=\"18\">\n   You are really reading from  every time.\n   <p>The more nodes you read from, more network traffic ensues, and the bigger the latencies involved.  Cassandra read operation won't return until at least this many nodes have responded with some data value.<\/p>\n<\/div>\n<div class=\"calculated\" readability=\"18\">\n   You are really writing to  every time.\n   <p>The more nodes you write to, more network traffic ensues, and the bigger the latencies involved. Cassandra write operation won't return until at least this many nodes have acknowledged receiving the data.<\/p>\n<\/div>\n<div class=\"calculated\" readability=\"28\">\n   Each node holds  of your data.\n   <p>The bigger your cluster is, the more the data gets distributed across your nodes.  If you are using the RandomPartitioner, or are very\n   good at distributing your keys when you use OrderedPartitioner, this is how much data each of your nodes has to handle.  This is also how much\n   of your keyspace becomes inaccessible for each node that you lose beyond the safe limit, above.<\/p>\n<\/div>\n<\/div>","created_at":"2017-10-31T20:26:44+0000","updated_at":"2017-10-31T20:32:25+0000","annotations":[],"mimetype":"text\/html","language":"","reading_time":1,"domain_name":"www.ecyrd.com","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4895"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4894,"title":"nicolasff\/docker-cassandra","url":"https:\/\/github.com\/nicolasff\/docker-cassandra","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p>This repository contains a set of scripts and configuration files to run a Cassandra cluster\nfrom <a href=\"https:\/\/www.docker.io\/\">Docker<\/a> containers. The current version of this repository is\nconfigured to create a Cassandra 1.2 or 2.0 image and cluster.<\/p>\n<p>Example:<\/p>\n<p><a href=\"https:\/\/camo.githubusercontent.com\/11ba2859ff53686f3a22a8eb29e63a811a1e25cd\/68747470733a2f2f692e696d6775722e636f6d2f705338747761332e676966\" target=\"_blank\"><img src=\"https:\/\/camo.githubusercontent.com\/11ba2859ff53686f3a22a8eb29e63a811a1e25cd\/68747470733a2f2f692e696d6775722e636f6d2f705338747761332e676966\" alt=\"Sample session\" data-canonical-src=\"https:\/\/i.imgur.com\/pS8twa3.gif\"\/><\/a><\/p>\n<p>Cassandra nodes are created with their own IP address and configured hostname:<\/p>\n<pre>$ .\/start-cluster.sh 2.0.3 3\nStarting node 1\nStarting node 2\nStarting node 3\n$ .\/client.sh 2.0.3 nodetool -h cass1 status\nDatacenter: datacenter1\n=======================\nStatus=Up\/Down\n|\/ State=Normal\/Leaving\/Joining\/Moving\n--  Address        Load       Tokens  Owns   Host ID                               Rack\nUN  192.168.100.3  40.84 KB   256     34.9%  9d4a223f-e80e-4b50-b379-0705b1c8971d  rack1\nUN  192.168.100.1  38.93 KB   256     33.7%  5128dcb0-14d0-4d17-9b53-acc8f9a0844b  rack1\nUN  192.168.100.2  30.92 KB   256     31.4%  8e6faaba-601f-4812-a33b-05ceaecf1159  rack1\n<\/pre>\n<p>Note that the nodes might take about 30 seconds to show up as they join the Cassandra ring.<\/p>\n<p>The shell scripts all assume that you have <code>sudo<\/code> privilege.<\/p>\n<h2><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#getting-started\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-started\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting started<\/h2>\n<h3><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#1-check-out-this-repository\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-1-check-out-this-repository\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>1. Check out this repository<\/h3>\n<pre>$ git clone https:\/\/github.com\/nicolasff\/docker-cassandra.git\n$ cd docker-cassandra\n<\/pre>\n<h3><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#2-install-pipework\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-2-install-pipework\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>2. Install pipework<\/h3>\n<p>Make sure that the bundled script <code>pipework<\/code> is in your path. You can install it with:<\/p>\n<pre>$ sudo cp install\/bin\/pipework \/usr\/bin\/\n<\/pre>\n<p>The latest version is on GitHub at <a href=\"https:\/\/github.com\/jpetazzo\/pipework\">https:\/\/github.com\/jpetazzo\/pipework<\/a>.<\/p>\n<h3><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#3-create-a-docker-image-for-cassandra\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-3-create-a-docker-image-for-cassandra\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>3. Create a Docker image for Cassandra<\/h3>\n<p>To create a Cassandra 2.0.3 image and tag it, run:<\/p>\n<pre>$ make image VERSION=2.0.3\n<\/pre>\n<p>You should then see it appear in your list of Docker images:<\/p>\n<pre>$ sudo docker images\nREPOSITORY          TAG                 ID                  CREATED              SIZE\ncassandra           2.0.3              b9ba84a33bb5        About a minute ago   12.29 kB (virtual 404.7 MB)\n$ .\/list-images.sh\n2.0.3\n<\/pre>\n<h3><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#4-start-a-cluster\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-4-start-a-cluster\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>4. Start a cluster<\/h3>\n<p>Run <code>.\/start-cluster.sh 2.0.3 3<\/code> to create a cluster of 3 nodes running Cassandra 2.0.3. They are given an IP address and name each, from <code>cass1<\/code> (<code>192.168.100.1<\/code>) to <code>cass3<\/code> (<code>192.168.100.3<\/code>).<\/p>\n<p>Run <code>sudo docker ps<\/code> to list your Cassandra nodes:<\/p>\n<pre>$ sudo docker ps\nID                  IMAGE               COMMAND                CREATED             STATUS              PORTS\n99d67692f535        cassandra:2.0.3    \/usr\/bin\/start-cassa   10 minutes ago      Up 10 minutes       49332-&gt;9160         \nfe7e2b13cb9e        cassandra:2.0.3    \/usr\/bin\/start-cassa   10 minutes ago      Up 10 minutes       49331-&gt;9160         \nf21da380b00c        cassandra:2.0.3    \/usr\/bin\/start-cassa   10 minutes ago      Up 10 minutes       49330-&gt;9160  \n<\/pre>\n<h3><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#5-connect-to-your-cluster\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-5-connect-to-your-cluster\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>5. Connect to your cluster<\/h3>\n<p>Cassandra nodes expose port 9160 for Thrift. Use <code>sudo docker port &lt;container-id&gt; 9160<\/code> or <code>sudo docker ps<\/code> to find the local port it is mapped to.<\/p>\n<p><code>client.sh<\/code> creates a docker container with access to the Cassandra cluster network (<code>192.168.100.0\/24<\/code>). The first client is given the name <code>cass254<\/code>\nwith IP <code>192.168.100.254<\/code>, the next one <code>cass253<\/code>, etc. Names are reused when client containers are stopped.<\/p>\n<p><code>client.sh<\/code> runs any command that is passed to it, e.g. <code>nodetool<\/code>, <code>cassandra-cli<\/code>, <code>cqlsh<\/code>... You can also open a shell with <code>.\/client.sh 2.0.3 bash<\/code>.<\/p>\n<h3><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#6-terminate-your-cluster\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-6-terminate-your-cluster\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>6. Terminate your cluster<\/h3>\n<pre>$ .\/stop-cluster.sh 2.0.3\nKilling and removing containers 99d67692f535 fe7e2b13cb9e f21da380b00c\n$ sudo docker ps\nID                  IMAGE               COMMAND             CREATED             STATUS              PORTS\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra#licensing-and-contributions\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-licensing-and-contributions\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Licensing and contributions<\/h2>\n<p>This set of scripts and configuration files is released under the <a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra\/blob\/master\/LICENSE\">Apache 2.0 License<\/a>.\n<code>pipework<\/code> is Copyright 2013 <a href=\"https:\/\/github.com\/jpetazzo\">J\u00e9r\u00f4me Petazzoni<\/a> and distributed under the Apache 2.0 license.<\/p>\n<p>Contributions and suggestions welcome <a href=\"https:\/\/github.com\/nicolasff\/docker-cassandra\/issues\">on GitHub<\/a> or <a href=\"https:\/\/twitter.com\/yowgi\">on Twitter<\/a>.<\/p>\n<\/article>","created_at":"2017-10-31T20:26:48+0000","updated_at":"2017-10-31T20:32:24+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":2,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/11ba2859ff53686f3a22a8eb29e63a811a1e25cd\/68747470733a2f2f692e696d6775722e636f6d2f705338747761332e676966","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4894"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4893,"title":"academyofdata\/cassandra-zeppelin","url":"https:\/\/github.com\/academyofdata\/cassandra-zeppelin","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p>This is a repository for a couple of docker-compose scripts, one of which that creates two Docker containers - one with a Zeppelin instance and the other one with a Cassandra node, the other one starting 4 containers - one with Zeppelin and 3 with a Cassandra three node cluster<\/p>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#configuration-and-installation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-configuration-and-installation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Configuration and Installation<\/h2>\n<p>Make sure to have a valid Docker and docker-compose Installation, running on a 64-bit system (either directly on a mac or Linux machine, or on a VirtualBox - or similar - VM running a 64-bit guest; this means that you'll end up running Docker inside a VM, this is fine for testing and learning purposes).<\/p>\n<p>To install\/configure Docker and\/or Docker Compose follow the steps described at <a href=\"https:\/\/docs.docker.com\/compose\/install\/\">https:\/\/docs.docker.com\/compose\/install\/<\/a> and <a href=\"https:\/\/docs.docker.com\/engine\/installation\/linux\/ubuntu\/\">https:\/\/docs.docker.com\/engine\/installation\/linux\/ubuntu\/<\/a> (this is for Ubuntu based Linux systems)<\/p>\n<p>As a last step, clone this repository (you might need to do first <code>apt-get install git<\/code>)<\/p>\n<pre>git clone https:\/\/github.com\/academyofdata\/cassandra-zeppelin\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#starting-a-single-node-cassandra--zeppelin-instance\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-starting-a-single-node-cassandra--zeppelin-instance\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Starting a single node Cassandra + Zeppelin instance<\/h2>\n<p>Once the docker &amp; docker-compose prerequisites are met and the repository is cloned (example below assumes it is cloned in a folder called cassandra-zeppelin), do the following<\/p>\n<pre>cd cassandra-zeppelin\ndocker-compose build\ndocker-compose up -d\n<\/pre>\n<p>Assuming that you haven't encountered problems during build or run phase, you can now test that the containers are running by issuing the following command<\/p>\n<pre>docker ps\n<\/pre>\n<p>which should have an output similar with the one below<\/p>\n<pre>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                                                      NAMES\n110e8f4b16b3        zeppelin_zeppelin   \"bin\/zeppelin.sh\"        4 days ago          Up 3 days           0.0.0.0:4040-&gt;4040\/tcp, 0.0.0.0:8080-8081-&gt;8080-8081\/tcp                                                   zeppelin_zeppelin_1\nbbb70c263987        cassandra:3.9       \"\/docker-entrypoint.s\"   4 days ago          Up 3 days           0.0.0.0:7000-7001-&gt;7000-7001\/tcp, 0.0.0.0:7199-&gt;7199\/tcp, 0.0.0.0:9042-&gt;9042\/tcp, 0.0.0.0:9160-&gt;9160\/tcp   zeppelin_cassandra_1\n<\/pre>\n<p>(pay attention in special to the STATUS column - it should say Up and not Exited)\nOnce the containers are running you can go to <a href=\"http:\/\/virtualmachineip:8080\">http:\/\/virtualmachineip:8080<\/a> (replace with your own VirtualBox or local machine IP) and you should see the Zeppelin interface<\/p>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#starting-a-zeppelin-instance-connected-to-a-cassandra-cluster-with-3-nodes\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-starting-a-zeppelin-instance-connected-to-a-cassandra-cluster-with-3-nodes\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Starting a Zeppelin instance connected to a Cassandra cluster (with 3 nodes)<\/h2>\n<p><em><strong>PLEASE NOTE<\/strong><\/em>\nIf you've previously started other containers with Zeppelin (for instance the Zeppelin + a single Cassandra node as outlined above), make sure to stop them before starting the instance connected to the cluster. You can do that with<\/p>\n<pre>docker-compose stop\n<\/pre>\n<p>Otherwise there will be port conflicts when attempting to start the new cluster and the new Zeppelin instance.<\/p>\n<p>Start with this more complex configuration by issuing the command below (in the same folder where you've cloned this git repository)<\/p>\n<pre>docker-compose -f docker-cluster.yml up -d\n<\/pre>\n<p>After starting check that the containers are running (<code>docker ps -a<\/code>), wait for a few seconds (20-30 should be enough), log into one of the cassandra nodes (<code>docker exec -ti zeppelin_node01_1 bash<\/code>) and check the cluster status (run this in the container)<\/p>\n<pre>nodetool status\n<\/pre>\n<p>If the cluster started correctly you should see back a few lines, three of them starting with UN, like this<\/p>\n<pre>Datacenter: datacenter1\n=======================\nStatus=Up\/Down\n|\/ State=Normal\/Leaving\/Joining\/Moving\n--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  172.17.0.3  110.13 KiB  256          67.6%             5460abe0-cf14-4d87-bf11-04f4ccd3f14c  rack1\nUN  172.17.0.2  108.46 KiB  256          62.0%             17d1e7cd-2ff6-4397-8495-a42c12a3807f  rack1\nUN  172.17.0.4  103.09 KiB  256          70.4%             70d2d32c-d7cd-4662-9e98-906167b0e4b7  rack1\n<\/pre>\n<p>This means that all the nodes are up (U) and operating normally (N)<\/p>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#bulk-loading-data-in-cassandra\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-bulk-loading-data-in-cassandra\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Bulk-Loading data in Cassandra<\/h2>\n<p><em><strong>PLEASE NOTE<\/strong><\/em>\nIf you already have a 'test' keyspace it's better to drop it before executing the steps below.<\/p>\n<p>To load all the exercise data into a newly created \"test\" keyspace and creating all the required tables, run the following command inside the Cassandra container (if you have an existing \"test\" keyspace, drop it)<\/p>\n<pre>apt-get update &amp;&amp; apt-get install -y wget &amp;&amp; wget -qO- https:\/\/raw.githubusercontent.com\/academyofdata\/cassandra-zeppelin\/master\/script.sh | bash\n<\/pre>\n<p>(to log into the container run 'docker exec -ti containers_cassandra_1 bash' from your container host, after you check the exact name of your container with 'docker ps -a')<\/p>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#connecting-zeppelin-to-cassandra\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-connecting-zeppelin-to-cassandra\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Connecting Zeppelin to Cassandra<\/h2>\n<p>To be able to run queries from Zeppelin against a cassandra cluster (or a single node) we need to instruct Zeppelin's interpreter for Cassandra to connect to the right host. Since when using docker-compose we've specified that the cassandra container (or, when using a cluster, one of the containers) is available as the host 'cassandra', we just need adjust a single  configuration value. For this, click in the right top corner of Zeppelin the \"Anonymous\" button to open the menu with a few options, one of which is \"Interpreter\"<\/p>\n<p><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin\/blob\/master\/assets\/1.png\" target=\"_blank\"><img src=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin\/raw\/master\/assets\/1.png\"\/><\/a><\/p>\n<p>Once on that page scroll to the Cassandra section and edit the value for <strong>cassandra.hosts<\/strong> to read <strong>cassandra<\/strong> as shown below<\/p>\n<p><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin\/blob\/master\/assets\/2.png\" target=\"_blank\"><img src=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin\/raw\/master\/assets\/2.png\"\/><\/a><\/p>\n<p><em><strong>NOTE<\/strong><\/em>\nWe could configure Zeppelin to connect to any of the hosts when running in the cluster configuration. For this we would first need to ammend the docker-compose configuration to also link the other nodes into zeppelin (in \"links\" section) and then we could set the cassandra.hosts to the hostnames separated by comma (e.g. \"cassandra,cassandra2,cassandra3\")<\/p>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#starting-containers-without-docker-compose\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-starting-containers-without-docker-compose\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Starting containers without docker-compose<\/h2>\n<p>Assuming that you already have a running Cassandra container, in order to connect a new zeppelin instance to it run the following<\/p>\n<pre>docker run -d -p 8080:8080 -p 8081:8081 -p 4040:4040 -e MASTER=\"local[*]\" -e ZEPPELIN_PORT=\"8080\" -e ZEPPELIN_JAVA_OPTS=\"-Dspark.driver.memory=1g -Dspark.executor.memory=2g\" -e SPARK_SUBMIT_OPTS=\"--conf spark.driver.host=localhost --conf spark.driver.port=8081\" --link &lt;id_or_name_of_cassandra_container&gt;:cassandra --name zeppelin dylanmei\/zeppelin\n<\/pre>\n<p>after the container starts run<\/p>\n<pre>docker exec -ti `docker ps --format '{{.Names}}' | grep zeppelin` bash -c \"\/usr\/zeppelin\/bin\/install-interpreter.sh --name cassandra\"\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#starting-a-zeppelin-only-instance\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-starting-a-zeppelin-only-instance\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Starting a Zeppelin only instance<\/h2>\n<p>Edit the docker-compose.yml file to read as below<\/p>\n<pre>zeppelin:\n  image:  dylanmei\/zeppelin\n  environment:\n    ZEPPELIN_PORT: 8080\n    ZEPPELIN_JAVA_OPTS: &gt;-\n      -Dspark.driver.memory=1g\n      -Dspark.executor.memory=2g\n    SPARK_SUBMIT_OPTIONS: &gt;-\n      --conf spark.driver.host=localhost\n      --conf spark.driver.port=8081\n      \n    MASTER: local[*]\n  ports:\n    - 8080:8080\n    - 8081:8081\n    - 4040:4040\n  volumes:\n    - .\/znotebooks:\/usr\/zeppelin\/notebook\n<\/pre>\n<p>and issue the same docker-compose up -d command<\/p>\n<h2><a href=\"https:\/\/github.com\/academyofdata\/cassandra-zeppelin#get_num_processes\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-get_num_processes\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>get_num_processes<\/h2>\n<p>If you get a <em><strong>get_num_processes() takes no keyword arguments error<\/strong><\/em>, get out of cqlsh (but stay in the container shell, not on the host system) and run<\/p>\n<p>rm \/usr\/lib\/pymodules\/python2.7\/cqlshlib\/copyutil.so<\/p>\n<\/article>","created_at":"2017-10-31T20:26:52+0000","updated_at":"2017-10-31T20:32:24+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":5,"domain_name":"github.com","preview_picture":"https:\/\/github.com\/academyofdata\/cassandra-zeppelin\/blob\/master\/assets\/1.png","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4893"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4892,"title":"datastax\/spark-cassandra-connector","url":"https:\/\/github.com\/datastax\/spark-cassandra-connector","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#quick-links\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-quick-links\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Quick Links<\/h2>\n<table><thead><tr><th>What<\/th>\n<th>Where<\/th>\n<\/tr><\/thead><tbody><tr><td>Packages<\/td>\n<td><a href=\"https:\/\/spark-packages.org\/package\/datastax\/spark-cassandra-connector\">Spark Cassandra Connector Spark Packages Website<\/a><\/td>\n<\/tr><tr><td>Community<\/td>\n<td>Chat with us at <a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#slack\">DataStax Academy's #spark-connector Slack channel<\/a><\/td>\n<\/tr><tr><td>Scala Docs<\/td>\n<td>Most Recent Release (2.0.5): <a href=\"https:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/2.0.4\/spark-cassandra-connector\/\">Spark-Cassandra-Connector<\/a>, <a href=\"https:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/2.0.4\/spark-cassandra-connector-embedded\/\">Embedded-Cassandra<\/a><\/td>\n<\/tr><\/tbody><\/table><h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#features\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-features\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Features<\/h2>\n<p><em>Lightning-fast cluster computing with Apache Spark\u2122 and Apache Cassandra\u00ae.<\/em><\/p>\n<p>This library lets you expose Cassandra tables as Spark RDDs, write Spark RDDs to Cassandra tables, and\nexecute arbitrary CQL queries in your Spark applications.<\/p>\n<ul><li>Compatible with Apache Cassandra version 2.0 or higher (see table below)<\/li>\n<li>Compatible with Apache Spark 1.0 through 2.0 (see table below)<\/li>\n<li>Compatible with Scala 2.10 and 2.11<\/li>\n<li>Exposes Cassandra tables as Spark RDDs<\/li>\n<li>Maps table rows to CassandraRow objects or tuples<\/li>\n<li>Offers customizable object mapper for mapping rows to objects of user-defined classes<\/li>\n<li>Saves RDDs back to Cassandra by implicit <code>saveToCassandra<\/code> call<\/li>\n<li>Delete rows and columns from cassandra by implicit <code>deleteFromCassandra<\/code> call<\/li>\n<li>Join with a subset of Cassandra data using <code>joinWithCassandraTable<\/code> call<\/li>\n<li>Partition RDDs according to Cassandra replication using <code>repartitionByCassandraReplica<\/code> call<\/li>\n<li>Converts data types between Cassandra and Scala<\/li>\n<li>Supports all Cassandra data types including collections<\/li>\n<li>Filters rows on the server side via the CQL <code>WHERE<\/code> clause<\/li>\n<li>Allows for execution of arbitrary CQL statements<\/li>\n<li>Plays nice with Cassandra Virtual Nodes<\/li>\n<li>Works with PySpark DataFrames<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#version-compatibility\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-version-compatibility\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Version Compatibility<\/h2>\n<p>The connector project has several branches, each of which map into different\nsupported versions of  Spark and Cassandra. For previous releases the branch is\nnamed \"bX.Y\" where X.Y is the major+minor version; for example the \"b1.6\" branch\ncorresponds to the 1.6 release. The \"master\" branch will normally contain\ndevelopment for the next connector release in progress.<\/p>\n<table><thead><tr><th>Connector<\/th>\n<th>Spark<\/th>\n<th>Cassandra<\/th>\n<th>Cassandra Java Driver<\/th>\n<th>Minimum Java Version<\/th>\n<th>Supported Scala Versions<\/th>\n<\/tr><\/thead><tbody><tr><td>2.0<\/td>\n<td>2.0, 2.1, 2.2<\/td>\n<td>2.1.5*, 2.2, 3.0<\/td>\n<td>3.0<\/td>\n<td>8<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><tr><td>1.6<\/td>\n<td>1.6<\/td>\n<td>2.1.5*, 2.2, 3.0<\/td>\n<td>3.0<\/td>\n<td>7<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><tr><td>1.5<\/td>\n<td>1.5, 1.6<\/td>\n<td>2.1.5*, 2.2, 3.0<\/td>\n<td>3.0<\/td>\n<td>7<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><tr><td>1.4<\/td>\n<td>1.4<\/td>\n<td>2.1.5*<\/td>\n<td>2.1<\/td>\n<td>7<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><tr><td>1.3<\/td>\n<td>1.3<\/td>\n<td>2.1.5*<\/td>\n<td>2.1<\/td>\n<td>7<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><tr><td>1.2<\/td>\n<td>1.2<\/td>\n<td>2.1, 2.0<\/td>\n<td>2.1<\/td>\n<td>7<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><tr><td>1.1<\/td>\n<td>1.1, 1.0<\/td>\n<td>2.1, 2.0<\/td>\n<td>2.1<\/td>\n<td>7<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><tr><td>1.0<\/td>\n<td>1.0, 0.9<\/td>\n<td>2.0<\/td>\n<td>2.0<\/td>\n<td>7<\/td>\n<td>2.10, 2.11<\/td>\n<\/tr><\/tbody><\/table><p>*<em>Compatible with 2.1.X where X &gt;= 5<\/em><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#hosted-api-docs\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-hosted-api-docs\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Hosted API Docs<\/h2>\n<p>API documentation for the Scala and Java interfaces are available online:<\/p>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#205\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-205\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>2.0.5<\/h3>\n<ul><li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/2.0.5\/spark-cassandra-connector\/\">Spark-Cassandra-Connector<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/2.0.5\/spark-cassandra-connector-embedded\/\">Embedded-Cassandra<\/a><\/li>\n<\/ul><h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#169\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-169\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>1.6.9<\/h3>\n<ul><li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.6.9\/spark-cassandra-connector\/\">Spark-Cassandra-Connector<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.6.9\/spark-cassandra-connector-embedded\/\">Embedded-Cassandra<\/a><\/li>\n<\/ul><h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#152\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-152\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>1.5.2<\/h3>\n<ul><li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.5.2\/spark-cassandra-connector\/\">Spark-Cassandra-Connector<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.5.2\/spark-cassandra-connector-java\/\">Spark-Cassandra-Connector-Java<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.5.0\/spark-cassandra-connector-embedded\/\">Embedded-Cassandra<\/a><\/li>\n<\/ul><h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#145\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-145\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>1.4.5<\/h3>\n<ul><li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.4.5\/spark-cassandra-connector\/\">Spark-Cassandra-Connector<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.4.5\/spark-cassandra-connector-java\/\">Spark-Cassandra-Connector-Java<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.4.2\/spark-cassandra-connector-embedded\/\">Embedded-Cassandra<\/a><\/li>\n<\/ul><h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#131\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-131\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>1.3.1<\/h3>\n<ul><li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.3.1\/spark-cassandra-connector\/\">Spark-Cassandra-Connector<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.3.1\/spark-cassandra-connector-java\/\">Spark-Cassandra-Connector-Java<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.3.1\/spark-cassandra-connector-embedded\/\">Embedded-Cassandra<\/a><\/li>\n<\/ul><h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#120\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-120\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>1.2.0<\/h3>\n<ul><li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.2.0\/spark-cassandra-connector\/\">Spark-Cassandra-Connector<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.2.0\/spark-cassandra-connector-java\/\">Spark-Cassandra-Connector-Java<\/a><\/li>\n<li><a href=\"http:\/\/datastax.github.io\/spark-cassandra-connector\/ApiDocs\/1.2.0\/spark-cassandra-connector-embedded\/\">Embedded-Cassandra<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#download\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-download\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Download<\/h2>\n<p>This project is available on Spark Packages; this is the easiest way to start using the connector:\n<a href=\"https:\/\/spark-packages.org\/package\/datastax\/spark-cassandra-connector\">https:\/\/spark-packages.org\/package\/datastax\/spark-cassandra-connector<\/a><\/p>\n<p>This project has also been published to the Maven Central Repository.\nFor SBT to download the connector binaries, sources and javadoc, put this in your project\nSBT config:<\/p>\n<pre>libraryDependencies += \"com.datastax.spark\" %% \"spark-cassandra-connector\" % \"2.0.3\"\n<\/pre>\n<ul><li>The default Scala version for Spark 2.0+ is 2.11 please choose the appropriate build. See the\n<a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/FAQ.md\">FAQ<\/a> for more information<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#building\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-building\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Building<\/h2>\n<p>See <a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/12_building_and_artifacts.md\">Building And Artifacts<\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#documentation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-documentation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Documentation<\/h2>\n<ul><li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/0_quick_start.md\">Quick-start guide<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/1_connecting.md\">Connecting to Cassandra<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/2_loading.md\">Loading datasets from Cassandra<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/3_selection.md\">Server-side data selection and filtering<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/4_mapper.md\">Working with user-defined case classes and tuples<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/5_saving.md\">Saving and deleting datasets to\/from Cassandra<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/6_advanced_mapper.md\">Customizing the object mapping<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/7_java_api.md\">Using Connector in Java<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/8_streaming.md\">Spark Streaming with Cassandra<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/10_embedded.md\">The spark-cassandra-connector-embedded Artifact<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/11_metrics.md\">Performance monitoring<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/12_building_and_artifacts.md\">Building And Artifacts<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/13_spark_shell.md\">The Spark Shell<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/14_data_frames.md\">DataFrames<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/15_python.md\">Python<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/16_partitioning.md\">Partitioner<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/FAQ.md\">Frequently Asked Questions<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/reference.md\">Configuration Parameter Reference Table<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/developers.md\">Tips for Developing the Spark Cassandra Connector<\/a><\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#online-training\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-online-training\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Online Training<\/h2>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#datastax-academy\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-datastax-academy\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>DataStax Academy<\/h3>\n<p>DataStax Academy provides free online training for Apache Cassandra and DataStax Enterprise. In <a href=\"https:\/\/academy.datastax.com\/courses\/ds320-analytics-with-apache-spark\">DS320: Analytics with Spark<\/a>, you will learn how to effectively and efficiently solve analytical problems with Apache Spark, Apache Cassandra, and DataStax Enterprise. You will learn about Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#community\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-community\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Community<\/h2>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#reporting-bugs\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-reporting-bugs\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Reporting Bugs<\/h3>\n<p>New issues may be reported using <a href=\"https:\/\/datastax-oss.atlassian.net\/browse\/SPARKC\/\">JIRA<\/a>. Please include\nall relevant details including versions of Spark, Spark Cassandra Connector, Cassandra and\/or DSE. A minimal\nreproducible case with sample code is ideal.<\/p>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#mailing-list\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-mailing-list\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Mailing List<\/h3>\n<p>Questions and requests for help may be submitted to the <a href=\"https:\/\/groups.google.com\/a\/lists.datastax.com\/forum\/#!forum\/spark-connector-user\">user mailing list<\/a>.<\/p>\n<h3><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#slack\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-slack\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Slack<\/h3>\n<p>The project uses Slack to facilitate conversation in our community. Find us in the <code>#spark-connector<\/code> channel at <a href=\"https:\/\/academy.datastax.com\/slack\">DataStax Academy Slack<\/a>.<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#contributing\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-contributing\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Contributing<\/h2>\n<p>To protect the community, all contributors are required to sign the <a href=\"http:\/\/spark-cassandra-connector-cla.datastax.com\/\">DataStax Spark Cassandra Connector Contribution License Agreement<\/a>. The process is completely electronic and should only take a few minutes.<\/p>\n<p>To develop this project, we recommend using IntelliJ IDEA. Make sure you have\ninstalled and enabled the Scala Plugin. Open the project with IntelliJ IDEA and\nit will automatically create the project structure from the provided SBT\nconfiguration.<\/p>\n<p><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector\/blob\/master\/doc\/developers.md\">Tips for Developing the Spark Cassandra Connector<\/a><\/p>\n<p>Checklist for contributing changes to the project:<\/p>\n<ul><li>Create a <a href=\"https:\/\/datastax-oss.atlassian.net\/projects\/SPARKC\/issues\">SPARKC JIRA<\/a><\/li>\n<li>Make sure that all unit tests and integration tests pass<\/li>\n<li>Add an appropriate entry at the top of CHANGES.txt<\/li>\n<li>If the change has any end-user impacts, also include changes to the .\/doc files as needed<\/li>\n<li>Prefix the pull request description with the JIRA number, for example: \"SPARKC-123: Fix the ...\"<\/li>\n<li>Open a pull-request on GitHub and await review<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#testing\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-testing\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Testing<\/h2>\n<p>To run unit and integration tests:<\/p>\n<pre>.\/sbt\/sbt test\n.\/sbt\/sbt it:test\n<\/pre>\n<p>By default, integration tests start up a separate, single Cassandra instance and run Spark in local mode.\nIt is possible to run integration tests with your own Cassandra and\/or Spark cluster.\nFirst, prepare a jar with testing code:<\/p>\n<pre>.\/sbt\/sbt test:package\n<\/pre>\n<p>Then copy the generated test jar to your Spark nodes and run:<\/p>\n<pre>export IT_TEST_CASSANDRA_HOST=&lt;IP of one of the Cassandra nodes&gt;\nexport IT_TEST_SPARK_MASTER=&lt;Spark Master URL&gt;\n.\/sbt\/sbt it:test\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#generating-documents\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-generating-documents\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Generating Documents<\/h2>\n<p>To generate the Reference Document use<\/p>\n<pre>.\/sbt\/sbt spark-cassandra-connector-unshaded\/run (outputLocation)\n<\/pre>\n<p>outputLocation defaults to doc\/reference.md<\/p>\n<h2><a href=\"https:\/\/github.com\/datastax\/spark-cassandra-connector#license\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-license\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>License<\/h2>\n<p>Copyright 2014-2017, DataStax, Inc.<\/p>\n<p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at<\/p>\n<p><a href=\"http:\/\/www.apache.org\/licenses\/LICENSE-2.0\">http:\/\/www.apache.org\/licenses\/LICENSE-2.0<\/a><\/p>\n<p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.<\/p>\n<\/article>","created_at":"2017-10-31T20:26:56+0000","updated_at":"2017-10-31T20:32:24+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":5,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/39a8c1c61a5bc3e93dbb7782ea9ce2081bd6327c\/68747470733a2f2f7472617669732d63692e6f72672f64617461737461782f737061726b2d63617373616e6472612d636f6e6e6563746f722e737667","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4892"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4891,"title":"Stratio\/stratio-deep \u00b7 GitHub","url":"https:\/\/github.com\/Stratio\/deep-spark","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\"><p>*Disclaimer: As of 01\/06\/2015 this project has been deprecated. Thank you for your understanding and continued help throughout the project's life.<\/p>\n<p>Deep is a thin integration layer between Apache Spark and several NoSQL datastores.\nWe actually support Apache Cassandra, MongoDB, Elastic Search, Aerospike, HDFS, S3 and any database accessible through JDBC, but in the near future we will add support for sever other datastores.<\/p>\n<ul><li>JIRA: <a href=\"https:\/\/deep-spark.atlassian.net\">https:\/\/deep-spark.atlassian.net<\/a><\/li>\n<\/ul>\n<p>In order to compile the deep-jdbc module is necessary to add the Oracle ojdbc driver into your local repository. You can download it from the URL: <a href=\"http:\/\/www.oracle.com\/technetwork\/database\/features\/jdbc\/default-2280470.html\">http:\/\/www.oracle.com\/technetwork\/database\/features\/jdbc\/default-2280470.html<\/a>. When you are on the web you must click in \"Accept License Agreement\" and later downlad ojdbc7.jar library. You need a free oracle account to download the official driver.<\/p>\n<p>To install the ojdbc driver in your local repository you must execute the command below:<\/p>\n<blockquote>\n<p>mvn install:install-file -Dfile= -DgroupId=com.oracle -DartifactId=ojdbc7  -Dversion=12.1.0.2 -Dpackaging=jar<\/p>\n<\/blockquote>\n<p>After that you can compile Deep executing the following steps:<\/p>\n<blockquote>\n<p>cd deep-parent<\/p>\n<\/blockquote>\n<blockquote>\n<p>mvn clean install<\/p>\n<\/blockquote>\n<p>If you want to create a Deep distribution you must execute the following steps:<\/p>\n<blockquote>\n<p>cd deep-scripts<\/p>\n<\/blockquote>\n<blockquote>\n<p>make-distribution-deep.sh<\/p>\n<\/blockquote>\n<p>During the creation you'll see the following question:<\/p>\n<blockquote>\n<p>What tag want to use for Aerospike native repository?<\/p>\n<\/blockquote>\n<p>You must type 0.7.0 and press enter.<\/p>\n<p>The integration is <em>not<\/em> based on the Cassandra's Hadoop interface.<\/p>\n<p>Deep comes with an user friendly API that lets developers create Spark RDDs mapped to Cassandra column families.\nWe provide two different interfaces:<\/p>\n<ul><li>\n<p>The first one will let developers map Cassandra tables to plain old java objects (POJOs), just like if you were using any other ORM. We call this API the 'entity objects' API.\nThis abstraction is quite handy, it will let you work on RDD (under the hood Deep will transparently map Cassandra's columns to entity properties).\nYour domain entities must be correctly annotated using Deep annotations (take a look at deep-core example entities in package com.stratio.deep.core.entity).<\/p>\n<\/li>\n<li>\n<p>The second one is a more generic 'cell' API, that will let developerss work on RDD&lt;com.stratio.deep.entity.Cells&gt; where a 'Cells' object is a collection of com.stratio.deep.entity.Cell objects.\nColumn metadata is automatically fetched from the data store. This interface is a little bit more cumbersome to work with (see the example below),\nbut has the advantage that it doesn't require the definition of additional entity classes.\nExample: you have a table called 'users' and you decide to use the 'Cells' interface. Once you get an instance 'c' of the Cells object,\nto get the value of column 'address' you can issue a c.getCellByName(\"address\").getCellValue().\nPlease, refer to the Deep API documentation to know more about the Cells and Cell objects.<\/p>\n<\/li>\n<\/ul><p>We encourage you to read the more comprehensive documentation hosted on the <a href=\"http:\/\/www.openstratio.org\/\">Openstratio website<\/a>.<\/p>\n<p>Deep comes with an example sub project called 'deep-examples' containing a set of working examples, both in Java and Scala.\nPlease, refer to the deep-example project README for further information on how to setup a working environment.<\/p>\n<p>Spark-MongoDB connector is based on Hadoop-mongoDB.<\/p>\n<p>Support for MongoDB has been added in version 0.3.0.<\/p>\n<p>We provide two different interfaces:<\/p>\n<ul><li>\n<p>ORM API, you just have to annotate your POJOs with Deep annotations and magic will begin, you will be able to connect MongoDB with Spark using your own model entities.<\/p>\n<\/li>\n<li>\n<p>Generic cell API, you do not need to specify the collection's schema or add anything to your POJOs, each document will be transform to an object \"Cells\".<\/p>\n<\/li>\n<\/ul><p>We added a few working examples for MongoDB in deep-examples subproject, take a look at:<\/p>\n<p>Entities:<\/p>\n<ul><li>com.stratio.deep.examples.java.ReadingEntityFromMongoDB<\/li>\n<li>com.stratio.deep.examples.java.WritingEntityToMongoDB<\/li>\n<li>com.stratio.deep.examples.java.GroupingEntityWithMongoDB<\/li>\n<\/ul><p>Cells:<\/p>\n<ul><li>com.stratio.deep.examples.java.ReadingCellFromMongoDB<\/li>\n<li>com.stratio.deep.examples.java.WritingCellToMongoDB<\/li>\n<li>com.stratio.deep.examples.java.GroupingCellWithMongoDB<\/li>\n<\/ul><p>You can check out our first steps guide here:<\/p>\n<p><a href=\"https:\/\/github.com\/Stratio\/deep-spark\/blob\/master\/doc\/src\/site\/sphinx\/t20-first-steps-deep-mongodb.rst\">First steps with Deep-MongoDB<\/a><\/p>\n<p>We are working on further improvements!<\/p>\n<p>Support for ElasticSearch has been added in version 0.5.0.<\/p>\n<p>Support for Aerospike has been added in version 0.6.0.<\/p>\n<p>Examples:<\/p>\n<p>Entities:<\/p>\n<ul><li>com.stratio.deep.examples.java.ReadingEntityFromAerospike<\/li>\n<li>com.stratio.deep.examples.java.WritingEntityToAerospike<\/li>\n<li>com.stratio.deep.examples.java.GroupingEntityWithAerospike<\/li>\n<\/ul><p>Cells:<\/p>\n<ul><li>com.stratio.deep.examples.java.ReadingCellFromAerospike<\/li>\n<li>com.stratio.deep.examples.java.WritingCellToAerospike<\/li>\n<li>com.stratio.deep.examples.java.GroupingCellWithAerospike<\/li>\n<\/ul>\n<p>Support for JDBC has been added in version 0.7.0.<\/p>\n<p>Examples:<\/p>\n<p>Entities:<\/p>\n<ul><li>package com.stratio.deep.examples.java.ReadingEntityWithJdbc<\/li>\n<li>package com.stratio.deep.examples.java.WritingEntityWithJdbc<\/li>\n<\/ul><p>Cells:<\/p>\n<ul><li>package com.stratio.deep.examples.java.ReadingCellWithJdbc<\/li>\n<li>package com.stratio.deep.examples.java.WritingCellWithJdbc<\/li>\n<\/ul>\n<ul><li>Cassandra, we tested versions from 1.2.8 up to 2.0.11 (for Spark &lt;=&gt; Cassandra integration).<\/li>\n<li>MongoDB, we tested the integration with MongoDB versions 2.2, 2.4 y 2.6 using Standalone, Replica Set and Sharded Cluster (for Spark &lt;=&gt; MongoDB integration).<\/li>\n<li>ElasticSearch, 1.3.0+<\/li>\n<li>Aerospike, 3.3.0+<\/li>\n<li>Spark 1.1.1<\/li>\n<li>Apache Maven &gt;= 3.0.4<\/li>\n<li>Java 1.7<\/li>\n<li>Scala 2.10.3<\/li>\n<\/ul>\n<ul><li>\n<p>Clone the project<\/p>\n<\/li>\n<li>\n<p>To configure a development environment in Eclipse: import as Maven project. In IntelliJ: open the project by selecting the deep-parent POM file<\/p>\n<\/li>\n<li>\n<p>Install the project in you local maven repository. Enter deep-parent subproject and perform: mvn clean install (add -DskipTests to skip tests)<\/p>\n<\/li>\n<li>\n<p>Put Deep to work on a working cassandra + spark cluster. You have several options:<\/p>\n<ul><li>\n<p>Download a pre-configured Stratio platform VM <a href=\"http:\/\/www.stratio.com\/\">Stratio's BigData platform (SDS)<\/a>.\nThis VM will work on both Virtualbox and VMWare, and comes with a fully configured distribution that also includes Stratio Deep. We also distribute the VM with several preloaded datasets in Cassandra. This distribution will include Stratio's customized Cassandra distribution containing our powerful <a href=\"https:\/\/github.com\/Stratio\/stratio-cassandra\">open-source lucene-based secondary indexes<\/a>, see Stratio documentation for further information.\nOnce your VM is up and running you can test Deep using the shell. Enter \/opt\/sds and run bin\/stratio-deep-shell.<\/p>\n<\/li>\n<li>\n<p>Install a new cluster using the Stratio installer. Please refer to Stratio's website to download the installer and its documentation.<\/p>\n<\/li>\n<li>\n<p>You already have a working Cassandra server on your development machine: you need a spark+deep bundle, we suggest to create one by running:<\/p>\n<p><code>cd deep-scripts<\/code><\/p>\n<p><code>.\/make-distribution-deep.sh<\/code><\/p>\n<\/li>\n<\/ul><p>this will build a Spark distribution package with StratioDeep and Cassandra's jars included (depending on your machine this script could take a while, since it will compile Spark from sources).\nThe package will be called <code>spark-deep-distribution-X.Y.Z.tgz<\/code>, untar it to a folder of your choice, enter that folder and issue a <code>.\/stratio-deep-shell<\/code>, this will start an interactive shell where you can test StratioDeep (you may have noticed this is will start a development cluster started with MASTER=\"local\").<\/p>\n<ul><li>\n<p>You already have a working installation os Cassandra and Spark on your development machine: this is the most difficult way to start testing Deep, but you know what you're doing you will have to<\/p>\n<ol><li>copy the Stratio Deep jars to Spark's 'jars' folder (<code>$SPARK_HOME\/jars<\/code>).<\/li>\n<li>copy Cassandra's jars to Spark's 'jar' folder.<\/li>\n<li>copy Datastax Java Driver jar (v 2.0.x) to Spark's 'jar' folder.<\/li>\n<li>start spark shell and import the following:<\/li>\n<\/ol><p><code>import com.stratio.deep.commons.annotations._<\/code><\/p>\n<p><code>import com.stratio.deep.commons.config._<\/code><\/p>\n<p><code>import com.stratio.deep.commons.entity._<\/code><\/p>\n<p><code>import com.stratio.deep.core.context._<\/code><\/p>\n<p><code>import com.stratio.deep.cassandra.config._<\/code><\/p>\n<p><code>import com.stratio.deep.cassandra.extractor._<\/code><\/p>\n<p><code>import com.stratio.deep.mongodb.config._<\/code><\/p>\n<p><code>import com.stratio.deep.mongodb.extractor._<\/code><\/p>\n<p><code>import com.stratio.deep.es.config._<\/code><\/p>\n<p><code>import com.stratio.deep.es.extractor._<\/code><\/p>\n<p><code>import com.stratio.deep.aerospike.config._<\/code><\/p>\n<p><code>import com.stratio.deep.aerospike.extractor._<\/code><\/p>\n<p><code>import org.apache.spark.rdd._<\/code><\/p>\n<p><code>import org.apache.spark.SparkContext._<\/code><\/p>\n<p><code>import org.apache.spark.sql.api.java.JavaSQLContext<\/code><\/p>\n<p><code>import org.apache.spark.sql.api.java.JavaSchemaRDD<\/code><\/p>\n<p><code>import org.apache.spark.sql.api.java.Row<\/code><\/p>\n<p><code>import scala.collection.JavaConversions._<\/code><\/p>\n<\/li>\n<\/ul><\/li>\n<\/ul><p>Once you have a working development environment you can finally start testing Deep. This are the basic steps you will always have to perform in order to use Deep:<\/p>\n<ul><li><strong>Build an instance of a configuration object<\/strong>: this will let you tell Deep the Cassandra endpoint, the keyspace, the table you want to access and much more.\nIt will also let you specify which interface to use (the domain entity or the generic interface).\nWe have a factory that will help you create a configuration object using a fluent API. Creating a configuration object is an expensive operation.\nPlease take the time to read the java and scala examples provided in 'deep-examples' subproject and to read the comprehensive documentation at <a href=\"https:\/\/github.com\/Stratio\/deep-spark\/blob\/release\/0.6\/doc\/t10-first-steps-deep-cassandra.md\">OpenStratio website<\/a>.<\/li>\n<li><strong>Create an RDD<\/strong>: using the DeepSparkContext helper methods and providing the configuration object you've just instantiated.<\/li>\n<li><strong>Perform some computation over this RDD(s)<\/strong>: this is up to you, we only help you fetching the data efficiently from Cassandra, you can use the powerful <a href=\"https:\/\/spark.apache.org\/docs\/1.1.1\/api\/java\/index.html\">Spark API<\/a>.<\/li>\n<li><strong>(optional) write the computation results out to Cassandra<\/strong>: we provide a way to efficiently save the result of your computation to Cassandra.\nIn order to do that you must have another configuration object where you specify the output keyspace\/column family. We can create the output column family for you if needed.\nPlease, refer to the comprehensive Stratio Deep documentation at <a href=\"https:\/\/github.com\/Stratio\/deep-spark\/blob\/release\/0.6\/doc\/about.md\">Stratio website<\/a>.<\/li>\n<\/ul>\n<ul><li><strong>Build an instance of a configuration object<\/strong>: this will let you tell Stratio Deep the MongoDB endpoint, the MongoDB database and collection you want to access and much more.\nIt will also let you specify which interface to use (the domain entity).\nWe have a factory that will help you create a configuration object using a fluent API. Creating a configuration object is an expensive operation.\nPlease take the time to read the java and scala examples provided in 'deep-examples' subproject and to read the comprehensive Deep documentation at <a href=\"https:\/\/github.com\/Stratio\/deep-spark\/blob\/release\/0.6\/doc\/t20-first-steps-deep-mongodb.md\">OpenStratio website<\/a>.<\/li>\n<li><strong>Create an RDD<\/strong>: using the DeepSparkContext helper methods and providing the configuration object you've just instantiated.<\/li>\n<li><strong>Perform some computation over this RDD(s)<\/strong>: this is up to you, we only help you fetching the data efficiently from MongoDB, you can use the powerful <a href=\"https:\/\/spark.apache.org\/docs\/1.1.1\/api\/java\/index.html\">Spark API<\/a>.<\/li>\n<li><strong>(optional) write the computation results out to MongoDB<\/strong>: we provide a way to efficiently save the result of your computation to MongoDB.<\/li>\n<\/ul>\n<p>From version 0.4.x, Deep supports multiple datastores, in order to correctly implement this new feature Deep has undergone an huge refactor between versions 0.2.9 and 0.4.x. To port your code to the new version you should take into account a few changes we made.<\/p>\n<h2><a href=\"https:\/\/github.com\/Stratio\/deep-spark#new-project-structure\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-new-project-structure\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>New Project Structure<\/h2>\n<p>From version 0.4.x, Deep supports multiple datastores, in your project you should import only the maven dependency you will use: deep-cassandra, deep-mongodb, deep-elasticsearch or deep-aerospike.<\/p>\n<h2><a href=\"https:\/\/github.com\/Stratio\/deep-spark#changes-to-comstratiodeepentitycells\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-changes-to-comstratiodeepentitycells\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Changes to 'com.stratio.deep.entity.Cells'<\/h2>\n<ul><li>Until version 0.4.x the 'Cells' was implicitly associated to a record coming from a specific table. When performing a join in Spark, 'Cell' objects coming from different tables are mixed into an single 'Cells' object.\nDeep now keeps track of the original table a Cell object comes from, changing the internal structure of 'Cells', where each 'Cell' is associated to its 'table'.\n<ol><li>If you are a user of 'Cells' objects returned from Deep, nothing changes for you. The 'Cells' API keeps working as usual.<\/li>\n<li>If you manually create 'Cells' objects you can keep using the original API, in this case each Cell you add to your Cells object is automatically associated to a default table name.<\/li>\n<li>You can specify the default table name, or let Deep chose an internal default table name for you.<\/li>\n<li>We added a new constructor to 'Cells' accepting the default table name. This way the 'old' API will always manipulate 'Cell' objects associated to the specified default table.<\/li>\n<li>For each method manipulating the content of a 'Cells' object, we added a new method that also accepts the table name: if you call the method\t whose signature does <em>not<\/em> have the table name, the table action is performed over the Cell associated to the default table, otherwise the action is performed over the 'Cell'(s) associated to the specified table.<\/li>\n<li>size() y isEmpty() will compute their results taking into account all the 'Cell' objects contained.<\/li>\n<li>size(String tableName) and isEmpty(tableName) compute their result taking into account only the 'Cell' objects associated to the specified table.<\/li>\n<li>Obviously, when dealing with Cells objects, Deep always associates a Cell to the correct table name.<\/li>\n<\/ol><\/li>\n<\/ul><p>Examples:<\/p>\n<pre>Cells cells1 = new Cells(); \/\/ instantiate a Cells object whose default table name is generated internally.\nCells cells2 = new Cells(\"my_default_table\"); \/\/ creates a new Cells object whose default table name is specified by the user\ncells2.add(new Cell(...)); \/\/ adds to the 'cells2' object a new Cell object associated to the default table\ncells2.add(\"my_other_table\", new Cell(...)); \/\/ adds to the 'cells2' object a new Cell associated to \"my_other_table\"  \n<\/pre>\n<h2><a href=\"https:\/\/github.com\/Stratio\/deep-spark#changes-to-objects-hierarchy\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-changes-to-objects-hierarchy\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Changes to objects hierarchy<\/h2>\n<ul><li>IDeepJobConfig interface has been splitted into ICassandraDeepJobConfig and IMongoDeepJobConfig sub-interfaces. Each sub-interface exposes only the configuration properties that make sense for each data base.\ncom.stratio.deep.config.DeepJobConfigFactory's factory methods now return the proper subinterface.<\/li>\n<li><strong>DeepSparkContext<\/strong> has been splitted into <strong>CassandraDeepSparkContext<\/strong> and <strong>MongoDeepSparkContext<\/strong>.<\/li>\n<li><strong>DeepJobConfigFactory<\/strong> has been renamed to <strong>ConfigFactory<\/strong> (to reduce verbosity).<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/Stratio\/deep-spark#rdd-creation\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-rdd-creation\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>RDD creation<\/h2>\n<p>Methods used to create Cell and Entity RDD has been merged into one single method:<\/p>\n<ul><li><strong>DeepSparkContext<\/strong>: createRDD(...)<\/li>\n<\/ul><\/article>","created_at":"2017-10-31T20:27:00+0000","updated_at":"2017-10-31T20:32:23+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":11,"domain_name":"github.com","preview_picture":"https:\/\/avatars1.githubusercontent.com\/u\/5228027?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4891"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4890,"title":"tjake\/Solandra","url":"https:\/\/github.com\/tjake\/Solandra","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p>Solandra is a real-time distributed search engine built on <a href=\"http:\/\/lucene.apache.org\/solr\/\">Apache Solr<\/a> and <a href=\"http:\/\/cassandra.apache.org\">Apache Cassandra<\/a>.<\/p>\n<p>At its core, Solandra is a tight integration of Solr and Cassandra, meaning within a single JVM both Solr and Cassandra are running, and\ndocuments are stored and disributed using Cassandra's data model.<\/p>\n<p>Solandra makes managing and dynamically growing Solr simple(r).<\/p>\n<p>For more information please see the <a href=\"https:\/\/github.com\/tjake\/Solandra\/wiki\">wiki<\/a><\/p>\n<p>####Project Status:####<\/p>\n<p>Solandra is relatively stable, most of the common functionality used has been working and stable for users.\nI personally am no longer developing Solandra much beyond version changes and applying pull requests.<\/p>\n<p>If you are looking for a supported Solr + Cassandra integration beyond what Solandra offers\nlook at <a href=\"http:\/\/www.datastax.com\/products\/enterprise\">DataStax Enterprise Search<\/a><br\/>(Full disclosure I am a developer on that team).<\/p>\n<p>I've written up <a href=\"http:\/\/www.datastax.com\/dev\/blog\/cassandra-with-solr-integration-details\">how Solandra and DataStax Enterprise Search differ here<\/a>.<\/p>\n<p>####Requirements:####<\/p>\n<p>Java &gt;= 1.6\nCassandra &gt;= 1.1\nSolr &gt;= 3.1<\/p>\n<p>####Features:######<\/p>\n<ul><li>Supports most out-of-the-box Solr functionality (search, faceting, highlights)<\/li>\n<li>Replication, sharding, caching, and compaction managed by Cassandra<\/li>\n<li>Multi-master (read\/write to any node)<\/li>\n<li>Writes become available as soon as write succeeds<\/li>\n<li>Easily add new SolrCores w\/o restart across the cluster<\/li>\n<\/ul><p>####Getting started:####<\/p>\n<p>The following will guide you through setting up a single node instance of Solandra.<\/p>\n<p>From the Solandra base directory:<\/p>\n<pre>mkdir \/tmp\/cassandra-data\nant\ncd solandra-app; bin\/solandra\n<\/pre>\n<p>Now that Solandra is running you can run the demo:<\/p>\n<pre>cd ..\/..\/reuters-demo\n.\/1-download_data.sh\n.\/2-import_data.sh\nWhile data is loading, open the file .\/website\/index.html in your favorite browser.\n<\/pre>\n<p>####Embedding in an existing cassandra distribution####<\/p>\n<p>To use an existing Cassandra distribution perform the following steps.<\/p>\n<ol><li>\n<p>Download your Cassandra distribution<\/p>\n<\/li>\n<li>\n<p>Unzip it the directory of your choice<\/p>\n<\/li>\n<li>\n<p>Run the following solandra ant task to deploy the necessary files into the unzipped dir<\/p>\n<p>ant -Dcassandra={unzipped dir} cassandra-dist<\/p>\n<\/li>\n<li>\n<p>You can now start Solr within Cassandra by using $CASSANDRA_HOME\/bin\/solandra command. Cassandra now takes two optional properties: -Dsolandra.context and -Dsolandra.port for the context path and the Jetty port.<\/p>\n<\/li>\n<\/ol><p>####Limitations####<\/p>\n<p>Solandra uses Solr's built in distributed searching mechanism.\nMost of its limitations are covered here:<\/p>\n<p><a href=\"http:\/\/wiki.apache.org\/solr\/DistributedSearch#Distributed_Searching_Limitations\">http:\/\/wiki.apache.org\/solr\/DistributedSearch#Distributed_Searching_Limitations<\/a><\/p>\n<\/article>","created_at":"2017-10-31T20:27:08+0000","updated_at":"2017-10-31T20:32:23+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":1,"domain_name":"github.com","preview_picture":"https:\/\/avatars2.githubusercontent.com\/u\/44456?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4890"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4889,"title":"DataStax OpsCenter","url":"https:\/\/www.datastax.com\/products\/datastax-opscenter","content":"<div class=\"DX3_SbBnr_DarkBlueBar\" readability=\"13\">\n    <div class=\"thismb2content1width1\" readability=\"23\"><p>&#13;\n&#13;\nDataStax OpsCenter is the web-based visual management and monitoring <br\/>&#13;\nsolution for <a href=\"https:\/\/www.datastax.com\/products\/datastax-enterprise\" class=\"DX3_skyblue_link\" target=\"_self\">&#13;\nDataStax Enterprise (DSE)<\/a>. OpsCenter has integrated functionality <br\/>&#13;\nfor real-time monitoring, tuning, provisioning, backup, and security <br\/>&#13;\nmanagement. OpsCenter provides everything you need to intelligently <br\/>&#13;\nmanage and monitor your business-critical systems at epic scale. &#13;\n    <\/p><\/div>\n<\/div><div class=\"thismb2content1width1 center  dx_actmrgn_bttm_e39px\" readability=\"64\">\n    <p>&#13;\nDSE OpsCenter&#13;\n    <\/p>\n    <p>&#13;\nBuilt for Cloud Applications&#13;\n    <\/p>\n    <p>&#13;\nDataStax OpsCenter is built from the ground up to manage and monitor the database infrastructure that powers large-scale <a href=\"https:\/\/www.datastax.com\/cloud-applications\" target=\"_self\">cloud applications<\/a>. With the click of a button, you can provision, monitor, backup, and manage your DSE clusters with little to no expertise. OpsCenter can manage clusters that exist on-premise, in the cloud, or in hybrid environments spanning multiple data centers. OpsCenter not only helps reduce your operational and hardware costs but dramatically increases your overall operational productivity. &#13;\n    <\/p>\n    <p>&#13;\nIntelligent Cluster Management&#13;\n    <\/p>\n    <p>&#13;\nDataStax OpsCenter supplies a centralized dashboard to monitor clusters, which allows you to quickly identify which clusters require your attention. OpsCenter monitors key metrics and performs trend analysis to proactively identify and alert on issues before they impact production workloads. OpsCenter also seamlessly integrates with existing management tools and workflows such as <a href=\"http:\/\/graphite.wikidot.com\/\" target=\"_blank\">Graphite<\/a> and SNMP management consoles. <a href=\"https:\/\/www.datastax.com\/wp-content\/themes\/datastax-2014-08\/images\/products\/OpsCenter-Screenshot-IntelligentClusterManagement.jpg\" class=\"fancybox image\" alt=\"Screenshot\">View screenshot.<\/a>&#13;\n    <\/p>\n<p>&#13;\nPoint-and-Click Provisioning&#13;\n    <\/p>\n    <p>&#13;\nThe provisioning functionality of the OpsCenter Lifecycle Manager provides declarative configuration management for your cluster. You can easily create new clusters, add or remove capacity in place without downtime, and change configuration files all from a central location. All of this functionality is also exposed via a RESTful API and integrates easily with your existing tools and workflows. <a href=\"https:\/\/www.datastax.com\/wp-content\/themes\/datastax-2014-08\/images\/products\/OpsCenter-Screenshot-PointandClickProvisioning.jpg\" class=\"fancybox image\" alt=\"Screenshot\">View screenshot.<\/a>&#13;\n    <\/p>\n<\/div><div class=\"thismb2content1width1  center  dx_actmrgn_bttm_e39px  \" readability=\"44\">\n    <p>&#13;\nVisual Monitoring and Tuning&#13;\n    <\/p>\n    <p>&#13;\nOpsCenter offers customized dashboards to provide detailed information and trend analysis for real-time and historical system metrics. Operations staff can easily spot outliers, discover bottlenecks, and identify machines that may be impacting system performance.&#13;\n<a href=\"https:\/\/www.datastax.com\/wp-content\/themes\/datastax-2014-08\/images\/products\/OpsCenter-Screenshot-VisualMonitoringandTuning.jpg\" class=\"fancybox image\" alt=\"Screenshot\">View screenshot.<\/a>&#13;\n    <\/p>\n    <p>&#13;\nRobust Backup and Point-in-Time Recovery&#13;\n    <\/p>\n    <div class=\"dxfnts_ds_f18l23  dx_actmrgn_bttm_et48px  dx_maxwidthsetup_center\" readability=\"25\">\nDataStax delivers full backup and disaster recovery protection for database clusters through the Backup Service. The Backup Service has a suite of features designed to help manage backup and restore procedures for large clusters of machines distributed across multiple data centers. \n<p>This includes the ability to visually schedule, backup and restore, hundreds of nodes at a point in time or object level, determine when a full or partial backup is needed through smart algorithms, and automatically transfer backups to on-premise or cloud storage with built-in compression and retention policies. &#13;\n<\/p><p>Additionally, the Backup Service includes notification and visual monitoring of backup and restore tasks, as well as the ability to clone database clusters (i.e. copying one cluster to another).&#13;\n    <\/p><\/div>\n    <p>&#13;\nManagement Success&#13;\n    <\/p>\n    <p>&#13;\nThe Automatic Management Services of DSE are designed to increase your productivity by automating important maintenance and monitoring procedures. DSE Management Services are capable of identifying configuration parameters that violate best practices, performing automated cluster consistency checks and forecasting a need for additional cluster capacity.&#13;\n    <\/p>\n<\/div><div class=\"thismb2content1width1 center  dx_actmrgn_bttm_e39px  \" readability=\"41\">\n    <p>&#13;\nAlways-On Management and Monitoring&#13;\n    <\/p>\n    <p>&#13;\nAutomatic failover is built into OpsCenter, which helps ensure that any scheduled tasks or monitoring activities continue even if the primary OpsCenter server fails.&#13;\n    <\/p>\n    <p>&#13;\nAccess &amp; Authorization&#13;\n    <\/p>\n    <p>&#13;\nDataStax OpsCenter is a secure management and monitoring tool that has granular roles and permissions to control the tasks that administrators and operations staff can perform.&#13;\n    <\/p>\n    <p>&#13;\nPowerful APIs for Seamless Integration&#13;\n    <\/p>\n    <p>&#13;\nEvery feature and component of OpsCenter is exposed via a comprehensive set of RESTful APIs. You can easily provision, monitor, and execute maintenance tasks from your favorite scripting language. The OpsCenter APIs make it easy to integrate powerful functionality into your existing tools and workflows.&#13;\n    <\/p>\n<\/div>","created_at":"2017-10-31T20:27:12+0000","updated_at":"2017-10-31T20:32:23+0000","annotations":[],"mimetype":"text\/html","language":"en-US","reading_time":3,"domain_name":"www.datastax.com","preview_picture":"http:\/\/www.datastax.com\/wp-content\/uploads\/2013\/03\/opsc-multi-cluster_thumb.jpg","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4889"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4888,"title":"sebgiroux\/Cassandra-Cluster-Admin","url":"https:\/\/github.com\/sebgiroux\/Cassandra-Cluster-Admin","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.mkd\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p>Cassandra Cluster Admin is a GUI tool to help people administrate their Apache Cassandra cluster.<\/p>\n<p>If you're like me and used MySQL for a while (and still using it!), you get used to phpMyAdmin and its simple and easy to use user interface. I thought it would be nice to have a similar tool for Cassandra and I couldn't find any, so I build my own!<\/p>\n<p>With Cassandra Cluster Admin, you can create\/edit\/drop keyspaces and column families, truncate a column family, create secondary indexes, display a row, browse data (get range slice), insert a row and much more!<\/p>\n<p>Bug report and\/or pull request are always welcome!<\/p>\n<h2><a href=\"https:\/\/github.com\/sebgiroux\/Cassandra-Cluster-Admin#screenshots\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-screenshots\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Screenshots<\/h2>\n<p><a href=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/1.png\"><img src=\"https:\/\/camo.githubusercontent.com\/b1b63951626ef0026e92eafaff3ef07e62e67c07\/687474703a2f2f7777772e666c617368792e63632f63617373616e6472612d636c75737465722d61646d696e2f315f736d616c6c2e706e67\" alt=\"Viewing Keyspaces and Column Families\" data-canonical-src=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/1_small.png\"\/><\/a> <a href=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/2.png\"><img src=\"https:\/\/camo.githubusercontent.com\/a6dc9d3f7fdb92c7366e7d7747d068c40d881410\/687474703a2f2f7777772e666c617368792e63632f63617373616e6472612d636c75737465722d61646d696e2f325f736d616c6c2e706e67\" alt=\"Viewing Cluster\" data-canonical-src=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/2_small.png\"\/><\/a> <a href=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/4.png\"><img src=\"https:\/\/camo.githubusercontent.com\/ac9f021da932b434f95922db279572d5fa8a6653\/687474703a2f2f7777772e666c617368792e63632f63617373616e6472612d636c75737465722d61646d696e2f345f736d616c6c2e706e67\" alt=\"Cassandra Cluster Admin Column family Definition and Actions\" data-canonical-src=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/4_small.png\"\/><\/a>  <a href=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/5.png\"><img src=\"https:\/\/camo.githubusercontent.com\/cf9d6d08936205aa34175f2aaee10fe01878251d\/687474703a2f2f7777772e666c617368792e63632f63617373616e6472612d636c75737465722d61646d696e2f355f736d616c6c2e706e67\" alt=\"Cassandra Cluster Admin List of Column Families in a Keyspace\" data-canonical-src=\"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/5_small.png\"\/><\/a><\/p>\n<h2><a href=\"https:\/\/github.com\/sebgiroux\/Cassandra-Cluster-Admin#supported-actions\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-supported-actions\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Supported actions<\/h2>\n<ul><li>Keyspace manipulation (add\/edit\/drop)<\/li>\n<li>Column Family manipulation (add\/edit\/truncate\/drop)<\/li>\n<li>Row manipulation on column family and super column family (insert\/edit\/remove)<\/li>\n<li>Basic data browser to navigate in the data of a column family<\/li>\n<li>Support Cassandra 0.8+ atomic counters<\/li>\n<li>Support management of multiple Cassandra clusters<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/sebgiroux\/Cassandra-Cluster-Admin#getting-started\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-getting-started\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Getting Started<\/h2>\n<p>If you're under Windows, I suggest you install <a href=\"http:\/\/www.easyphp.org\/\">EasyPHP<\/a> or <a href=\"http:\/\/www.apachefriends.org\/en\/xampp-windows.html\">XAMPP<\/a> for a quick WAMP setup install.<\/p>\n<p>Once your Web server is setup, you copy all the files from the package you've just downloaded into a directory that can be accessed by a Web browser (ex: <a href=\"http:\/\/localhost\/cassandra-cluster-admin\">http:\/\/localhost\/cassandra-cluster-admin<\/a>). The server must have PHP installed (5.3+ recommended). Installing the Thrift PHP extension is also a good idea for performance (read \"Thrift C extension\" section below).<\/p>\n<p>All configuration is in <code>include\/conf.inc.php<\/code>:<\/p>\n<p>If this Web server is accessible by everyone, you might want to password protect the application, so your data is secure. To do so, you can set <code>CCA_LOGIN_REQUIRED<\/code> to true and specify your desired username and password by altering <code>CCA_USERNAME<\/code> and <code>CCA_PASSWORD<\/code> respectivly.<\/p>\n<p>If your Cassandra server is not running on localhost or if you have multiple Cassandra nodes\/clusters, you have to alter the <code>$CASSANDRA_CLUSTERS<\/code> array. This application support multiple Cassandra Cluster so you can alter <code>$CASSANDRA_CLUSTERS<\/code> accordingly. More info is found in the configuration file about multi cluster configuration.<\/p>\n<p>If you want to see JMX stats in Cassandra Cluster Admin, you will need to activate MX4J on all your Casandra nodes you want to see the JMX stats. Once this is done, if MX4J is not running on the default port (8081), you will also need to alter <code>MX4J_HTTP_ADAPTOR_PORT<\/code> in the configuration file of Cassandra Cluster Admin.<\/p>\n<h2><a href=\"https:\/\/github.com\/sebgiroux\/Cassandra-Cluster-Admin#thrift-c-extension\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-thrift-c-extension\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Thrift C extension<\/h2>\n<p>If you're in a test environnement or just want to get started with Cassandra, I suggest you skip this step as it's for performance improvement only. No extra feature by installing this.<\/p>\n<p>The C extension is crucial for phpcassa's performance.<\/p>\n<p>You need to configure and make to be able to use the C extension.<\/p>\n<pre>cd include\/phpcassa\/thrift\/ext\/thrift_protocol  \nphpize  \n.\/configure  \nmake  \nsudo make install  \n<\/pre>\n<p>Add the following line to your php.ini file:<\/p>\n<pre>extension=thrift_protocol.so\n<\/pre>\n<h2><a href=\"https:\/\/github.com\/sebgiroux\/Cassandra-Cluster-Admin#disclaimer\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-disclaimer\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Disclaimer<\/h2>\n<p>This software is still in beta so always be careful when using it on a production cluster. I won't take any responsability if for some reason this tool drops all your keyspaces and wipes all your data, although I really doubt it will happen =)<\/p>\n<h2><a href=\"https:\/\/github.com\/sebgiroux\/Cassandra-Cluster-Admin#credits\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-credits\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Credits<\/h2>\n<\/article>","created_at":"2017-10-31T20:27:17+0000","updated_at":"2017-10-31T20:32:22+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":2,"domain_name":"github.com","preview_picture":"http:\/\/www.flashy.cc\/cassandra-cluster-admin\/1.png","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4888"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4887,"title":"lookout\/cassandra-statsd-agent","url":"https:\/\/github.com\/lookout\/cassandra-statsd-agent","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p>Thanks to UnderSiege for getting this project off the ground.<\/p>\n<h2><a href=\"https:\/\/github.com\/lookout\/cassandra-statsd-agent#requirements\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-requirements\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>REQUIREMENTS<\/h2>\n<ul><li>Maven<\/li>\n<li>Java 7<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/lookout\/cassandra-statsd-agent#build\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-build\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>BUILD<\/h2>\n<p>Check which metrics library cassandra is using by looking in\ncassandra\/lib\/metrics-core*, verify that pom.xml points to the\nsame exact version. For example, if you have metrics-core-2.2.0.jar,\nmake sure pom.xml has 2.2.0.<\/p>\n<p><code>mvn package<\/code><\/p>\n<p>Alternatively, grab the binary from bintray:<\/p>\n<p><code>curl -L http:\/\/dl.bintray.com\/lookout\/systems\/com\/github\/lookout\/metrics\/agent\/1.2\/agent-1.2.jar -o agent-1.2.jar<\/code><\/p>\n<h2><a href=\"https:\/\/github.com\/lookout\/cassandra-statsd-agent#install\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-install\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>INSTALL<\/h2>\n<p>Copy the statsd library from the .m2 folder to cassandra\/lib.\nAdd the following to your cassandra startup script:<\/p>\n<p>Copy the agent-1.2.jar to a new directory cassandra\/plugins<\/p>\n<p>Change cassandra startup to add this agent. This can be done in\na stock install by adding the following to \/etc\/default\/cassandra:<\/p>\n<p><code>export JVM_OPTS=\"-javaagent:\/usr\/share\/cassandra\/plugins\/agent-1.2.jar=localhost\"<\/code><\/p>\n<p>Note the '=localhost' at the end. This supports the following syntaxes:\n<code>hostname:port@interval<\/code>\nFor example:\n<code>your.statsd.host.com:9999@60<\/code>\nThe default port is 8125 and the default interval is 10 (seconds); these\ncan be omitted. IPV6 is also supported with the following syntax:\n<code>[2001:db8::1]:8888@300<\/code>\nwhich means connect to 2001:db8::1 on port 8888 every 300 seconds.<\/p>\n<h2><a href=\"https:\/\/github.com\/lookout\/cassandra-statsd-agent#reporting\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-reporting\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>REPORTING<\/h2>\n<p>A log message will be added to the system.log at startup to\nconfirm that everything is running, it looks like this:<\/p>\n<p><code>INFO [metrics-statsd-thread-1] 2014-12-19 19:05:37,120 StatsdReporter.java:65 - Statsd reporting to host localhost port 8125 every 10 seconds<\/code><\/p>\n<h2><a href=\"https:\/\/github.com\/lookout\/cassandra-statsd-agent#what-gets-reported\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-what-gets-reported\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>WHAT GETS REPORTED<\/h2>\n<p>Lots of stuff:<\/p>\n<ul><li>Gossip statistics:\ngossip.score., which help decide who is closer\/faster for queries\ngossip.severity, which indicates how busy this node is self-reporting to others<\/li>\n<li>Per table statistics:\ncfstats...ReadCount\ncfstats...WriteCount\ncfstats...RecentReadLatencyMicros\ncfstats...RecentWriteLatencyMicros\ncfstats...TombstonesPerSlice\ncfstats...estimatedKeys\nThe last one is great for monitoring general trends, but of course don't\nrely on that number to be very accurate.<\/li>\n<li>PHI reporter\nAlso supported is the currently-experimental PHI reporter, in PHI.,\ncoming to a Cassandra cluster near you soon.<\/li>\n<li>JVM GC metrics<\/li>\n<li>Anything else registered with yammer-metrics<\/li>\n<\/ul><h2><a href=\"https:\/\/github.com\/lookout\/cassandra-statsd-agent#debugging\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-debugging\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>DEBUGGING<\/h2>\n<p>Not working? There's a lot of tracing and debugging available. Change the\nlog4j-server.properties and add something like this to get extremely detailed\ntraces of what it's doing in the server.log.<\/p>\n<p><code>log4j.logger.com.github.lookout.metrics.agent.generators=TRACE<\/code><\/p>\n<h2><a href=\"https:\/\/github.com\/lookout\/cassandra-statsd-agent#todo\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-todo\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>TODO<\/h2>\n<p>Errors that happen during startup are not reported as well as they should\nbe, mostly because the logging system is not active during startup. The log\nmessage is only generated when the actual metrics collector has run for the\nfirst time.<\/p>\n<\/article>","created_at":"2017-10-31T20:27:21+0000","updated_at":"2017-10-31T20:32:22+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":2,"domain_name":"github.com","preview_picture":"https:\/\/avatars0.githubusercontent.com\/u\/47237?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4887"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4886,"title":"bart613\/cassandra","url":"https:\/\/github.com\/bart613\/cassandra","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README\n    <\/h3>\n      <div class=\"plain\"><pre>A collection of scripts\/tools that can come quite handy for a person looking\nafter Cassandra cluster.\n  * cassandra_cfstats2graphite.py - push data from cfstats to Graphite\n  * check_cassandra_CompletedTasks.sh - checks CompletedTasks attribute\n    through JMX to see whether Cassandra is actually doing anything;\n    unfortunatelly depends on jmx4perl and requires Jolokia\n  * check_manualrepair.sh - greps Cassandra's logs to see whether manual\n    repair has heppened recently\n<\/pre><\/div>","created_at":"2017-10-31T20:27:25+0000","updated_at":"2017-10-31T20:32:21+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":0,"domain_name":"github.com","preview_picture":"https:\/\/avatars3.githubusercontent.com\/u\/735253?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4886"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4885,"title":"CrowdStrike\/cassandra-tools","url":"https:\/\/github.com\/CrowdStrike\/cassandra-tools","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><p>This repository is a collection of automation scripts that allow you to launch and test different Cassandra configurations. You can have multiple profiles to test against to see the difference in performance between an 8GB heap and a 12GB heap for example, or making multiple changes to a yaml file vs a control cluster to see if performance or stability improved with your changes.<\/p>\n<p>Cassandra tools pulled a lot of bootstrapping and node configuration from the DataStax AMI Builder tool and simplified it via Fabric so that you have more control over the changes you want to make to your cluster and giving you a clear view on what is going on.<\/p>\n<p>The topology that would be recommended would be something as seen below. Where you have a dedicated node running opscenter that can be static and separate instances of stress and C*<\/p>\n<p><a href=\"https:\/\/camo.githubusercontent.com\/2216a88d0077ecbe79a1245e70d168072b3b4dfc\/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f393530373731322f63617373616e6472612f746f706f6c6f67792e706e67\" target=\"_blank\"><img src=\"https:\/\/camo.githubusercontent.com\/2216a88d0077ecbe79a1245e70d168072b3b4dfc\/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f393530373731322f63617373616e6472612f746f706f6c6f67792e706e67\" alt=\"Topology\" data-canonical-src=\"https:\/\/dl.dropboxusercontent.com\/u\/9507712\/cassandra\/topology.png\"\/><\/a><\/p>\n<p>Bootsrapping a cluster supports:<\/p>\n<ul><li>Mounting and formatting Drives using XFS<\/li>\n<li>RAID0 for testing the i2 series of instance types<\/li>\n<\/ul><p>The basic workflow is as follows:<\/p>\n<ol><li>Launch a machine and install Opscenter<\/li>\n<li>Launch and bootstrap a cluster of C* nodes<\/li>\n<li>Launch and bootstrap several stress runner nodes<\/li>\n<li>Run stress yaml files against the cluster and monitor<\/li>\n<\/ol><p>All of these scripts expect you to have the requirements installed from requirements.txt To do that simply type from the root directory<\/p>\n<pre>pip install -r requirements.txt\n<\/pre>\n<p>Since this is for AWS it's expected that you have your keys exported in your shell for auth.<\/p>\n<pre>export AWS_ACCESS_KEY_ID=YOURKEY\nexport AWS_SECRET_ACCESS_KEY=YOURSECRET\n<\/pre>\n<h4><a href=\"https:\/\/github.com\/CrowdStrike\/cassandra-tools#ubuntu-note\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-ubuntu-note\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Ubuntu Note<\/h4>\n<p>you may need to install python dev tools to get pycrypto working<\/p>\n<pre>sudo apt-get install python-dev\n<\/pre>\n<p>Now let's get to launching. It's assumed that you have an AMI you want to use as your base. It can just be a base Ubuntu AMI from the AWS console for example. Once you have that AMI you'll need to configure a launch json file that has the ami id, security groups you want applied, tags, launch key, etc... so launcher.py knows how to build your instances.<\/p>\n<p>Take a look at the configs\/*.sample files for examples of where to plug your information in. This also assumes you're in a VPC. If you're not feel free to submit a pull request to support non VPC launching or just launch your nodes via the AWS console or CLI. Launcher does nothing fancy and doesn't bootstrap anything. It just provisions instances, which you can do yourself via the AWS console.<\/p>\n<p>Copy a profile sample to work with<\/p>\n<pre>cd launcher\/configs\/\ncp c4-highperf.json.sample c4-highperf.json\n<\/pre>\n<p>Now edit that profile with your AMI ID to use, tags you want on the instances, security groups, subnets to launch in, etc...<\/p>\n<p>You can see the AMI ID in this screenshot as ami-d05e75b8<\/p>\n<p><a href=\"https:\/\/camo.githubusercontent.com\/0ce34f118f4db7cce164da103724c1a1c5d49260\/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f393530373731322f63617373616e6472612f616d692e706e67\" target=\"_blank\"><img src=\"https:\/\/camo.githubusercontent.com\/0ce34f118f4db7cce164da103724c1a1c5d49260\/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f393530373731322f63617373616e6472612f616d692e706e67\" alt=\"AMI\" data-canonical-src=\"https:\/\/dl.dropboxusercontent.com\/u\/9507712\/cassandra\/ami.png\"\/><\/a><\/p>\n<p>Assuming you're using the launcher script, let's fire up 3 nodes in us-east-1a using the c4-highperf profile that you created from a .sample file.<\/p>\n<pre>cd launcher\/\npython launch.py launch --nodes=3 --config=c4-highperf --az=us-east-1a\n<\/pre>\n<p>You can repeat the process across AZ's as needed to get the final cluster topology squared away. At the end of that output you'll see  a list of IPs that it provisioned. Copy those down for future use.<\/p>\n<h3><a href=\"https:\/\/github.com\/CrowdStrike\/cassandra-tools#creating-a-profile\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-creating-a-profile\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Creating a Profile<\/h3>\n<p>The first step in the process will be to use one of the sample profiles to base a new profile you want to test.<\/p>\n<pre>cd manage\/configs\ncp -rf c4-highperf-sample c4-highperf\n<\/pre>\n<p>More docs to come on this but for now go through the files in that directory and change the 10.10.10.XX ips to ones in your environment. e..g in address.yaml put in your opscenter IP address<\/p>\n<p>Files of interest:<\/p>\n<ul><li>address.yaml the IP address to where your opscenter node is for reporting<\/li>\n<li>cassandra-env.sh contains the startup params, GC settings for config<\/li>\n<li>cassandra.yaml contains the properties used to control various C* settings<\/li>\n<li>collectd.conf if you want to use collectd to monitor via graphite, put your graphite ip in there<\/li>\n<li>hostfile.txt contains all the IP address for the nodes you want to manage<\/li>\n<li>metrics.yaml if you're reporting to graphite, send C* metrics over with a whitelist<\/li>\n<\/ul><p>NOTE: For EBS volumes it's expected you mount your drives in specific locations. e.g. commit drive goes to \/dev\/sdk(xvdf) and data drive goes to \/mnt\/sdf(xvdf) or as seen below<\/p>\n<p><a href=\"https:\/\/camo.githubusercontent.com\/98e7119cf87200e8bbbd60688a9bdaa97b96a511\/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f393530373731322f63617373616e6472612f6562732e706e67\" target=\"_blank\"><img src=\"https:\/\/camo.githubusercontent.com\/98e7119cf87200e8bbbd60688a9bdaa97b96a511\/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f393530373731322f63617373616e6472612f6562732e706e67\" alt=\"EBS\" data-canonical-src=\"https:\/\/dl.dropboxusercontent.com\/u\/9507712\/cassandra\/ebs.png\"\/><\/a><\/p>\n<p>Once you have your cluster up and running you're now ready to bootstrap and provision it. The manager file expects your list of ips to be newline separated and in configs\/yourconfig\/hostfile.txt<\/p>\n<p>Place all of your IP address in that file.<\/p>\n<h3><a href=\"https:\/\/github.com\/CrowdStrike\/cassandra-tools#bootstrappingprovisioning\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-bootstrappingprovisioning\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Bootstrapping\/Provisioning<\/h3>\n<p>To test out your running system (assuming you ran the pip install -r requirements.txt cmd above)<\/p>\n<pre>fab -u ubuntu  bootstrapcass21:config=c4-highperf\n<\/pre>\n<p>That command will run all the apt-get update\/installs, install java, format the EBS volume using XFS, turn off swap, etc.... One thing to note is that the fab command will always prompt you as to which hostfile you want to run. There are times you just want to bootstrap a few nodes and not the whole cluster. So you can just put those ips anywhere like \/tmp\/newips.txt and use type in that file in the prompt instead.<\/p>\n<p>Note that at time of writing it installs Cassandra Community version 2.1.9, if you're bored, submit a PR to make that configurable from the profile :)<\/p>\n<p>Once that is complete you'll want to set your seed nodes for that cluster. So pick one IP or a comma separated list and run<\/p>\n<pre>fab -u ubuntu  set_seeds:config=c4-highperf,seeds='10.10.100.XX'\n<\/pre>\n<p>Once you have your seeds set up now we can start up Cassandra<\/p>\n<pre>fab -u ubuntu  start_cass:config=c4-highperf\n<\/pre>\n<p>At this point you should login to one or all of the instances and just do a headcheck in \/var\/log\/cassandra\/system.log to ensure everything started up ok. If you want to do a quick check on what nodes are running Cassandra you can use the getrunning task<\/p>\n<pre>fab -u ubuntu  getrunning:config=c4-highperf\n<\/pre>\n<p>For a list of all the commands available you can ask fab to list the tasks<\/p>\n<pre>fab -l\n<\/pre>\n<p>Other common tasks will be changing yaml files or cassandra-env settings for testing different GC combinations. For that you would make your changes, save the files and run<\/p>\n<pre>fab -u ubuntu  configs:config=c4-highperf\n<\/pre>\n<p>You can also use the free form cmd task. For example, want to see all the java versions across your cluster?<\/p>\n<pre>fab -u ubuntu cmd:config=c4-highperf,cmd=\"java -version 2&gt;&amp;1 | grep version  | awk '{print \\$NF}'\"\n<\/pre>\n<p>Or see how much \"MAX HEAP SIZE\" your nodes are configured for<\/p>\n<pre>fab -u ubuntu cmd:config=c4-highperf,cmd=\"grep MAX_HEAP_SIZE \/etc\/cassandra\/cassandra-env.sh | grep G\"\n<\/pre>\n<p>The cmd task runs in parallel so going over 60+ nodes is within seconds.<\/p>\n<p>This repo also has support for running your stress machines. The workflow I was using was the following<\/p>\n<ol><li>Launch stress instances<\/li>\n<li>Set hostfile.txt in stress\/hostfile.txt with the IP address of stress machines<\/li>\n<li>Bootstrap stress machines with stress 2.1 code and yaml files<\/li>\n<li>Use csshX to view all the stress machines in multiple terminals<\/li>\n<li>Tweak yaml files and re-push stress to test various configs<\/li>\n<\/ol><p>A note on stress is that there is a 70MB compiled stress tarball included so rather than push that up on every node I'll run<\/p>\n<pre>fab -u ubuntu installstress\n<\/pre>\n<p>which will install stress on a single node (if just one is in your hostfile) then create an AMI of that node to launch more stress boxes to make things a bit faster.<\/p>\n<h3><a href=\"https:\/\/github.com\/CrowdStrike\/cassandra-tools#csshx\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-csshx\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>csshX<\/h3>\n<p>csshX is a neat little program that will allow you run the same command across multiple terminal windows simultaneously.<\/p>\n<p>You can find it here: <a href=\"https:\/\/github.com\/brockgr\/csshx\">https:\/\/github.com\/brockgr\/csshx<\/a>\nor install on OSX with<\/p>\n<pre>brew install csshx\n<\/pre>\n<p><a href=\"https:\/\/camo.githubusercontent.com\/d57641e4995a334d273acd0b90c151d04d4c7501\/687474703a2f2f7777772e62726f636b2d66616d696c792e6f72672f676176696e2f6d61636f73782f63737368582e706e67\" target=\"_blank\"><img src=\"https:\/\/camo.githubusercontent.com\/d57641e4995a334d273acd0b90c151d04d4c7501\/687474703a2f2f7777772e62726f636b2d66616d696c792e6f72672f676176696e2f6d61636f73782f63737368582e706e67\" alt=\"csshX view\" data-canonical-src=\"http:\/\/www.brock-family.org\/gavin\/macosx\/csshX.png\"\/><\/a><\/p>\n<p>to fire up csshX just type in<\/p>\n<pre>csshX --login ubuntu `cat ..\/stress\/hostfile.txt`\n<\/pre>\n<p>that will bring up the pane of stress machines, alt+tab if you don't see it right away and find the terminal windows.<\/p>\n<h3><a href=\"https:\/\/github.com\/CrowdStrike\/cassandra-tools#bootstrapping-stress-nodes\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-bootstrapping-stress-nodes\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Bootstrapping Stress Nodes<\/h3>\n<p>to install stress and the base yaml files, you can run<\/p>\n<pre>fab -u ubuntu installstress\n<\/pre>\n<p>that will install all the base code needed to run stress. If you make changes to the yaml files or add new ones and profiles you can use what's below to just push those changes<\/p>\n<pre>fab -u ubuntu  putstress\n<\/pre>\n<p>Once the files are uploaded you're ready to run stress. Using csshX in the red area that controls the output to all terminals you can type in<\/p>\n<pre>python runstress.py --profile=stress --seednode=10.10.10.XX --nodenum=1\n<\/pre>\n<p>That will run the following cmd under the covers<\/p>\n<pre>\/home\/ubuntu\/apache-cassandra-2.1.5\/tools\/bin\/cassandra-stress user duration=100000m cl=ONE profile=\/home\/ubuntu\/summit_stress.yaml ops\\(insert=1\\) no-warmup  -pop seq=1..100000000 -mode native cql3 -node 10.10.10.XX -rate threads=1000  -errors ignore\n<\/pre>\n<p>Type python runstress.py -h\nfor all the available options to pass like threads, seednode, etc...<\/p>\n<p>Place the correct IP there and you should be running stress against your new cluster. Dig around the runstress.py file to see what other profiles you can run, or add your own.<\/p>\n<\/article>","created_at":"2017-10-31T20:27:30+0000","updated_at":"2017-10-31T20:32:21+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":7,"domain_name":"github.com","preview_picture":"https:\/\/camo.githubusercontent.com\/2216a88d0077ecbe79a1245e70d168072b3b4dfc\/68747470733a2f2f646c2e64726f70626f7875736572636f6e74656e742e636f6d2f752f393530373731322f63617373616e6472612f746f706f6c6f67792e706e67","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4885"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4884,"title":"spotify\/cassandra-opstools","url":"https:\/\/github.com\/spotify\/cassandra-opstools","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3>\n      <article class=\"markdown-body entry-content\" itemprop=\"text\">\n<p>Generic tools and scripts to help operating Cassandra cluster<\/p>\n<p>spcassandra-abortrepairs:\nStops ongoing anti-entropy sessions on the local Cassandra host<\/p>\n<p>spcassandra-autobalance:\nAutomatically redistributes the tokens in a cluster so they are evenly\ndistributed. Tries to move as few tokens as possible to achieve this.\nIn a multi-DC setup, all datacenters must have the same number of nodes.\nOnly useful when not using vnodes.<\/p>\n<p>spcassandra-dsnitch:\nOutputs the score the Cassandra snitch has for every peer.<\/p>\n<p>spcassandra-generate-repairs:\nGenerates \"nodetool repair\" commands that repairs an entire cluster\nwith small token ranges.<\/p>\n<p>spcassandra-repairstats:\nScans the Cassandra system log and displays readable statistics\nof finished and running repairs.<\/p>\n<p>spcassandra-tombstones:\nScans a sstable and prints number of tombstones for each partition.<\/p>\n<p>spcassandra-truncate[all]hints:\nTruncates (all) hints on localhost toward the specified hosts.<\/p>\n<\/article>","created_at":"2017-10-31T20:27:34+0000","updated_at":"2017-10-31T20:32:21+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":0,"domain_name":"github.com","preview_picture":"https:\/\/avatars1.githubusercontent.com\/u\/251374?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4884"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4883,"title":"A script to monitor cassandra","url":"https:\/\/github.com\/causes\/cassandra-nagios","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.txt\n    <\/h3>\n      <div class=\"plain\"><pre>The repo:\nThis repo houses the work we did to monitor Cassandra using Nagios.\nHow repo is structured:\n  src - a patch to apply to nagios so that it does not truncate performance data\n  examples - example configuration\n    nagios - example nagios configuration\n    jolokia - example jolokia configuration\n  plugins - the check_cassandra.pl plugin and Jolokia.pm wrapper\nWhy:\nJolokia is a really awesome tool that makes it easy to get at jmx without having\nto use jmx or java. If you haven't already you should check out jmx4perl, a\ncomplete version of the Jolokia API, and another very good script\ncheck_jmx4perl.\nWe decided not to use jmx4perl because it had *too many* features (and\ndependencies). We wrote a minimalist Jolokia.pm module, implementing a very\nsmall subset of the Jolokia API (list, read). Also, we wanted to minimize the\nnumber of nagios checks we are making while still exporting all of the\nperformance datas.\nWhat:\nThe script, check_cassandra.pl, will query the Jolokia API running inside the\nCassandra JVM, checking an arbitrary number of metrics. The script returns all\nof the metrics, not just the checked metrics, as performane data. The examples\ndirectory has an example nagios configuration*.\nThe script is meant to run under ePn and can check multiple metrics in each run,\nso it should be relatively efficient.\nThe most common check is a regex check (-C regex -r '.*') that will check all\nmetrics matching the regular expression.\nThe script can also check the length of a list. The StorageService mbean exposes\nlists of nodes in certain states. This is the only place this type of check is\nused.\nThe script can also check for the presence of a string. This is useful, e.g., to\ncheck the cluster is NORMAL and the nodes are UP.\n*A disclaimer here: We have not actually started using Cassandra in production so\nthe thresholds are probably wrong and\/or we are not monitoring everything we\nshould and\/or we are monitoring things we probably shouldn't be.\nHow:\nFirst, you may want to apply the patch in the src directory to Nagios. Nagios\ntruncates plugin output at an arbitrary buffer size. This step is only required\nif you are interested in collecting all of the performance output returned by\nthe plugin. Without the patch nagios will truncate the performance data.\nConfigure Cassandra:\nCassandra needs to be configured with the jolokia-agent[1]. The agent should be\non the classpath. The easiest way is to drop the jolokia-jvm.jar into\n\/usr\/share\/cassandra\/lib.\nAdd the following to cassandra-env.sh:\n# Load the jolokia agent\nJVM_OPTS=\"$JVM_OPTS -javaagent:\/usr\/share\/cassandra\/lib\/jolokia-jvm-1.1.1-agent.jar=\\\nconfig=\/etc\/cassandra\/jolokia\/jolokia.properties\"\nThen copy the examples\/jolokia\/ to \/etc\/cassandra\/jolokia\/.\nConfigure Nagios:\nInstall the required perl modules on the nagios machine:\nsudo yum install perl-libwww-perl perl-JSON\nsudo apt-get install libwww-perl libjson-perl\nCopy the plugins directory into the nagios plugins directory.\nDefine nagios check commands similar to those in the examples directory.\nCollect performance data:\nUse graphios. Seriously, use graphios. It *just works*.\n[1] <a href=\"http:\/\/jolokia.org\/agent\/jvm.html\">http:\/\/jolokia.org\/agent\/jvm.html<\/a>\n<\/pre><\/div>","created_at":"2017-10-31T20:27:43+0000","updated_at":"2017-10-31T20:32:20+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":2,"domain_name":"github.com","preview_picture":"https:\/\/avatars1.githubusercontent.com\/u\/7448?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4883"}}},{"is_archived":0,"is_starred":0,"user_name":"admin","user_email":"rahul.singh@anant.us","user_id":1,"tags":[{"id":89,"label":"cassandra","slug":"cassandra"}],"id":4882,"title":"erickramirezDSE\/cass_log_tools","url":"https:\/\/github.com\/erickramirezDSE\/cass_log_tools","content":"<h3>\n      <svg aria-hidden=\"true\" class=\"octicon octicon-book\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/>\n      README.md\n    <\/h3><article class=\"markdown-body entry-content\" itemprop=\"text\"><h2><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#description\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-description\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Description<\/h2>\n<p>Simple scripts for working with Apache Cassandra logs.<\/p>\n<h2><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#overview\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-overview\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Overview<\/h2>\n<p>These are scripts I created to make it simpler to read\/summarise\/parse the <code>system.log<\/code>.<\/p>\n<p>They were intended to be overly simple for readability and for portability, i.e. they can just run on any machine that can run Bourne shell or Perl without having to download additional modules or plugins.<\/p>\n<h2><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#scripts\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-scripts\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a>Scripts<\/h2>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#compaction_ratesh\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-compaction_ratesh\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>compaction_rate.sh<\/code><\/h4>\n<p>Extracts the compaction throughput from a Cassandra <code>system.log<\/code>.<\/p>\n<p>Use this script to get a feel for the compaction in MB\/s.<\/p>\n<p>Usage: <code>compaction_rate.sh &lt;system_log&gt; [min_data_size_bytes]<\/code><\/p>\n<p>Sample output:<\/p>\n<pre>$ compaction_rate.sh system.log 20000000\n  Throughput: 16.228230MB\/s. | Data size: 38798031 (37 MB) | SSTables count: 2\n  Throughput: 15.939397MB\/s. | Data size: 41834507 (39 MB) | SSTables count: 2\n  Throughput: 15.885001MB\/s. | Data size: 45639407 (43 MB) | SSTables count: 2\n<\/pre>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#count_entries_per_hoursh\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-count_entries_per_hoursh\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>count_entries_per_hour.sh<\/code><\/h4>\n<p>Counts the occurrences of a string for each hour in the Cassandra <code>system.log<\/code>.<\/p>\n<p>Use this script to work out whether load has increased during a particular period.<\/p>\n<p>Useful query strings:<\/p>\n<ul><li>\"ParNew\" - shows distribution of GC pauses<\/li>\n<li>\"Compacted\" - shows distribution of compaction activity<\/li>\n<li>\"flush of Memtable\" - shows flushing activity, indicates traffic<\/li>\n<li>\"ConcurrentMarkSweep\" - indicates GC pressure<\/li>\n<li>\"Started hinted handoff\" - indicates existence of unresponsive nodes<\/li>\n<\/ul><p>Sample output:<\/p>\n<pre>$ count_entries_per_hour.sh ParNew system.log\n2015-04-28 12:00 - 8\n2015-04-28 16:00 - 108\n2015-04-28 20:00 - 202\n<\/pre>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#display_large_rowssh\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-display_large_rowssh\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>display_large_rows.sh<\/code><\/h4>\n<p>Displays entries in Cassandra logs relating to compaction of large rows.<\/p>\n<p>Useful for showing rows larger than a given size, e.g. 100MB.<\/p>\n<p>Usage: <code>display_large_rows.sh &lt;system_log&gt; [min_row_size_bytes]<\/code><\/p>\n<p>Sample output:<\/p>\n<pre>$ display_large_rows.sh system.log 1000000000\nINFO [CompactionExecutor:73] 2015-01-14 19:11:45,959 CompactionController.java (line 192) Compacting large row myKS\/myCF:8e6fb0b72937 (1407625692 bytes) incrementally | 1342 MB\nINFO [CompactionExecutor:73] 2015-01-14 19:13:09,901 CompactionController.java (line 192) Compacting large row myKS\/myCF:2eec906de37b (1410187132 bytes) incrementally | 1344 MB\nINFO [CompactionExecutor:73] 2015-01-14 19:14:34,765 CompactionController.java (line 192) Compacting large row myKS\/myCF:ce49043461ce (2871138316 bytes) incrementally | 2738 MB\n<\/pre>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#initial_log_assesssh\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-initial_log_assesssh\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>initial_log_assess.sh<\/code><\/h4>\n<p>A script I use to do a quick assessment of a Cassandra node. It highlights restarts, GC activity, dropped mutations, large rows, errors, etc.<\/p>\n<p>Usage: <code>initial_log_assess.sh system.log<\/code><\/p>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#rename_node_dirssh\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-rename_node_dirssh\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>rename_node_dirs.sh<\/code><\/h4>\n<p>The directory names for nodes in the OpsCenter Diagnostic tarball are quite long so I wrote this script to simplify them to just the IP address of the nodes.<\/p>\n<p>Usage: <code>cd &lt;diagnostic_dir&gt;\/nodes &amp;&amp; rename_node_dirs.sh<\/code><\/p>\n<p>Sample output:<\/p>\n<pre>$ rename_node_dirs.sh \nRenaming [opsc-2015-04-29-11-54-21-UTC-172.31.3.100] to [172.31.3.100]... OK\nRenaming [opsc-2015-04-29-11-54-21-UTC-172.31.36.54] to [172.31.36.54]... OK\nRenaming [opsc-2015-04-29-11-54-21-UTC-172.31.43.125] to [172.31.43.125]... OK\n<\/pre>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#summarise_log_casspl\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-summarise_log_casspl\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>summarise_log_cass.pl<\/code><\/h4>\n<p>Summarises a Cassandra log file into line counts by message type, thread names, classes and de-personalised messages.<\/p>\n<p>Usage: <code>summarise_log_cass.pl -f system.log<\/code><\/p>\n<p>Sample output:<\/p>\n<pre>===== Summarising log file [system_678571075.log] =====\n===== Count of message entries by log level =====\n    15708 --- INFO \n      311 --- WARN \n===== Count of message entries by thread =====\n     9871 --- [ScheduledTasks] \n     1512 --- [FlushWriter] \n     1263 --- [MemoryMeter] \n     1068 --- [RequestResponseStage] \n      814 --- [CompactionExecutor] \n      305 --- [HANDSHAKE#.#.#.#\/#.#.#.#] \n      279 --- [WRITE-\/#.#.#.#] \n      228 --- [main] \n      219 --- [HintedHandoff] \n...\n===== Count of message entries by class =====\n     9239 --- StatusLogger.java \n     2775 --- Memtable.java \n     1233 --- Gossiper.java \n      808 --- ColumnFamilyStore.java \n      593 --- CompactionTask.java \n      305 --- OutboundTcpConnection.java \n      280 --- SSLFactory.java \n      202 --- HintedHandOffManager.java \n      118 --- GCInspector.java \n...\n===== Count of message entries =====\n     9239 --- INFO [ScheduledTasks] StatusLogger.java ... \n     1234 --- INFO [MemoryMeter] Memtable.java CFS(Keyspace='...') liveRatio is #.# (just-counted was #.#).  calculation took #ms for # cells \n     1067 --- INFO [RequestResponseStage] Gossiper.java InetAddress \/#.#.#.# is now UP \n      756 --- INFO [FlushWriter] Memtable.java Writing Memtable-&lt;table&gt;@#(#\/# serialized\/live bytes, # ops) \n      743 --- INFO [FlushWriter] Memtable.java Completed flushing &lt;db_file&gt; (# bytes) for commitlog position ReplayPosition(segmentId=#, position=#) \n      500 --- INFO [ScheduledTasks] ColumnFamilyStore.java Enqueuing flush of Memtable-&lt;table&gt; \n      298 --- INFO [CompactionExecutor] CompactionTask.java Compacting [SSTableReader(path=&lt;sstable_files&gt;), ...] \n      295 --- INFO [CompactionExecutor] CompactionTask.java Compacted # to [&lt;sstable_files&gt;]... \n      279 --- INFO [HANDSHAKE#.#.#.#\/#.#.#.#] OutboundTcpConnection.java Handshaking version with #.#.#.#\/#.#.#.# \n      279 --- WARN [WRITE-\/#.#.#.#] SSLFactory.java Filtering out TLS_RSA_WITH_AES_#_CBC_SHA,TLS_DHE_RSA_WITH_AES_#_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_#_CBC_SHA as it isnt supported by the socket \n      155 --- INFO [GossipTasks] Gossiper.java InetAddress \/#.#.#.# is now DOWN \n      106 --- INFO [ScheduledTasks] GCInspector.java GC for ConcurrentMarkSweep: # ms for # collections, # used; max is # \n      100 --- INFO [HintedHandoff] HintedHandOffManager.java Started hinted handoff for host: UUID with IP: \/#.#.#.#\n...\n<\/pre>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#show_log_rangessh\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-show_log_rangessh\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>show_log_ranges.sh<\/code><\/h4>\n<p>This script is also run from the nodes directory, it will look for \"system.log\" files and then grab the first and last lines with the date string in them. The idea is to give the user the range the logs cover<\/p>\n<h4><a href=\"https:\/\/github.com\/erickramirezDSE\/cass_log_tools#nodeuptime\" aria-hidden=\"true\" class=\"anchor\" id=\"user-content-nodeuptime\"><svg aria-hidden=\"true\" class=\"octicon octicon-link\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"\/><\/a><code>nodeuptime<\/code><\/h4>\n<p>This script takes input from <code>nodetool info<\/code> and prints the nodes uptime in a more 'friendly' format .\nUseful to see how long has been up when looking at other nodetool commands.<\/p>\n<\/article>","created_at":"2017-10-31T20:27:47+0000","updated_at":"2017-10-31T20:32:20+0000","annotations":[],"mimetype":"text\/html","language":"en","reading_time":4,"domain_name":"github.com","preview_picture":"https:\/\/avatars0.githubusercontent.com\/u\/8530750?s=400&v=4","http_status":"200","_links":{"self":{"href":"\/api\/entries\/4882"}}}]}}